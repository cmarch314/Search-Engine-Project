{"text": "HW2 Frequency analysis Due date see schedule Part Warmup Pick your favorite image and sharpen it using the unsharp masking technique that we covered in class Part 1 Hybrid Images Look at image on right from very close then from far away Overview The goal of this part of the assignment is to create hybrid images using the approach described in the SIGGRAPH 2 6 paper by Oliva Torralba and Schyns Hybrid images are static images that change in interpretation as a function of the viewing distance The basic idea is that high frequency tends to dominate perception when it is available but at a distance only the low frequency smooth part of the signal can be seen By blending the high frequency portion of one image with the low frequency portion of another you get a hybrid image that leads to different interpretations at different distances Details Here we have included two sample images and some starter code that can be used to load two images and align them The alignment is important because it affects the perceptual grouping read the paper for details if you are interested First you ll need to get a few pairs of images that you want to make into hybrid images You can use the sample images for debugging but you should use your own images in your results Then you will need to write code to low pass filter one image high pass filter the second image and add or average the two images For a low pass filter Oliva et al suggest using a standard 2D Gaussian filter For a high pass filter they suggest using the impulse filter minus the Gaussian filter which can be computed by subtracting the Gaussian filtered image from the original I suggest using Matlab s conv2 fspecial commands Recall that the cutoff frequency for a Gaussian filter is controlled by its variance You will need to experiment to determine proper cutoff variances to capture the right frequencies For your favorite result you should also illustrate the process through frequency analysis Show the log magnitude of the Fourier transform of the two input images the filtered images and the hybrid image In MATLAB you can compute and display the 2D Fourier transform with with imagesc log abs fftshift fft2 gray image Try creating a variety of types of hybrid images change of expression morph between different objects change over time etc The site has several examples that may inspire Extra Points Try using color to enhance the effect Does it work better to use color for the high frequency component the low frequency component or both 5 pts Part 2 Gaussian and Laplacian Stacks Overview In this part you will implement Gaussian and Laplacian stacks which are kind of like pyramids but without the downsampling Then you will use these to analyze some images and your results from part 1 Details Implement a Gaussian and a Laplacian stack For reference Gaussian and Laplacian pyramids were first introduced in this paper The different between a stack and a pyramid is that in each level of the pyramid the image is downsampled so that the result gets smaller and smaller In a stack the images are never downsampled so the results are all the same dimension as the original image and can all be saved in one 3D matrix if the original image was a grayscale image Note that there is one subtlety here since we are not downsampling the image we must use a larger and larger sigma for the Gaussian filtering at each level A good rule of thumb is to double the sigma at each level of the pyramid e g sigma 2 4 8 16 and to always use the resulting Gaussian filter on the original image In this way we will get a stack that behaves similarly to a pyramid that was downsampled to half its size at each level If you would rather work with pyramids you may implement pyramids other than stacks However in any case you are NOT allowed to use matlab s impyramid and its equivalents in this project You must implement your stacks from scratch Apply your Gaussian and Laplacian stacks to interesting images that contain structure in multiple resolution such as paintings like the Salvador Dali painting of Lincoln and Gala we saw in class or the Mona Lisa Display your stacks computed from these images to discover the structure at each resolution Illustrate the process you took to create your hybrid images in part 1 by applying your Gaussian and Laplacian stacks and displaying them for your favorite result This should look similar to Figure 7 in the Oliva et al paper Part 3 Multiresolution Blending Overview The goal of this part of the assignment is to blend two images seamlessly using a multi resolution blending as described in the 1983 paper by Burt and Adelson An image spline is a smooth seam joining two image together by gently distorting them Multiresolution blending computes a gentle seam between the two images seperately at each band of image frequencies resulting in a much smoother seam Details Here we have included the two sample images from the paper of an apple and an orange First you ll need to get a few pairs of images that you want blend together with a vertical or horizontal seam You can use the sample images for debugging but you should use your own images in your results Then you will need to write some code in order to use your Gaussian and Laplacian stacks from part 2 in order to blend the images together Since we are using stacks instead of pyramids like in the paper the algorithm described on page 226 will not work as is If you try it out you will find that you end up with a very clear seam between the apple and the orange since in the pyramid case the downsampling blurring upsampling hoopla ends up blurring the abrupt seam proposed in this algorithm Instead you should always use a mask as is proposed in the algorithm on page 23 and remember to create a Gaussian pyramid for your mask image as well as for the two input images The Gaussian blurring of the mask in the pyramid will smooth out the transition between the two images For the vertical or horizontal seam your mask will simply be a step function of the same size as the original images Now that you ve made yourself an oraple a k a your vertical or horizontal seam is nicely working pick a couple of images to blend together with an irregular mask as is demonstrated in figure 8 in the paper Blend together some crazy ideas of your own Illustrate the process by applying your Laplacian stack and displaying it for your favorite result and the masked input images that created it This should look similar to Figure 1 in the paper Extra Points Try using color to enhance the effect 5 pts Implement Style transfer for headshot portraits From this exciting SIGGRAPH 2 14 paper by Shih et al It s amazing to see just how far Gaussian and Laplacian stacks can take you 2 pts What to turn in Writeup Make sure your PDF writeup includes both text and images to show us what you ve done describe in detail your algorithm parameters for each of your results Code Make sure each part of the project has a main part1 m main part2 m etc file that can execute that part of the assignment in full Include a README describing the contents of each file For the warmup Show us your sharpened image including the original one For the hybrid images Show us your favorite result Include 1 the original and filtered input images 2 the hybrid image 3 and the FFT images Briefly a few sentences explain how it works using the included images as illustrations Explain any clever ideas that you ve incorporated and any parameters This should be with your own images not the included samples Next show us at least two more results including one that doesn t work so well failure example Briefly explain how you got the good results e g chosen cut off frequencies alignment tricks other techniques as well as any difficulties and the possible reasons for the bad results If you are so fortunate that everything that you try works well try to figure out what shouldn t work Describe any extra credit under a separate heading For the Stacks Display the multiple resolutions of image structure you found using your Laplacian stacks on at least one cool image like the Lincoln one Display your multiresolution analysis of your favorite hybrid image result For the multiresolution blending Show us your favorite result Include 1 the original images 2 the blended images and 3 the stack analysis Briefly a few sentences explain how it works using the included images as illustrations Explain any clever ideas that you ve incorporated and any parameters This should be with your own images not the included samples Next show us at least two more results including one with a non trivial mask and one that doesn t work so well failure example Briefly explain how you got the good results as well as any difficulties and the possible reasons for the bad results If you are so fortunate that everything that you try works well try to figure out what shouldn t work Describe any extra credit under a separate heading Tell us what is the coolest most interesting thing you learned from this assignment Scoring The core assignment is worth 1 points as follows 5 points for the implementation of all three parts of the project 5 points for the writeup 5 points for the warmup 1 points for hybrid images and the Fourier analysis 5 points for including at least two hybrid image examples beyond the first including at least one failure 1 points for at least two laplacian stack examples 1 points for multiresolution blending and the Fourier analysis 5 points for including at least two multiresolution blending examples beyond the apple orange one of them with an irregular mask 5 points for clarity You can also earn up to 2 extra points for extensions above as well as an additional 1 points for a 1 day early submission Acknowledgements This assignment was created by Alyosha Efros at UC Berkeley ", "_id": "http://www.ics.uci.edu/~dramanan/teaching/cs116_winter15/hw/hw2.html", "title": "hw2", "html": "<html>\n<head>\n<title>HW2</title>\n</head>\n<body>\n\n  <h1>HW2: Frequency analysis</h1>\n  <h2> Due date (see <a href=\"../lec.html\">schedule</a>)</h1>\n\n<h2> Part 0: Warmup</h2>\n<p> Pick your favorite image and \"sharpen\" it using the unsharp masking technique that we covered in class.\n\n<h2>Part 1: Hybrid Images</h2>\n  <img src=\"./teaser.jpg\" width=300><br/>\n  <span class=text style='font-size:12.0pt'>(Look at image on right from very close, then from far away.) \n</center>\n<br>\n<h3>Overview</h3>\n\n<p class=\"text\">The goal of this part of the assignment is to create hybrid images using the approach\ndescribed in the SIGGRAPH 2006 <a\nhref=\"hybrid_images.pdf\">paper</a>\nby Oliva, Torralba, and Schyns. <i>Hybrid images</i> are static images that\nchange in interpretation as a function of the viewing distance. The basic idea is that high frequency tends\nto dominate perception when it is available, but, at a distance, only the low\nfrequency (smooth) part of the signal can be seen. By blending the high frequency portion of one image with the low-frequency portion of another, you get a hybrid image that leads to different interpretations at different distances.\n</p>\n\n<h3>Details</h3>\n\n<p class=text><a href=\"./hybrid.zip\">Here</a>, we have included two sample images and some\nstarter code that can be used to load two images and align them.  The alignment is important because it affects the perceptual grouping (read the paper for details if you are interested).</p>\n\n<ol>\n  <li>\n    First, you'll need to get a few pairs of images that you want to make into\n    hybrid images.  You can use the sample images for debugging, but you should use your own images in your results.  Then, you will need to write code to low-pass filter one image, high-pass filter the second image, and add (or average) the two images.  For a low-pass filter, Oliva et al. suggest using a standard 2D Gaussian filter. For a high-pass filter, they suggest using the impulse filter minus the Gaussian filter (which can be computed by subtracting the Gaussian-filtered image from the original). I suggest using Matlab's <tt>conv2,fspecial</tt> commands.\n    Recall that the <a href=\"http://en.wikipedia.org/wiki/Cutoff_frequency\">cutoff-frequency</a> for a Gaussian filter is controlled by its variance. You will need to experiment to determine proper cutoff / variances to capture the \"right\" frequencies.\n  <li>For your favorite result, you should also illustrate the process through frequency analysis.  Show the log magnitude of the Fourier transform of the two input images, the filtered images, and the\n    hybrid image.  In MATLAB, you can compute and display the 2D Fourier transform with\n    with: \n    <tt>imagesc(log(abs(fftshift(fft2(gray_image)))))</tt> \n  <li>Try creating a variety of types of hybrid images (change of expression,\n    morph between different objects, change over time, etc.).\n    The <a href=\"http://cvcl.mit.edu/hybridimage.htm\">site</a> has several examples that\n    may inspire.</li>\n</ol>\n<h3> Extra Points</h3>\n<p class=text>Try using color to enhance the effect.\nDoes it work better to use color for the high-frequency component, the\nlow-frequency component, or both? (5 pts)\n\n<h2>Part 2: Gaussian and Laplacian Stacks</h2>\n<img src=\"lincoln.jpg\" width=\"200\" alt=\"lincoln\">\n<h3 align=\"left\">Overview</h3>\n<p align=\"left\" class=\"text\">In this part you will implement Gaussian and Laplacian stacks, which are kind of like pyramids but without the downsampling. Then you will use these to analyze some images, and your results from part 1.</p>\n  <h3 align=\"left\">Details</h3>\n</center>\n<ol>\n  <li>\n    <div align=\"left\"> Implement a Gaussian and a Laplacian <strong>stack</strong>. For reference, Gaussian and Laplacian pyramids were first introduced in this <a href=\"pyramid.pdf\">paper</a>. The different between a stack and a pyramid is that in each level of the pyramid the image is downsampled, so that the result gets smaller and smaller. In a stack the images are never downsampled so the results are all the same dimension as the original image, and can all be saved in one 3D matrix (if the original image was a grayscale image). Note that there is one subtlety here: since we are not downsampling the image, we must use a larger and larger sigma for the Gaussian filtering at each level. A good rule of thumb is to double the sigma at each level of the pyramid (e.g. sigma = 2,4,8,16...), and to always use the resulting Gaussian filter on the <strong>original</strong> image. In this way we will get a stack that behaves similarly to a pyramid that was downsampled to half its size at each level. If you would rather work with pyramids, you may implement pyramids other than stacks. However, in any case, you are <strong>NOT</strong> allowed to use matlab's<span style=\"font-family: &quot;Courier New&quot;; font-size: 11.0pt\"> impyramid() </span>and its equivalents in this project. You must implement your stacks from scratch!</div>\n  </li>\n  <li>Apply your Gaussian and Laplacian stacks to interesting images that contain structure in multiple resolution such as paintings like the Salvador Dali painting of Lincoln and Gala we saw in class, or the Mona Lisa. Display your stacks computed from these images to discover the structure at each resolution.</li>\n  <li>Illustrate the process you took to create your hybrid images in part 1 by applying your Gaussian and Laplacian stacks and displaying them for your favorite result.  This should look similar to Figure 7 in the Oliva et al. paper.</li>\n</ol>\n<p class=text>\n<p class=text>\n<h2>Part 3: Multiresolution Blending</h2>\n<img src=\"orple.jpg\" alt=\"half apple half orange\" width=\"200\">\n<h3>Overview</h3>\n<p class=\"text\">The goal of this part of the assignment is to blend two images seamlessly using a multi resolution blending as described in the 1983 <a href=\"http://persci.mit.edu/pub_pdfs/spline83.pdf\">paper</a> by Burt and Adelson. An <em>image spline</em> is a smooth seam joining two image together by gently distorting them. <em>Multiresolution blending </em> computes a gentle seam between the two images seperately at each band of image frequencies, resulting in a much smoother seam.</p>\n<h3>Details</h3>\n<p class=text><a href=\"spline.zip\">Here</a>, we have included the two sample images from the paper (of an apple and an orange).</p>\n<ol>\n  <li> First, you'll need to get a few pairs of images that you want blend together with a vertical or horizontal seam.  You can use the sample\n  images for debugging, but you should use your own images in your results. Then you will need to write some code in order to use your Gaussian and Laplacian stacks from part 2 in order to blend the images together. Since we are using stacks instead of pyramids like in the paper, the algorithm described on page 226 will not work as-is. If you try it out, you will find that you end up with a very clear seam between the apple and the orange since in the pyramid case the downsampling/blurring/upsampling hoopla ends up blurring the abrupt seam proposed in this algorithm. Instead, you should always use a mask as is proposed in the algorithm on page 230, and remember to create a Gaussian pyramid for your mask image as well as for the two input images. The Gaussian blurring of the mask in the pyramid will smooth out the transition between the two images. For the vertical or horizontal seam, your mask will simply be a step function of the same size as the original images.</li>\n  <li>Now that you've made yourself an oraple (a.k.a your vertical or horizontal seam is nicely working), pick a couple of images to blend together with an irregular mask, as is demonstrated in figure 8 in the paper.<span style='font-size:11.0pt;font-family:\"Courier New\"'></span></li>\n  <li>Blend together some crazy ideas of your own!</li>\n  <li>Illustrate the process by applying your  Laplacian stack and displaying it for your favorite result and the masked input images that created it.  This should look similar to Figure 10 in the paper.</li>\n</ol>\n<h3> Extra Points</h3>\n<ul>\n  <li>Try using color to enhance the effect. (5 pts)\n  </li>\n  <li>Implement <a href=\"http://people.csail.mit.edu/yichangshih/portrait_web/\">Style transfer for headshot portraits </a>From this exciting SIGGRAPH 2014 paper by Shih et. al. It's amazing to see just how far Gaussian and Laplacian stacks can take you! (20 pts)</li>\n</ul>\n<h3>&nbsp;</h3>\n<h3>What to turn in</h3>\n\n<p> <b> Writeup:</b> Make sure your PDF writeup includes both text and images to show us what you've done (describe in detail your algorithm parameters for each of your results).\n<p> <b> Code:</b> Make sure each part of the project has a main_part1.m, main_part2.m, etc. file <strong>that can execute that part of the assignment in full </strong>. Include a README describing the contents of each file.<br />\n<p class=text><strong>For the warmup:</strong>\n<ul>\n  <li class=text>Show us your sharpened image, including the original one.</li>\n</ul>\n<p><strong>For the hybrid images:</strong></p>\n<ul>\n  <li class=text> Show us your favorite result.  Include: 1) the original and filtered input images; 2) the hybrid image; 3) and the FFT images. Briefly (a few sentences) explain how it\n    works, using the included images as illustrations.  Explain any clever\n    ideas that you've incorporated and any parameters. This should be with your own\n    images (not the included samples). </li>\n  <li class=text> Next, show us at least two more results, including one that doesn't work so well (failure example).  Briefly explain how you got the good results (e.g., chosen cut-off frequencies, alignment tricks, other techniques), as well as any difficulties and the possible reasons for the bad results.  If you are so fortunate that everything that you try works well, try to figure out what shouldn't work.</li>\n  <li class=text> Describe any extra credit under a separate heading. </li>\n</ul>\n<p><strong>For the Stacks:</strong></p>\n<ul>\n  <li class=text>Display the multiple resolutions of image structure you found using your Laplacian  stacks on at least one cool image (like the Lincoln one).</li>\n  <li class=text>Display your multiresolution analysis of your favorite hybrid image result.</li>\n</ul>\n<p class=text><strong>For the multiresolution blending:</strong>\n<ul>\n<li class=text>\nShow us your favorite result.  Include: 1) the original  images; 2) the blended images; and 3) the stack analysis. Briefly (a few sentences) explain how it\nworks, using the included images as illustrations.  Explain any clever\nideas that you've incorporated and any parameters. This should be with your own\nimages (not the included samples).\n</li>\n<li class=text>\nNext, show us at least two more results, including one with a non-trivial mask and one that doesn't work so well (failure example).  Briefly explain how you got the good results, as well as any difficulties and the possible reasons for the bad results.  If you are so fortunate that everything that you try works well, try to figure out what shouldn't work.  \n</li>\n<li class=text>  Describe any extra credit under a separate heading.\n</li>\n</ul>\n<p><span class=\"text\">Tell us what is the coolest/most interesting thing you learned from this assignment!</span></p>\n<h3>Scoring</h3>\n\n<p class=text>The core assignment is worth <b>100</b> points, as follows: </p>\n\n<ul>\n <li class=text> <b>50 points</b> for the implementation of all three parts of the project. </li>\n <li class=text> <b> 50 points </b> for the writeup: 5 points for the warmup; 10 points for hybrid images and the Fourier analysis; 5 points for including at least two hybrid image examples beyond the first (including at least one failure); 10 points for at least two laplacian stack examples; 10 points for multiresolution blending and the Fourier analysis; 5 points for including at least two multiresolution blending examples beyond the apple+orange, one of them with an irregular mask! 5 points for clarity. \n   <o:p></o:p>\n </li>\n</ul>\n\n<p class=text>\nYou can also earn up to <b>20 extra points</b> for extensions above, as well as an additional <b>10 points</b> for a 1-day early submission.\n</p>\n\n<h3>Acknowledgements</h3>\n\n<p class=text>\nThis assignment was created by Alyosha Efros at UC Berkeley.\n\n</body>\n\n</html>\n", "id": 2663.0}