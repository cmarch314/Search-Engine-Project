{"text": "ICS 161 Design and Analysis of Algorithms Lecture notes for February 15 1996 Breadth first search and depth first search Traversal of graphs and digraphs To traverse means to visit the vertices in some systematic order You should be familiar with various traversal methods for trees preorder visit each node before its children postorder visit each node after its children inorder for binary trees only visit left subtree node right subtree We also saw another kind of traversal topological ordering when I talked about shortest paths Today we ll see two other traversals breadth first search BFS and depth first search DFS Both of these construct spanning trees with certain properties useful in other graph algorithms We ll start by describing them in undirected graphs but they are both also very useful for directed graphs Breadth First Search This can be throught of as being like Dijkstra s algorithm for shortest paths but with every edge having the same length However it is a lot simpler and doesn t need any data structures We just keep a tree the breadth first search tree a list of nodes to be added to the tree and markings Boolean variables on the vertices to tell whether they are in the tree or list breadth first search unmark all vertices choose some starting vertex x mark x list L x tree T x while L nonempty choose some vertex v from front of list visit v for each unmarked neighbor w mark w add it to end of list add edge vw to T It s very important that you remove vertices from the other end of the list than the one you add them to so that the list acts as a queue fifo storage rather than a stack lifo The visit v step would be filled out later depending on what you are using BFS for just like the tree traversals usually involve doing something at each vertex that is not specified as part of the basic algorithm If a vertex has several unmarked neighbors it would be equally correct to visit them in any order Probably the easiest method to implement would be simply to visit them in the order the adjacency list for v is stored in Let s prove some basic facts about this algorithm First each vertex is clearly marked at most once added to the list at most once since that happens only when it s marked and therefore removed from the list at most once Since the time to process a vertex is proportional to the length of its adjacency list the total time for the whole algorithm is O m Next let s look at the tree T constructed by the algorithm Why is it a tree If you think of each edge vw as pointing upward from w to v then each edge points from a vertex visited later to one visited earlier Following successive edges upwards can only get stopped at x which has no edge going upward from it so every vertex in T has a path to x This means that T is at least a connected subgraph of G Now let s prove that it s a tree A tree is just a connected and acyclic graph so we need only to show that T has no cycles In any cycle no matter how you orient the edges so that one direction is upward and the other downward there is always a bottom vertex having two upward edges out of it But in T each vertex has at most one upward edge so T can have no cycles Therefore T really is a tree It is known as a breadth first search tree We also want to know that T is a spanning tree i e that if the graph is connected every vertex has some path to the root x then every vertex will occur somewhere in T We can prove this by induction on the length of the shortest path to x If v has a path of length k starting v w x then w has a path of length k 1 and by induction would be included in T But then when we visited w we would have seen edge vw and if v were not already in the tree it would have been added Breadth first traversal of G corresponds to some kind of tree traversal on T But it isn t preorder postorder or even inorder traversal Instead the traversal goes a level at a time left to right within a level where a level is defined simply in terms of distance from the root of the tree For instance the following tree is drawn with vertices numbered in an order that might be followed by breadth first search 1 2 3 4 5 6 7 8 9 1 11 The proof that vertices are in this order by breadth first search goes by induction on the level number By the induction hypothesis BFS lists all vertices at level k 1 before those at level k Therefore it will place into L all vertices at level k before all those of level k 1 and therefore so list those of level k before those of level k 1 This really is a proof even though it sounds like circular reasoning Breadth first search trees have a nice property Every edge of G can be classified into one of three groups Some edges are in T themselves Some connect two vertices at the same level of T And the remaining ones connect two vertices on two adjacent levels It is not possible for an edge to skip a level Therefore the breadth first search tree really is a shortest path tree starting from its root Every vertex has a path to the root with path length equal to its level just follow the tree itself and no path can skip a level so this really is a shortest path Breadth first search has several uses in other graph algorithms but most are too complicated to explain in detail here One is as part of an algorithm for matching which is a problem in which you want to pair up the n vertices of a graph by n 2 edges If you have a partial matching pairing up only some of the vertices you can extend it by finding an alternating path connecting two unmatched vertices this is a path in which every other edge is part of the partial matching If you remove those edges in the path from the matching and add the other path edges back into the matching you get a matching with one more edge Alternating paths can be found using a version of breadth first search A second use of breadth first search arises in certain pattern matching problems For instance if you re looking for a small subgraph such as a triangle as part of a larger graph you know that every vertex in the triangle has to be connected by an edge to every other vertex Since no edge can skip levels in the BFS tree you can divide the problem into subproblems in which you look for the triangle in pairs of adjacent levels of the tree This sort of problem in which you look for a small graph as part of a larger one is known as subgraph isomorphism In a recent paper I used this idea to solve many similar pattern matching problems in linear time Depth first search Depth first search is another way of traversing graphs which is closely related to preorder traversal of a tree Recall that preorder traversal simply visits each node before its children It is most easy to program as a recursive routine preorder node v visit v for each child w of v preorder w To turn this into a graph traversal algorithm we basically replace child by neighbor But to prevent infinite loops we only want to visit each vertex once Just like in BFS we can use marks to keep track of the vertices that have already been visited and not visit them again Also just like in BFS we can use this search to build a spanning tree with certain useful properties dfs vertex v visit v for each neighbor w of v if w is unvisited dfs w add edge vw to tree T The overall depth first search algorithm then simply initializes a set of markers so we can tell which vertices are visited chooses a starting vertex x initializes tree T to x and calls dfs x Just like in breadth first search if a vertex has several neighbors it would be equally correct to go through them in any order I didn t simply say for each unvisited neighbor of v because it is very important to delay the test for whether a vertex is visited until the recursive calls for previous neighbors are finished The proof that this produces a spanning tree the depth first search tree is essentially the same as that for BFS so I won t repeat it However while the BFS tree is typically short and bushy the DFS tree is typically long and stringy Just like we did for BFS we can use DFS to classify the edges of G into types Either an edge vw is in the DFS tree itself v is an ancestor of w or w is an ancestor of v These last two cases should be thought of as a single type since they only differ by what order we look at the vertices in What this means is that if v and w are in different subtrees of v we can t have an edge from v to w This is because if such an edge existed and say v were visited first then the only way we would avoid adding vw to the DFS tree would be if w were visited during one of the recursive calls from v but then v would be an ancestor of w As an example of why this property might be useful let s prove the following fact in any graph G either G has some path of length at least k or G has O kn edges Proof look at the longest path in the DFS tree If it has length at least k we re done Otherwise since each edge connects an ancestor and a descendant we can bound the number of edges by counting the total number of ancestors of each descendant but if the longest path is shorter than k each descendant has at most k 1 ancestors So there can be at most k 1 n edges This fact can be used as part of an algorithm for finding long paths in G another subgraph isomorphism problem closely related to the traveling salesman problem If k is a small constant like say 5 you can find paths of length k in linear time measured as a function of n But measured as a function of k the time is exponential which isn t surprising because this problem is closely related to the traveling salesman problem For more on this particular problem see Michael R Fellows and Michael A Langston On search decision and the efficiency of polynomial time algorithms 21st ACM Symp Theory of Computing 1989 pp 5 1 512 Relation between BFS and DFS It may not be clear from the pseudo code above but BFS and DFS are very closely related to each other In fact in class I tried to describe a search in which I modified the add to end of list line in the BFS pseudocode to add to start of list but the resulting traversal algorithm was not the same as DFS With a little care it is possible to make BFS and DFS look almost the same as each other as similar as say Prim s and Dijkstra s algorithms are to each other bfs G list L empty tree T empty choose a starting vertex x search x while L nonempty remove edge v w from start of L if w not yet visited add v w to T search w dfs G list L empty tree T empty choose a starting vertex x search x while L nonempty remove edge v w from end of L if w not yet visited add v w to T search w search vertex v visit v for each edge v w add edge v w to end of L Both of these search algorithms now keep a list of edges to explore the only difference between the two is that while both algorithms adds items to the end of L BFS removes them from the beginning which results in maintaining the list as a queue while DFS removes them from the end maintaining the list as a stack BFS and DFS in directed graphs Although we have discussed them for undirected graphs the same search routines work essentially unmodified for directed graphs The only difference is that when exploring a vertex v we only want to look at edges v w going out of v we ignore the other edges coming into v For directed graphs too we can prove nice properties of the BFS and DFS tree that help to classify the edges of the graph For BFS in directed graphs each edge of the graph either connects two vertices at the same level goes down exactly one level or goes up any number of levels For DFS each edge either connects an ancestor to a descendant a descendant to an ancestor or one node to a node in a previously visited subtree It is not possible to get forward edges connecting a node to a subtree visited later than that node We ll use this property next time to test if a directed graph is strongly connected every vertex can reach every other one ICS 161 Dept Information Computer Science UC Irvine Last update ", "_id": "http://www.ics.uci.edu/~eppstein/161/960215.html", "title": "bfs and dfs", "html": "<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 3.2//EN\">\n<html>\n<head>\n<title>BFS and DFS</title>\n<meta name=\"Owner\" value=\"eppstein\">\n<meta name=\"Reply-To\" value=\"eppstein@ics.uci.edu\">\n</head>\n<body>\n<h1>ICS 161: Design and Analysis of Algorithms<br>\nLecture notes for February 15, 1996</h1>\n\n<!--#config timefmt=\"%d %h %Y, %T %Z\" -->\n<hr>\n<h1>Breadth first search and depth first search</h1>\n\n<h2>Traversal of graphs and digraphs</h2>\n\nTo traverse means to visit the vertices in some systematic order.\nYou should be familiar with various traversal methods for trees: \n\n<blockquote>preorder: visit each node before its children.<br>\npostorder: visit each node after its children.<br>\ninorder (for binary trees only): visit left subtree, node, right\nsubtree.</blockquote>\n\n<p>We also saw another kind of traversal, <a href=\n\"960208.html#topo\">topological ordering</a>, when I talked about\nshortest paths.</p>\n\n<p>Today, we'll see two other traversals: breadth first search\n(BFS) and depth first search (DFS). Both of these construct\nspanning trees with certain properties useful in other graph\nalgorithms. We'll start by describing them in undirected graphs,\nbut they are both also very useful for directed graphs.</p>\n\n<h2>Breadth First Search</h2>\n\nThis can be throught of as being like Dijkstra's algorithm for\nshortest paths, but with every edge having the same length. However\nit is a lot simpler and doesn't need any data structures. We just\nkeep a tree (the breadth first search tree), a list of nodes to be\nadded to the tree, and markings (Boolean variables) on the vertices\nto tell whether they are in the tree or list. \n\n<p><b>breadth first search:</b></p>\n\n<pre>\n    unmark all vertices\n    choose some starting vertex x\n    mark x\n    list L = x\n    tree T = x\n    while L nonempty\n    choose some vertex v from front of list\n    visit v\n    for each unmarked neighbor w\n        mark w\n        add it to end of list\n        add edge vw to T\n</pre>\n\nIt's very important that you remove vertices from the other end of\nthe list than the one you add them to, so that the list acts as a\nqueue (fifo storage) rather than a stack (lifo). The \"visit v\" step\nwould be filled out later depending on what you are using BFS for,\njust like the tree traversals usually involve doing something at\neach vertex that is not specified as part of the basic algorithm.\nIf a vertex has several unmarked neighbors, it would be equally\ncorrect to visit them in any order. Probably the easiest method to\nimplement would be simply to visit them in the order the adjacency\nlist for v is stored in. \n\n<p>Let's prove some basic facts about this algorithm. First, each\nvertex is clearly marked at most once, added to the list at most\nonce (since that happens only when it's marked), and therefore\nremoved from the list at most once. Since the time to process a\nvertex is proportional to the length of its adjacency list, the\ntotal time for the whole algorithm is O(m).</p>\n\n<p><a name=\"bfstree\">Next, let's look at the tree T constructed by\nthe algorithm. Why is it a tree? If you think of each edge vw as\npointing \"upward\" from w to v, then each edge points from a vertex\nvisited later to one visited earlier. Following successive edges\nupwards can only get stopped at x (which has no edge going upward\nfrom it) so every vertex in T has a path to x. This means that T is\nat least a connected subgraph of G. Now let's prove that it's a\ntree. A tree is just a connected and acyclic graph, so we need only\nto show that T has no cycles. In any cycle, no matter how you\norient the edges so that one direction is \"upward\" and the other\n\"downward\", there is always a \"bottom\" vertex having two upward\nedges out of it. But in T, each vertex has at most one upward edge,\nso T can have no cycles. Therefore T really is a tree. It is known\nas a <i>breadth first search tree</i>.</a></p>\n\n<p>We also want to know that T is a <i>spanning tree</i>, i.e. that\nif the graph is connected (every vertex has some path to the root\nx) then every vertex will occur somewhere in T. We can prove this\nby induction on the length of the shortest path to x. If v has a\npath of length k, starting v-w-...-x, then w has a path of length\nk-1, and by induction would be included in T. But then when we\nvisited w we would have seen edge vw, and if v were not already in\nthe tree it would have been added.</p>\n\n<p>Breadth first traversal of G corresponds to some kind of tree\ntraversal on T. But it isn't preorder, postorder, or even inorder\ntraversal. Instead, the traversal goes a <i>level</i> at a time,\nleft to right within a level (where a level is defined simply in\nterms of distance from the root of the tree). For instance, the\nfollowing tree is drawn with vertices numbered in an order that\nmight be followed by breadth first search:</p>\n\n<pre>\n        1\n      / | \\\n    2   3   4\n      /   \\     |\n    5       6   7\n    |     / | \\\n    8    9 10 11\n</pre>\n\nThe proof that vertices are in this order by breadth first search\ngoes by induction on the level number. By the induction hypothesis,\nBFS lists all vertices at level k-1 before those at level k.\nTherefore it will place into L all vertices at level k before all\nthose of level k+1, and therefore so list those of level k before\nthose of level k+1. (This really is a proof even though it sounds\nlike circular reasoning.) \n\n<p>Breadth first search trees have a nice property: Every edge of G\ncan be classified into one of three groups. Some edges are in T\nthemselves. Some connect two vertices at the same level of T. And\nthe remaining ones connect two vertices on two adjacent levels. It\nis not possible for an edge to skip a level.</p>\n\n<p>Therefore, the breadth first search tree really is a shortest\npath tree starting from its root. Every vertex has a path to the\nroot, with path length equal to its level (just follow the tree\nitself), and no path can skip a level so this really is a shortest\npath.</p>\n\n<p><a name=\"match\">Breadth first search has several uses in other\ngraph algorithms, but most are too complicated to explain in detail\nhere. One is as part of an algorithm for <i>matching</i>, which is\na problem in which you want to pair up the n vertices of a graph by\nn/2 edges. If you have a partial matching, pairing up only some of\nthe vertices, you can extend it by finding an <i>alternating\npath</i> connecting two unmatched vertices; this is a path in which\nevery other edge is part of the partial matching. If you remove\nthose edges in the path from the matching, and add the other path\nedges back into the matching, you get a matching with one more\nedge. Alternating paths can be found using a version of breadth\nfirst search.</a></p>\n\n<p><a name=\"sgi\">A second use of breadth first search arises in\ncertain pattern matching problems. For instance, if you're looking\nfor a small subgraph such as a triangle as part of a larger graph,\nyou know that every vertex in the triangle has to be connected by\nan edge to every other vertex. Since no edge can skip levels in the\nBFS tree, you can divide the problem into subproblems, in which you\nlook for the triangle in pairs of adjacent levels of the tree. This\nsort of problem, in which you look for a small graph as part of a\nlarger one, is known as <i>subgraph isomorphism</i>. In <a href= \n\"http://www.ics.uci.edu/~eppstein/pubs/p-psgi\">a recent paper</a>,\nI used this idea to solve many similar pattern-matching problems in\nlinear time.</a></p>\n\n<h2>Depth first search</h2>\n\nDepth first search is another way of traversing graphs, which is\nclosely related to preorder traversal of a tree. Recall that\npreorder traversal simply visits each node before its children. It\nis most easy to program as a recursive routine: \n\n<pre>\n    preorder(node v)\n    {\n    visit(v);\n    for each child w of v\n        preorder(w);\n    }\n</pre>\n\nTo turn this into a graph traversal algorithm, we basically replace\n\"child\" by \"neighbor\". But to prevent infinite loops, we only want\nto visit each vertex once. Just like in BFS we can use marks to\nkeep track of the vertices that have already been visited, and not\nvisit them again. Also, just like in BFS, we can use this search to\nbuild a spanning tree with certain useful properties. \n\n<pre>\n    dfs(vertex v)\n    {\n    visit(v);\n    for each neighbor w of v\n        if w is unvisited\n        {\n        dfs(w);\n        add edge vw to tree T\n        }\n    }\n</pre>\n\nThe overall depth first search algorithm then simply initializes a\nset of markers so we can tell which vertices are visited, chooses a\nstarting vertex x, initializes tree T to x, and calls dfs(x). Just\nlike in breadth first search, if a vertex has several neighbors it\nwould be equally correct to go through them in any order. I didn't\nsimply say \"for each unvisited neighbor of v\" because it is very\nimportant to delay the test for whether a vertex is visited until\nthe recursive calls for previous neighbors are finished. \n\n<p><a name=\"dfstree\">The proof that this produces a spanning tree\n(the <i>depth first search tree</i>) is essentially the same as\nthat for BFS, so I won't repeat it. However while the BFS tree is\ntypically \"short and bushy\", the DFS tree is typically \"long and\nstringy\".</a></p>\n\n<p>Just like we did for BFS, we can use DFS to classify the edges\nof G into types. Either an edge vw is in the DFS tree itself, v is\nan ancestor of w, or w is an ancestor of v. (These last two cases\nshould be thought of as a single type, since they only differ by\nwhat order we look at the vertices in.) What this means is that if\nv and w are in different subtrees of v, we can't have an edge from\nv to w. This is because if such an edge existed and (say) v were\nvisited first, then the only way we would avoid adding vw to the\nDFS tree would be if w were visited during one of the recursive\ncalls from v, but then v would be an ancestor of w.</p>\n\n<p>As an example of why this property might be useful, let's prove\nthe following fact: in any graph G, either G has some path of\nlength at least k. or G has O(kn) edges.</p>\n\n<p>Proof: look at the longest path in the DFS tree. If it has\nlength at least k, we're done. Otherwise, since each edge connects\nan ancestor and a descendant, we can bound the number of edges by\ncounting the total number of ancestors of each descendant, but if\nthe longest path is shorter than k, each descendant has at most k-1\nancestors. So there can be at most (k-1)n edges.</p>\n\n<p>This fact can be used as part of an algorithm for finding long\npaths in G, another subgraph isomorphism problem closely related to\nthe traveling salesman problem. If k is a small constant (like say\n5) you can find paths of length k in linear time (measured as a\nfunction of n). But measured as a function of k, the time is\nexponential, which isn't surprising because this problem is closely\nrelated to the <a href=\"960206.html#tsp\">traveling salesman\nproblem</a>. For more on this particular problem, see Michael R.\nFellows and Michael A. Langston, \"On search, decision and the\nefficiency of polynomial-time algorithms\", 21st ACM Symp. Theory of\nComputing, 1989, pp. 501-512.</p>\n\n<h2>Relation between BFS and DFS</h2>\n\nIt may not be clear from the pseudo-code above, but BFS and DFS are\nvery closely related to each other. (In fact in class I tried to\ndescribe a search in which I modified the \"add to end of list\" line\nin the BFS pseudocode to \"add to start of list\" but the resulting\ntraversal algorithm was not the same as DFS.) \n\n<p>With a little care it is possible to make BFS and DFS look\nalmost the same as each other (as similar as, say, <a href= \n\"960206.html#prim\">Prim's</a> and <a href=\"960208.html#dijkstra\">\nDijkstra's</a> algorithms are to each other):</p>\n\n<pre>\n    bfs(G)\n    {\n    list L = empty\n    tree T = empty\n    choose a starting vertex x\n    search(x)\n    while(L nonempty)\n        remove edge (v,w) from start of L\n        if w not yet visited\n        {\n        add (v,w) to T\n        search(w)\n        }\n    }\n\n    dfs(G)\n    {\n    list L = empty\n    tree T = empty\n    choose a starting vertex x\n    search(x)\n    while(L nonempty)\n        remove edge (v,w) from end of L\n        if w not yet visited\n        {\n        add (v,w) to T\n        search(w)\n        }\n    }\n\n    search(vertex v)\n    {\n    visit(v);\n    for each edge (v,w)\n        add edge (v,w) to end of L\n    }\n</pre>\n\n<a name=\"stack\">Both of these search algorithms now keep a list of\nedges to explore; the only difference between the two is that,\nwhile both algorithms adds items to the end of L, BFS removes them\nfrom the beginning, which results in maintaining the list as a\nqueue, while DFS removes them from the end, maintaining the list as\na stack.</a> \n\n<h2>BFS and DFS in directed graphs</h2>\n\nAlthough we have discussed them for undirected graphs, the same\nsearch routines work essentially unmodified for directed graphs.\nThe only difference is that when exploring a vertex v, we only want\nto look at edges (v,w) going out of v; we ignore the other edges\ncoming into v. \n\n<p>For directed graphs, too, we can prove nice properties of the\nBFS and DFS tree that help to classify the edges of the graph. For\nBFS in directed graphs, each edge of the graph either connects two\nvertices at the same level, goes down exactly one level, or goes up\nany number of levels. For DFS, each edge either connects an\nancestor to a descendant, a descendant to an ancestor, or one node\nto a node in a previously visited subtree. It is not possible to\nget \"forward edges\" connecting a node to a subtree visited later\nthan that node. We'll use this property next time to test if a\ndirected graph is strongly connected (every vertex can reach every\nother one).</p>\n\n<hr>\n<p><a href=\"/~eppstein/161/\">ICS 161</a> -- <a href=\"/\">Dept.\nInformation &amp; Computer Science</a> -- <a href= \n\"http://www.uci.edu/\">UC Irvine</a><br>\n<small>Last update: \n<!--#flastmod file=\"960215.html\" --></small></p>\n</body>\n</html>\n\n", "id": 13550.0}