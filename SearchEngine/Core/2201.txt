{"text": " Local Distance Functions A Taxonomy New Aglorithms and an Evaluation We present a taxonomy for local distance functions where most existing algorithms can be regarded as approximations of the geodesic distance defined by a metric tensor We categorize existing algorithms by how where and when they estimate the metric tensor We also extend the taxonomy along each axis How We introduce hybrid algorithms that use a combination of techniques to ameliorate over fitting Where We present an exact polynomial time algorithm to integrate the metric tensor along the lines between the test and training points under the assumption that the metric tensor is piecewise constant When We propose an interpolation algorithm where the metric tensor is sampled at a number of references points during the offline phase The reference points are then interpolated during the online classification phase We also present a comprehensive evaluation on tasks in face recognition object recognition and digit recognition D Ramanan S Baker Local Distance Functions A Taxonomy New Algorithms and an Evaluation International Conference on Computer Vision ICCV Kyoto Japan Sept 2 9 PDF Supplementary Results References for datasets and feature vector construction MultiPIE Data Caltech 1 1 Data MNIST Data Readme To allow comparisons with our work we are making computed feature vectors class membership data and training test partitions of our experimental evaluation available in the above links We gladly acknowledge the original authors of the above datasets Gross et al Fei Fei at al and Lecun and Cortes We also gladly acknowledge Killian Weibgerger for providing code for Large Margin Nearest Neighbors LMNN and Svetlana Lazebnik for providing code for spatial pyramid kernels ", "_id": "http://www.ics.uci.edu/~dramanan/localdist/", "title": "local distance functions: a taxonomy, new algorithms, and an evaluation", "html": "<html>\n<head>\n<title>Local Distance Functions: A Taxonomy, New Algorithms, and an Evaluation</title>\n</head>\n<style type=\"text/css\">\nA:link {text-decoration: none}\nA:visited {text-decoration: none}\nA:active {text-decoration: none}\nA:hover {text-decoration: underline}\ntr {border:0px}\nimg.pub {height:200px;border:0px}\np.link {font-weight:bold;font-size:small;text-align:center;white-space:pre}\ntable.pub {width: 800px; border=0;cellpadding: 5}\ntd.pic {text-align: right; vertical-align:top}\ntd.pub {width: 600px; vertical-align:bottom}\np.abs {font-size:small}\nspan.h2 {font-size:x-large; font-weight:bold}\nspan.h3 {font-size:large; font-weight:bold}\nspan.h3red {font-size:large; color:red}\nspan.h4 {font-style:italic; font-weight:bold} \n</style>\n\n<body bgcolor=white>\n<div align=center>\n<h1 align=\"center\"> \"Local Distance Functions: A Taxonomy, New Aglorithms, and an Evaluation</h1>\n\n<table class=\"pub\">\n\n<tr>\n<td class=\"pic\"><a href=\"../papers/localdist.pdf\"><img class=\"pub\" alt=\"paper\" src=\"cover.gif\"></a>\n\n<td class=\"pub\"> <p class=\"abs\"> We present a taxonomy for local distance functions where most existing algorithms can be regarded as approximations of the geodesic distance defined by a metric tensor. We categorize existing algorithms by <b>how</b>, <b>where</b>, and <b>when</b> they estimate the metric tensor. We also extend the taxonomy along each axis. <b>How</b>: We introduce hybrid algorithms that use a combination of techniques to ameliorate over-fitting. <b>Where</b>: We present an exact polynomial time algorithm to integrate the metric tensor along the lines between the test and training points under the assumption that the metric tensor is piecewise constant. <b>When</b>: We propose an interpolation algorithm where the metric tensor is sampled at a number of references points during the offline phase. The reference points are then interpolated during the online classification phase. We also present a comprehensive evaluation on tasks in face recognition, object recognition, and digit recognition. </p>\n<br>\n<p> D. Ramanan, S. Baker. <b>\"Local Distance Functions: A Taxonomy, New Algorithms, and an Evaluation\"</b> <i> International Conference on Computer Vision </i>(ICCV) Kyoto, Japan, Sept. 2009.\n</table>\n<p class=\"link\"> <a href=\"../papers/localdist.pdf\">PDF</a>    <a href=\"supp/main.html\">Supplementary Results</a></p>\n\n<br>\n\n<h3> References for datasets and feature vector construction </h3>\n\n\n<img height=200px alt=\"Datasets\" src=\"db_shadow.jpg\">\n<p class=\"link\"><a href=\"multipie.mat\">MultiPIE Data</a>       <a href=\"caltech.mat\">Caltech 101 Data</a>       <a href=\"mnist.mat\">MNIST Data</a>       <a href=\"README.txt\">Readme</a> </p>\n\n<br>\n\n<table width=700px>\n<tr> <td> <br> To allow comparisons with our work, we are making computed feature vectors, class membership data, and training-test partitions of our experimental evaluation available in the above links. We gladly acknowledge the original authors of the above datasets  -  <a href=\"http://www.ralphgross.com/\">Gross et al.</a>, <a href=\"http://www.vision.caltech.edu/Image_Datasets/Caltech101/\">Fei-Fei at al.</a>, and <a href=\"http://yann.lecun.com/exdb/mnist/\">Lecun and Cortes</a>. We also gladly acknowledge Killian Weibgerger for providing code for Large Margin Nearest Neighbors <a href=\"http://www.weinbergerweb.net/Downloads/LMNN.html\">(LMNN)</a> and Svetlana Lazebnik for providing code for  <a href=\"http://www.cs.unc.edu/~lazebnik/research/spatial_pyramid_code.zip\">spatial pyramid kernels</a>. \n</table>\n\n</div>\n</body>\n</html>\n", "id": 2201.0}