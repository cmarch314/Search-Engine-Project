{"text": "ISGInformation Systems GroupBren School of ICSUC IrvineAboutNewsPeopleResearchPublicationsEventsCoursesPartnershipsVisitorsISG SeminarsInvited TalksUpcomingPastISG SeminarsRegular ISG seminar Time Every Fri afternoon 3pm 4pm Location Bren Hall 3 11 2 9 2 1 ISG Scalable Data Management Seminar Series talks Support for the ISG Seminar Series from Yahoo is gratefully acknowledged Invited Talks Upcoming Events Feb 2 2 15SPEAKER Karthik Ramasamy Twitter Real Time Analytics Twitter DetailsDate and TimeFeb 2 2 15 3 pmLocationDBH 3 11SpeakerKarthik Ramasamy Twitter Title Real Time Analytics Twitter AbstractReal time analytics seems to be a buzz word these days Twitter identified the need for real time analytics early on and invested in a massive data pipeline that collects aggregates processes large volumes of data in real time At the heart of the pipeline is Twitter Storm a real time stream processing engine widely used in Twitter Storm is used for real time data analytics time series aggregation and powering real time features like trending topics In this talk we will give an overview of real time analytics discuss the twitter real time data pipeline and how Storm is used for extracting analytics We will also discuss the challenges we faced and lessons we have learned while building this infrastructure at Twitter Speaker BioKarthik is the engineering manager and technical lead for Real Time Analytics at Twitter He has two decades of experience working in parallel databases big data infrastructure and networking He cofounded Locomatix a company that specializes in real timestreaming processing on Hadoop and Cassandra using SQL that was acquired by Twitter Before Locomatix he had a brief stint with Greenplum where he worked on parallel query scheduling Greenplum was eventually acquired by EMC for more than 3 M Prior to Greenplum Karthik was at Juniper Networks where he designed and delivered platforms protocols databases and high availability solutions for network routers that are widely deployed in the Internet Before joining Juniper at University of Wisconsin he worked extensively in parallel database systems query processing scale out technologies storage engine and online analytical systems Several of these research were spun as a company later acquired by Teradata He is the author of several publications patents and one of the best selling book Network Routing Algorithms Protocols and Architectures He has a Ph D in Computer Science from UW Madison with a focus on databases Feb 27 2 15SPEAKER Fatma Ozcan IBM Research Almaden SQL Comes Back But This is not Your Father s DBMS DetailsDate and TimeFeb 27 2 15 3 pmLocationDBH 3 11SpeakerFatma Ozcan IBM Research Almaden TitleSQL Comes Back But This is not Your Father s DBMS AbstractRecent years have seen the resurgence of SQL this time in the context of Big Data Platforms SQL on Hadoop was one of the hottest topics in 2 14 with many newcomers and adaptations of old systems There are significant differences between the new incarnation of SQL systems and the traditional enterprise warehouses First semi structured data is inherent in the Hadoop data as the data frequently comes from noSQL and web sources Hence JSON data and complex types are more important than in traditional systems Second SQL is only one of the steps in the bigger analytical flows This requires SQL to interact with other frameworks including streaming ETL as well as advanced analytics and machine learning Finally we see more user defined function in big data platforms because a lot of business logic needs to be executed closer to the data In this talk I will first describe IBM Big SQL an SQL on Hadoop offering that works on all Hadoop data formats I will describe how we adapted IBM database technology to this new world In the second part of the talk I will describe a couple of research projects in IBM Almaden that focus on new aspects of the Hadoop SQL engines and the big data eco system Speaker BioFatma zcan is a Research Staff Member and a manager at IBM Almaden Research Center Her current research focuses on platforms and infra structure for large scale data analysis Hadoop and database integration and query optimization for semi structured data Dr zcan got her PhD degree in computer science from University of Maryland College Park She has over 1 years of experience in semi structured and structured data management query processing and optimization and has delivered core technologies into IBM DB2 and BigInsights products She is the co author of the book Heterogeneous Agent Systems and co author of several conference papers and patents She has chaired program committees for various conferences and served on NSF National Science Foundation panels She is a member of the ACM Mar 6 2 15SPEAKER Raman Grover AsterixDB DetailsDate and TimeMar 6 2 15 3 pmLocationDBH 3 11SpeakerRaman Grover AsterixDB TitleAbstractSpeaker BioMar 13 2 15SPEAKER Lada Adamic David Kempe Mark Handcock Carter ButtsNetworks Algorithms Statistics and Social Science Data Science Initiative Sponsored Event DetailsDate and TimeMar 13 2 15 1 am 5pmLocationCalit2 AuditoriumSpeakerLada Adamic David Kempe Mark Handcock Carter ButtsTitleNetworks Algorithms Statistics and Social Science Data Science Initiative Sponsored Event AbstractSee http datascience uci edu event registration ee 14 for more detailsSpeaker BioApr 1 2 15SPEAKER Liuba Shrira Brandeis University Modular and efficient past state protocols for transactional systemsDetailsDate and TimeApr 1 2 15 3 pmLocationDBH 3 11SpeakerLiuba Shrira Brandeis University TitleModular and efficient past state protocols for transactional systemsAbstractThe remarkable drop in storage costs makes it possible and attractive to capture past application states and store them for a long time This opens the possibility that kinds of demanding analysis like forecasting formerly dependent on data warehouses and temporal databases can become available to everyday applications in off the shelf data stores The challenge is how to organize past states so that they are not in the way and always there when needed Our approach called Retro integrates a low level consistent snapshot system into a data store storage manager allowing to run unmodified data store programs against the snapshots side by side with programs running against the current state The approach is attractive for several reasons An application can take snapshots efficiently with any frequency keep them indefinitely or garbage collect them at low cost a useful feature in long lived systems A principled methodology derives the snapshot protocols from the native data store storage manager mechanisms allowing to implement the snapshot system in a modular way without extensive modifications to the data store internals making the approach suitable in off the shelf data stores The talk will describe the new techniques that underly Retro and present preliminary performance results from a prototype we built in Berkeley DB indicating Retro is efficient imposing moderate performance penalty on the native data store on expected common workloads Speaker BioLiuba Shrira is a Professor in the Computer Science Department at Brandeis University and is affiliated with the Computer Science and Artificial Intelligence Laboratory at MIT She received her Ph D from Technion Israeli Institute of Technology and has been affiliated with Microsoft Research Cambridge UK Microsoft Research Asia Beijing and Computer Science Department in the Technion Haifa Her research interests span aspects of design and implementation of distributed systems and especially storage systems This includes fault tolerance availability and performance issues Her recent focus is on long lived transactional storage time travel in storage software upgrades and support for collaborative access to long lived objects Apr 17 2 15SPEAKER Xifeng Yan UCSB DetailsDate and TimeApr 17 2 15 3 pmLocationDBH 3 11SpeakerXifeng Yan UCSB TitleAbstractSpeaker BioMay 1 2 15 Special Time Place SPEAKER C Mohan IBM Research Almaden DetailsDate and TimeMay 1 2 15 Special Time Place 11 amLocationDBH 6 11SpeakerC Mohan IBM Research Almaden TitleAbstractSpeaker BioMay 1 2 15SPEAKER C Mohan IBM Research Almaden DetailsDate and TimeMay 1 2 15 3 pmLocationDBH 3 11SpeakerC Mohan IBM Research Almaden TitleAbstractSpeaker BioMay 29 2 15 Special Time Place SPEAKER Michael Franklin UC Berkeley Computer ScienceBig Data Data Science and other Buzzwords that Really MatterDetailsDate and TimeMay 29 2 15 Special Time Place 11 amLocationDBH 6 11SpeakerMichael Franklin UC Berkeley Computer ScienceTitleBig Data Data Science and other Buzzwords that Really MatterAbstractData is all the rage across industry and across campuses While it may be temping to dismiss the buzz as just another spin of the hype cycle there are substantial shifts and realignments underway that are fundamentally changing how Computer Science Statistics and virtually all subject areas will be taught researched and perceived as disciplines In this talk I will give my personal perspectives on this new landscape based on experiences organizing a large industry engaged academic Computer Science research project the AMPLab in helping to establish a campus wide Data Science research initiative the Berkeley Institute for Data Science and my participation on a campus task force charged with mapping out Data Science Education for all undergraduates at Berkeley Speaker BioMichael Franklin is the Thomas M Siebel Professor of Computer Science and Chair of the Computer Science Division of the EECS Department at UC Berkeley He is director of the Berkeley AMPLab a 7 person effort fusing scalable computing machine learning and human computation to make sense of data at scale AMPLab software including Spark Shark and Mesos plays a significant role in the emerging Big Data ecosystem The lab is funded by an NSF CISE Expeditions Award the Darpa XData program and 26 companies including founding sponsors Amazon Web Services Google and SAP Jun 5 2 15SPEAKER Michael Carey UCI DetailsDate and TimeJun 5 2 15 3 pmLocationDBH 3 11SpeakerMichael Carey UCI TitleAbstractSpeaker Bio Past Events Feb 13 2 15SPEAKER Yannis Papakonstantinou UCSD The SQL Query Language Support for native JSON while backwards compatible with SQLDetailsDate and TimeFeb 13 2 15 3 pmLocationDBH 3 11SpeakerYannis Papakonstantinou UCSD TitleThe SQL Query Language Support for native JSON while backwards compatible with SQLAbstractSQL on Hadoop NewSQL and NoSQL databases provide semi structured data models typically JSON based They now drive towards declarative SQL alike query languages However their idiomatic non SQL language constructs the many variations and the lack of formal syntax and semantics pose problems Notably database vendors end up with unclear semantics and complicated implementations as they add one feature at a time The presented SQL semi structured data model bridges JSON and the SQL data model The SQL query language is backwards compatible with SQL while supporting native JSON SQL includes configuration options that describe different options of language semantics and formally capture the variations of existing database languages SQL is unifying By appropriate choices of configuration options the SQL semantics can morph into the semantics of any of eleven popular semistructured databases which we surveyed as the experimental validation shows In this way SQL allows a formal characterization of the capabilities of the emerging query languages We briefly discuss the key role of SQL and SQL Incremental View Maintenance in the FORWARD application and visualization development platform SQL also is the query language of the FORWARD middleware query processor We briefly discuss issues and opportunities in federated queries over SQL and non SQL database Speaker BioYannis Papakonstantinou is a Professor of Computer Science and Engineering at the University of California San Diego His research is in the intersection of data management technologies and the web where he has published over ninety research articles and received over 1 citations He has given multiple tutorials and invited talks has served on journal editorial boards and has chaired and participated in program committees for many international conferences and workshops He also teaches for UCSD s Master of Advanced Studies in Data Science Yannis enjoys to commercialize his research and to inform his research accordingly He was the CEO and Chief Scientist of Enosys Software which built and commercialized an early Enterprise Information Integration platform for structured and semistructured data which became part of BEA s Aqualogic His lab s recent FORWARD platform is in use by UCSD and commercial applications He is in the technical advisory board of Brightscope Inc and GraphSQL Inc Feb 6 2 15SPEAKER Ansgar ScherpExtraction and Analyses of Schema Information on the Linked Open Data CloudDetailsDate and TimeFeb 6 2 15 3 pmLocationDBH 3 11SpeakerAnsgar ScherpTitleExtraction and Analyses of Schema Information on the Linked Open Data CloudAbstractThe Linked Open Data LOD cloud interlinks information about entities from different data sources and across various domains using the Resource Description Framework RDF In contrast to traditional relational databases the LOD cloud does not provide a fixed pre defined schema Rather RDF allows for flexibly modeling the data schema by attaching RDF types to the entities and by using domain specific RDF properties to describe the entities The talk presents recent developments on the extraction and analysis of schema information from the LOD cloud For example with SchemEX we have developed an efficient approach and tool for a stream based extraction and indexing of schema information from Linked Open Data LOD at web scale The schema index provided by SchemEX can be used to locate distributed data sources in the LOD cloud The SchemEX approach is used in LODatio a Google inspired search engine designed for data engineers to find relevant sources of LOD Further analysis of schema structures on the LOD cloud include investigating the redundancy between type and property information use of vocabularies in pay level domains and change of schema information over weekly snapshots of a larger amount of LOD data The talk will conclude with current developments and future work Speaker BioAnsgar Scherp is a professor at the Leibniz Information Center for Economics and Kiel University Kiel GermanyJan 3 2 15SPEAKER Chris Jermaine Rice University Large Scale Machine Learning with the SimSQL SystemDetailsDate and TimeJan 3 2 15 3 pmLocationDBH 3 11SpeakerChris Jermaine Rice University TitleLarge Scale Machine Learning with the SimSQL SystemAbstractIn this talk I ll describe the SimSQL system which is a platform for writing and executing statistical codes over large data sets particularly for machine learning applications Codes that run on SimSQL can be written in a very high level declarative language called Buds A Buds program looks a lot like a mathematical specification of an algorithm and statistical codes written in Buds are often just a few lines long At its heart SimSQL is really a relational database system and like other relational systems SimSQL is designed to support data independence That is a single declarative code for a particular statistical inference problem can be used regardless of data set size compute hardware and physical data storage and distribution across machines One concern is that a platform supporting data independence will not perform well But we ve done extensive experimentation and have found that SimSQL performs as well as other competitive platforms that support writing and executing machine learning codes for large data sets Speaker BioChris Jermaine is an associate professor of computer science at Rice University He is the recipient of an Alfred P Sloan Foundation Research Fellowship a National Science Foundation CAREER award and an ACM SIGMOD Best Paper Award In his spare time Chris enjoys outdoor activities such as hiking climbing and whitewater boating In one particular exploit Chris and his wife floated a whitewater raft home made from scratch using a sewing machine glue and plastic over 1 miles down the Nizina River and beyond in Alaska Jan 16 2 15SPEAKER Ryan Compton Howard Hughes Research Laboratories Geotagging One Hundred Million Twitter Accounts with Total Variation Minimization DetailsDate and TimeJan 16 2 15 3 pmLocationDBH 3 11SpeakerRyan Compton Howard Hughes Research Laboratories TitleGeotagging One Hundred Million Twitter Accounts with Total Variation Minimization Abstract Geographically annotated social media is extremely valuable for modern information retrieval However when researchers can only access publicly visible data one quickly finds that social media users rarely publish location information In this work we provide a method which can geolocate the overwhelming majority of active Twitter users independent of their location sharing preferences using only publicly visible Twitter data Our method infers an unknown user s location by examining their friend s locations We frame the geotagging problem as an optimization over a social network with a total variation based objective and provide a scalable and distributed algorithm for its solution Furthermore we show how a robust estimate of the geographic dispersion of each user s ego network can be used as a per user accuracy measure allowing us to discard poor location inferences and control the overall error of our approach Leave many out evaluation shows that our method is able to infer location for 1 1 846 236 Twitter users at a median error of 6 38 km allowing us to geotag over 8 of public tweets http arxiv org abs 14 4 7152Speaker Bio Ryan Compton is postdoc in the Information and System Sciences Laboratory at Howard Hughes Research Laboratories in Malibu CA His work focuses on social media data mining for early detection of newsworthy events In 2 12 Ryan finished a mathematics PhD at UCLA with a thesis on sparsity promoting optimization for quantum mechanical signal processing His website is http www ryancompton net Dec 12 2 14SPEAKER Heri Ramampia Norwegian University of Science and Technology Boosting Event Related Image Retrieval with Spatiotemporal Distribution of Tag Terms DetailsDate and TimeDec 12 2 14 3 pmLocationDBH 3 11SpeakerHeri Ramampia Norwegian University of Science and Technology TitleBoosting Event Related Image Retrieval with Spatiotemporal Distribution of Tag Terms AbstractMedia sharing applications such as Flickr and Panoramio contain a large amount of pictures related to real life events For this reason although still being a challenging task the development of effective methods to retrieve these pictures is important Recognizing this importance and to improve the retrieval effectiveness of tag based event retrieval systems we have proposed a new effective method to extract a set of geographical tag features from raw geo spatial profiles of user tags The main idea is to use these features to select the best expansion terms in a machine learning based query expansion approach Specifically we apply rigorous statistical exploratory analysis of spatial point patterns to extract the geo spatial features Then we used the features both to summarize the spatial characteristics of the spatial distribution of a single term and to determine the similarity between the spatial profiles of two terms i e term to term spatial similarity To further improve our image retrieval approach we investigated the effect of combining our geo spatial features with temporal features In this presentation I will try to give an overview of the methods we used 1 to extract the spatio temporal featrues from image tags and 2 how to use these features to improve the retrieval performance focusing on retrieval of event related images Finally I will discuss the results from our experiments and show how our method has improved the state of the art approach Speaker BioHeri Ramampiaro is an Associate Professor at the Dept of Computer and Information Science Norwegian University of Science and Technology NTNU He is Head of the Data and Information Management group His main research interests include Information Retrieval BigData Information Extraction Text Mining Bioinformatics and Health Informatics Ramampiaro is currently on a one year research sabbatical visiting the ISG group UC Irvine Dec 5 2 14SPEAKER Daniel Wood DELL Dell and Big Data Software Data replication and ReorganizationDetailsDate and TimeDec 5 2 14 3 pmLocationDBH 3 11SpeakerDaniel Wood DELL TitleDell and Big Data Software Data replication and ReorganizationAbstractThe role of an enterprise independent software vendor ISV is to develop tools and technologies that support the information systems of their customers Customers cannot easily switch technologies or adapt them to their needs without causing disruptions to their business This is where software vendors are able to help I will discuss how an ISV like Quest managed to go from startup to acquisition and the details of two of the relevant enterprise technologies The first technology database replication has become critical in scaling many of the household names we know We will explore this technology and its evolution from homogeneous database replication to heterogeneous database replication that includes Oracle SQL Server and Hadoop systems The second technology data reorganization is crucial to curbing storage hungry databases and improving database performance by defragmenting data Speaker BioDaniel Wood is a manager of software development inside Dell Software Group Formerly Quest Software where he has worked for 13 years Daniel focuses on database management tools and problems at scale Daniel holds a BA in physics from University of California Santa Barbara Nov 21 2 14 Special Time Place SPEAKER Prof Wei Wang UCLA Big Data Analytics in ScienceDetailsDate and TimeNov 21 2 14 Special Time Place 11 amLocationDBH 6 11SpeakerProf Wei Wang UCLA TitleBig Data Analytics in ScienceAbstractBig data analytics is the process of examining large amounts of data of a variety of types big data to uncover hidden patterns unknown correlations and other useful information Its revolutionary potential is now universally recognized Data complexity heterogeneity scale and timeliness make data analysis a clear bottleneck in many biomedical applications due to the complexity of the patterns and lack of scalability of the underlying algorithms Advanced machine learning and data mining algorithms are being developed to address one or more challenges listed above It is typical that the complexity of potential patterns may grow exponentially with respect to the data complexity and so is the size of the pattern space To avoid an exhaustive search through the pattern space machine learning and data mining algorithms usually employ a greedy approach to search for a local optimum in the solution space or use a branch and bound approach to seek optimal solutions and consequently are often implemented as iterative or recursive procedures To improve efficiency these algorithms often exploit the dependencies between potential patterns to maximize in memory computation and or leverage special hardware for acceleration In this talk I will present some open challenges faced by data scientist in biomedical fields and our approaches to tackle these challenges through examples such as multi locus QTL analysis and transcriptome quantification using RNAseq data Speaker BioWei Wang is a professor in the Department of Computer Science at University of California at Los Angeles and the director of the Scalable Analytics Institute ScAi She is a member of the UCLA Jonsson Comprehensive Cancer Center She received her PhD degree in Computer Science from the University of California at Los Angeles in 1999 Before she rejoined UCLA she was a professor in Computer Science and a member of the Carolina Center for Genomic Sciences and Lineberger Comprehensive Cancer Center at the University of North Carolina at Chapel Hill from 2 2 to 2 12 and was a research staff member at the IBM T J Watson Research Center between 1999 and 2 2 Dr Wang s research interests include big data data mining bioinformatics and computational biology and databases Nov 18 2 14 Special Time Place SPEAKER Hwanjo Yu Associate Professor POSTECH Pohang University of Science and Technology Search and Mining for Big DataDetailsDate and TimeNov 18 2 14 Special Time Place 4 pmLocationDBH 3 11SpeakerHwanjo Yu Associate Professor POSTECH Pohang University of Science and Technology TitleSearch and Mining for Big DataAbstractBig data is recently defined by Gartner as high volume high velocity and or high variety information assets that require new forms of processing to enable enhanced decision making insight discovery and process optimization In this talk we first present key challenges in Big data programming that are distinct from conventional parallel processing After that we introduce several research projects dealing with large volume of data in the data mining lab at POSTECH that are PubMed relevance feedback search engine blackbox video search novel recommendation and timing when to recommend Speaker Bio Hwanjo Yu received his PhD in Computer Science at the University of Illinois at Urbana Champaign at June 2 4 under the supervision of Prof Jiawei Han From July 2 4 to January 2 8 he had been an assistant professor at the University of Iowa He is now an associate professor at POSTECH Pohang University of Science and Technology He developed influential algorithms and systems in the areas of data mining database and machine learning including 1 algorithms for classifying without negative examples PEBL SVMC 2 privacy preserving SVM algorithms 3 SVM JAVA an educational java open source for SVM 4 RefMed relevance feedback search engine for PubMed 5 TurboGraph a fast parallel graph engine handling billion scale graphs in a single PC His methods and algorithms were published in prestigious journals and conferences including ACM SIGMOD ACM SIGKDD IEEE ICDE IEEE ICDM ACM CIKM etc where he is also serving as a program committee Nov 14 2 14SPEAKER Dr Jiannan Wang UC Berkeley SampleClean Fast and Accurate Query Processing on Dirty DataDetailsDate and TimeNov 14 2 14 3 pmLocationDBH 3 11SpeakerDr Jiannan Wang UC Berkeley TitleSampleClean Fast and Accurate Query Processing on Dirty DataAbstractThe vision of AMPLab is to integrate Algorithms Machine Learning Machines Cloud Computing and People Crowdsourcing to make sense of Big Data In the past several years the lab has developed a variety of open source software e g Spark and MLBase to integrate the three resources For the People part one of our main focuses is on data cleaning Real world data is often dirty Data cleaning is usually a tedious and time consuming process which requires a lot of human work In the AMPLab we have exploited the use of crowdsourcing to reduce the human cost While crowdsourcing makes data cleaning more scalable it is still highly inefficient for large datasets To overcome this limitation we started the SampleClean project last year The project aims to investigate how to obtain accurate query results from dirty data by only cleaning a small sample of the data We achieved this goal by marrying data cleaning with sampling based approximate query processing and addressing many challenging statistical issues We build a new system that combines our work on crowdsourcing data cleaning and SampleClean query processing An initial version of the system has shown that our system can help users to obtain very accurate query results on dirty data at significantly reduced cleaning cost Speaker BioJiannan Wang is a postdoc in the AMPLab at UC Berkeley where he works with Prof Michael Franklin and leads the SampleClean project His research is focusing on developing algorithms and systems for extracting value from dirty data He obtained his PhD from the Computer Science Department at Tsinghua University During his PhD he has been a visiting scholar at Chinese University of Hong Kong and UC Berkeley and an intern at Qatar Computing Research Institute His PhD research work was supported by Google PhD Fellowship Boeing Scholarship and New PhD Researcher Award by Chinese Ministry of Education His PhD dissertation has won the China Computer Federation CCF Distinguished Dissertation Award His similarity join algorithm has won the first place of EDBT String Similarity Search Join Competition Nov 7 2 14SPEAKER Prof Shahram Ghandeharizadeh USC BG A Benchmark for Interactive Social Networking ActionsDetailsDate and TimeNov 7 2 14 3 pmLocationDBH 3 11SpeakerProf Shahram Ghandeharizadeh USC TitleBG A Benchmark for Interactive Social Networking ActionsAbstractBG is a benchmark for interactive social networking actions also known as simple or small data operations It is motivated by the flurry of novel data store designs ranging from SQL to NoSQL and NewSQL Cache Augmented SQL graph databases and others More than 4 data stores have been introduced in the past decade including systems contributed by the social networking sites e g Cassandra by Facebook and Voldemort by LinkedIn Some systems sacrifice strict ACID Atomicity Consistency Isolation Durability properties and opt for BASE Basically Available Soft state Eventual Consistency to enhance performance BG strives to compare these systems with one another quantitatively This presentation details the design of BG and its SoAR metric to rate data stores We describe how BG quantifies the amount of unpredictable stale erroneous or inconsistent data produced by a data store We present ratings from an industrial strength relational database management system a document store named MongoDB a graph data store named Neo4j and an extensible data store named HBase We show the use of SoAR to evaluate both vertical and horizontal scalability of MongoDB and HBase We also describe the use of BG to evaluate novel cache replacement algorithms such as CAMP and consistency frameworks such as IQ We conclude with the use of BG to demonstrate a novel SQL middleware named KOSAR BG is joint work with Sumita Barahmand Visit http bgbenchmark org to download BG Speaker Bio Shahram Ghandeharizadeh received his Ph D degree in Computer Science from the University of Wisconsin Madison in 199 Since then he has been on the faculty at the University of Southern California In 1992 he received the National Science Foundation Young Investigator s Award for his research on the physical design of parallel database systems In 1995 he received an award from the School of Engineering at USC in recognition of his research activities He was a recipient of the ACM Software System Award 2 8 His primary motivation for developing BG is today s proliferation of many data stores and a scarcity of benchmarks to substantiate their claims Oct 3 2 14 Special Day Time SPEAKER Dr David Lomet MSR Achieving Ridiculously High TPSDetailsDate and TimeOct 3 2 14 Special Day Time 4 5 pmLocationDBH 3 11SpeakerDr David Lomet MSR TitleAchieving Ridiculously High TPSAbstractThe Deuteronomy architecture provides a clean separation of transaction functionality performed in a transaction component or TC from data management functionality performed in a data component or DC In prior work we implemented both a TC and DC that achieved modest performance We recently built a high performance DC the Bw tree key value store that achieves very high performance on modern hardware via latch free and log structuring techniques and is currently shipping as an indexing and storage layer in Microsoft systems such as Hekaton and DocumentDB The new DC executes operations more than 1 x faster than the TC we previously implemented This talk describes how we achieved two orders of magnitude speedup in TC performance and shows that a full Deuteronomy stack can achieve very high performance overall We built the TC using techniques analogous to the Bw tree latch free data structures log structuring The TC uses multi version concurrency control MVCC to improve concurrency and performance Our new prototype TC scales to 32 cores on our 4 socket NUMA machine and commits more than a million of transactions per second for a variety of workloads Speaker BioDavid Lomet has been a principal researcher and manager of the Database Group at Microsoft Research Redmond since 1995 Before that he was at Digital Equipment Corporation mainly at Cambridge Research Lab Earlier he was a research staff member at IBM Research in Yorktown and subsequently a Professor at Wang Institute Lomet spent a sabbatical at Newcastle University working with Brian Randell He is best known for his work in database systems and is one of the inventors of the transaction concept His database work has focused on access methods concurrency control and recovery His recent Bw tree work is part of Microsoft s Hekaton main memory database system He has published over 1 papers including two SIGMOD best paper awards and has over 4 patents Lomet has served on many PCs including SIGMOD VLDB and ICDE He has been ICDE 2 PC co chair VLDB 2 6 Core Track Chair and ICDE 2 1 conference co chair Lomet has been editor in chief of the Data Engineering Bulletin since 1992 and won the 2 11 SIGMOD Contributions Award for this He has also been an editor of ACM TODS and the VLDB Journal has served on the VLDB Endowment Board and ICDE Steering Committee and has been Chair of the IEEE TC on Data Engineering Dr Lomet is a Fellow of AAAS ACM and IEEE Oct 24 2 14 Special Time Place SPEAKER Prof Padhraic Smyth and othersUCI Data Science Kickoff MeetingDetailsDate and TimeOct 24 2 14 Special Time Place 1 3 5 PM with reception to follow LocationCalIIT2 AuditoriumSpeakerProf Padhraic Smyth and othersTitleUCI Data Science Kickoff MeetingAbstractThis will be the official kickoff event for a new UCI campus wide Data Sciences Initiative Come hear about the Initiative as well as efforts related to Data Sciences from across the campus The afternoon s program will be followed by a reception at 5 PM This event is open to anyone everyone who is interested A detailed agenda for this afternoon event can be found hanging here http datascience uci edu Speaker Bio Oct 17 2 14SPEAKER Mark Callaghan Facebook Still Doing It WrongDetailsDate and TimeOct 17 2 14 3 pmLocationDBH 3 11SpeakerMark Callaghan Facebook TitleStill Doing It WrongAbstractFamous people have interesting things to say about my work and my fate I hope to provide more context on doing small data per request e g OLTP at scale I will start with a short history of web scale MySQL from 2 5 until today and predict where it is heading in the next 5 years My current work is to improve storage efficiency for small data per request workloads Algorithms tend to be fixed in their behavior while both workloads and storage device performance vary There is thus an opportunity to improve efficiency by making algorithms more dynamic Speaker BioMark Callaghan has worked with great teams to make MySQL better for scale out deployments at Facebook and Google for 9 years His current focus at Facebook is the analysis and improvement of database algorithms and storage systems for small data OLTP workloads He also works with WebScaleSQL and RocksDB to make MySQL and MongoDB better Prior to his web scale work Mark spent many years working on RDBMS internals at Oracle and Informix He invented and implemented a very fast general purpose sort algorithm for the Oracle RDBMS He has an MS in CS from UW Madison Oct 1 2 14SPEAKER Prof Jimeng Sun Georgia Institute of Technology Do it Once Do it Right Building a Scalable Predictive Modeling Platform for Healthcare Applications DetailsDate and TimeOct 1 2 14 3 pmLocationDBH 3 11SpeakerProf Jimeng Sun Georgia Institute of Technology TitleDo it Once Do it Right Building a Scalable Predictive Modeling Platform for Healthcare Applications Abstract Predictive models are designed to predict the likelihood of one or more outcomes and are playing an increasing important role in biomedical research Thanks to the explosion of Electronic Heart Records EHR the interest in building predictive models based on EHR data has skyrocketed in recent years There are some major challenges that remain to be addressed In this talk I will explore two of them Effective algorithms are lacking in dealing with high dimensional longitudinal sparse inaccurate and inconsistent EHR data The methodologies to develop predictive models are still labor intensive and ad hoc These rudimentary approaches are hindering the quality and throughput of healthcare and biomedical research In this talk we promote a holistic approach that addresses both challenges by combining 1 algorithm development and 2 system building We believe that a more robust and domain specific big data platform could significantly speedup the development of robust and accurate predictive models for biomedical research I will present different projects covering both aspects of such a platform Algorithms I will first describe our work on computational phenotyping from EHR data using sparse tensor factorization then I will present a patient similarity method using supervised distance metric learning System I will introduce a parallel predictive modeling platform using Hadoop for enabling large scale modeling and exploration of big healthcare dataSpeaker BioJimeng Sun is an Associate Professor of School of Computational Science and Engineering at College of Computing in Georgia Institute of Technology Prior to joining Georgia Tech he was a research staff member at IBM TJ Watson Research Center His research focuses on health analytics using electronic health records and data mining especially in designing novel tensor analysis and similarity learning methods and developing large scale predictive modeling systems Dr Sun has worked on various healthcare applications such as computational phenotyping from electronic health records heart failure onset prediction and hypertension control management He has collaborated with many healthcare institutions including Vanderbilt university medical center Children s healthcare of Atlanta Center for Disease Control and Prevention CDC Geisinger Health System and Sutter Health He has published over 7 papers filed over 2 patents 5 granted He has received ICDM best research paper award in 2 8 SDM best research paper award in 2 7 and KDD Dissertation runner up award in 2 8 Dr Sun received his B S and M Phil in Computer Science from Hong Kong University of Science and Technology in 2 2 and 2 3 and a PhD in Computer Science from Carnegie Mellon University in 2 7 Oct 3 2 14SPEAKER ISG Faculty2 14 15 ISG Welcome Back SeminarDetailsDate and TimeOct 3 2 14 3 pmLocationDBH 3 11SpeakerISG FacultyTitle2 14 15 ISG Welcome Back SeminarAbstractSpeaker Bio May 3 2 14SPEAKER No SeminarDetailsDate and TimeMay 3 2 14 11 pmLocationDBH 6 11Speaker TitleNo SeminarAbstractGo to CS Colloquium for Ed Lazowska s Big Data talk Speaker Bio May 23 2 14SPEAKER Odej Kao TU Berlin Dynamic Scheduling and Resource Management for Big DataDetailsDate and TimeMay 23 2 14 3 pmLocationDBH 3 11SpeakerOdej Kao TU Berlin TitleDynamic Scheduling and Resource Management for Big DataAbstract Speaker Bio May 16 2 14SPEAKER Daniel Ford Dell Research The Unintended Consequences of The Internet of ThingsDetailsDate and TimeMay 16 2 14 3 pmLocationDBH 3 11SpeakerDaniel Ford Dell Research Title The Unintended Consequences of The Internet of ThingsAbstract Computer technology is subject to rapid change and evolution Each new development seems to be subject to exuberant hyperbole The latest round is focusing on embedded electronics and is called The Internet of Things or just The IoT The main force powering this hype machine is the suggestion of vast new commercial opportunities estimated by some sources to be in the range of 19 Trillion This talk begins with the conclusion that the hype about The Internet of Things is underplayed and that the commercial implications of The Internet of Things are the smallest parts of a bigger story It compares The IoT to other historical technological developments examining what is similar and what is without historical precedent In particular it finds the impact of applications of The Internet of Things to be spectacularly unconstrained All this leads to the idiom Careful what you wish for So while commerce is wishing for a 19 Trillion market our society and our economy are going to get something else The talk concludes with an examination of some of the potential unintended consequences of The Internet of Things It predicts that areas as diverse as Brand Management Advertising Propaganda Healthcare Law Enforcement Insurance Automobile ownership Politics and Warfare to name just a few will all be affected in ways few are considering Speaker BioDr Ford is Executive Director and Chief Scientist for Mobility and The Internet of Things for Dell Research in San Jose California Prior to joining Dell Research Dr Ford was CEO and co founder of Paupt Labs LLC in New York He also was with IBM Research in a variety of positions for nineteen years before that His immediate research interests are focused on The Internet of Things including supporting software architectures novel applications and unintended consequences Previous research interests have included Healthcare Informatics Pandemic Modeling Social Networking Mobile Computing Web Search and High Performance Tertiary Storage Systems Dr Ford has twenty eight issued US patents and dozens of peer reviewed publications Dr Ford earned his Ph D in Computer Science from the University of Waterloo in 1992 May 9 2 14SPEAKER Vinayak Borkar UC Irvine An Efficient Platform for Parallel Data Processing on Large ClustersDetailsDate and TimeMay 9 2 14 3 pmLocationDBH 3 11SpeakerVinayak Borkar UC Irvine TitleAn Efficient Platform for Parallel Data Processing on Large ClustersAbstractThe growth of user activity on the Internet and the rise of social networks has led to an exponential growth of data Storage of this data and its subsequent analysis have posed significant challenges Unlike the business data that drove research and development of relational databases for the past several decades Web and Social data tend to have rich and varying structure making traditional database systems a poor choice for their management The astronomical size and semi structured nature of this new data has forced companies in the business of managing it to look for other cost effective solutions In 2 4 Google presented the MapReduce system as a way to harness the power of thousands of commodity machines to solve problems like building a search index over the entire World Wide Web in reasonable time at reasonable cost MapReduce turned out to be a useful tool for performing other parallel computations over large amounts of data while presenting a simple programming model to users Soon after the MapReduce paper the open source community created the Hadoop platform to resemble Google s MapReduce system Hadoop soon became a popular platform for processing large amounts of data using commodity computers In an effort to boost user productivity new declarative languages were designed and built to compile high level declarative queries down to Hadoop MapReduce programs making Hadoop the de facto runtime layer for large scale parallel data computation While widely used and popular today Hadoop was not intentionally designed to be a runtime layer for higher level declarative languages In this talk we explore an alternative to the Hadoop platform whose design is rooted in parallel database research from the 198 s and 199 s Hyracks is an efficient runtime platform that accepts data parallel jobs from users and from high level language compilers and executes them on a cluster of commodity machines We describe the design of Hyracks as well as salient aspects of its implementation Using Hyracks we study the trade offs involved in building an extensible and reusable set of runtime components for large scale data processing We show experimentally that Hyracks is a highly configurable platform and well suited for several different data processing tasks We do so via three different use cases executing queries expressed in high level declarative languages running actual Hadoop jobs using the Hadoop Compatibility Layer of Hyracks and finally running parallel graph computations using Pregelix an open source graph analytics platform that uses Hyracks and emulates Google s Pregel programming model for analyzing large graphs in parallel A number of new declarative parallel languages have been proposed for querying and analyzing very large data sets To aid with the construction of declarative parallel query compilers we propose an extensible algebraic framework called Algebricks Algebricks is a model agnostic compilation framework that provides the ability for a compiler to inject its own semantics in an extensible manner Algebricks includes a reusable and extensible set of logical and physical operators and a large set of general purpose rewrite rules useful to most query compilers We describe the implementation of three different language compilers AsterixDB for AQL Hivesterix for HiveQL and VXQuery for XQuery that use the Algebricks compiler framework to create parallel jobs to run on a Hyracks Cluster Speaker BioMay 2 2 14SPEAKER Dick Bulterman FXPAL Authoring Support for Social Media Interaction Understanding Compound Multimedia DependenciesDetailsDate and TimeMay 2 2 14 3 pmLocationDBH 3 11SpeakerDick Bulterman FXPAL TitleAuthoring Support for Social Media Interaction Understanding Compound Multimedia DependenciesAbstract Creating compelling multimedia content is a difficult task It involves not only the creative process of developing a compelling media based story but it also requires significant technical support for content editing and management This process is made more complex by an increased desire for media personalization the story you tell Mom about an event may be different than the version you d like to share with your friends It is also different from the version you d like to tell your own children 15 years after the event had taken place The makes media authoring a context and time sensitive problem No wonder most researchers analyze media instead of create it It is tempting to categorize multimedia authoring in terms of component areas media encoding media storage media access media transport media rendering and overall presentation composition and control Unfortunately this partitioning blurs the dependencies that exist among these component areas that ultimately determine the success of an authoring system Using the broad problem of social media interaction as an example this talk will consider the composite effects of creating and accessing and transporting and presenting rich media objects for use by non technical end users The talk will survey several approaches to describe and manage media interactions We will focus on the temporal modelling of context sensitive personalized interactions of complex collections of independent media objects Using the concepts of togetherness being employed in the EU s FP 7 project TA2 Together Anywhere Together Anytime we will follow the process of media capture profiling composition sharing and end user manipulation We will consider the promise of using automated tools and contrast this with the reality of letting real users manipulation presentation semantics in real time The talk will not present a closed form solution but will present a series of topics and problems that can stimulate the development of a new generation of systems to stimulate social media interaction Speaker Bio Dr Dick Bulterman is President of the FX Palo Alto Laboratory FXPAL and professor of computer science at the VU University in Amsterdam Before joining FXPAL in 2 13 he was a senior researcher at CWI in Amsterdam where he founded the Distributed Multimedia Languages and Interfaces group In 1999 he started Oratrix Development BV a CWI spin off company that transferred the group s SMIL based GRiNS software to many parts of the civilized world Prior to joining CWI in 1988 he was on the faculty of the Division of Engineering at Brown University where he was part of the Laboratory for Engineering Man Machine Systems Dr Bulterman received a Ph D in computer science from Brown University USA in 1982 In 2 13 he was awarded the ACM SIGMM Lifetime Technical Achievement Award He is a member of Sigma Xi the ACM and the IEEE April 18 2 14SPEAKER Pekka Kostamaa Teradata Big Data at Teradata Teradata Unified Data ArchitectureDetailsDate and TimeApril 18 2 14 3 pmLocationDBH 3 11SpeakerPekka Kostamaa Teradata TitleBig Data at Teradata Teradata Unified Data ArchitectureAbstract Unified Data Architecture UDA is Teradata s strategy and program for Big Data UDA combines three platforms in a unified architecture 1 Data Warehouse 2 Discovery Platform 3 Data Platform This talk will describe the architecture and present real customer use cases Speaker BioPekka Kostamaa is Senior Director of Product Management for the Teradata Database His team is responsible for the strategy and definition of new releases of Teradata from concept phase through development to delivery to customers Previously Pekka was the Vice President of Engineering and Big Data Lab for Teradata Aster and Director of Advanced Development and Enterprise Architecture for Teradata R and D He has several publications holds twenty patents with several pending and presented the Keynote Speech at the ICDE 2 11 conference and an Invited Talk at the 2 12 DOLAP Workshop He is a member of the UCLA Computer Science Advisory Boards March 14 2 14SPEAKER Christoph Freytag Humboldt U When to say NO to protect Privacy when answering QueriesDetailsDate and TimeMarch 14 2 14 3 pmLocationDBH 3 11SpeakerChristoph Freytag Humboldt U TitleWhen to say NO to protect Privacy when answering QueriesAbstractThis talk presents privacy concepts that keep the balance between utility and privacy when returning answers to a sequence of queries In particular we show how to model the increasing knowledge of an adversary resulting from the answers to queries by a sequence of bipartite graphs Those provide the foundation for deciding when a privacy breach occurs might occur and how to balance the need for accurate responses versus the right for privacy Examples demonstrate the intricacies of managing this trade off Speaker BioJohann Christoph Freytag is currently full professor for Databases and Information Systems DBIS at the Computer Science Department of the Humboldt Universit t zu Berlin Germany Before joining the department in 1994 he was a research staff member at the IBM Almaden Research Center 1985 1987 a researcher at the European Computer Industry Research Centre ECRC in Munich Germany 1987 1989 and the head of Digital s Database Technology Center also in Munich 199 1993 He holds a Ph D in Applied Mathematics Computer Science from Harvard University MA Prof Freytag s research interests include all aspects of query processing and query optimization in object relational database systems new developments in the database area such as semi structured data data quality databases and security privacy in database systems and applying database technology to applications such as GIS genomics and bioinformatics life science In the last years he received the IBM Faculty Award four times for collaborative work in the areas of databases middleware and bioinformatics life science He organized the VLDB conference in Berlin in 2 3 and was a member of the VLDB Endowment 2 1 2 7 and in the head of the German database interest group of the GI Fachbereich DBIS Gesellschaft fur Informatik March 7 2 14SPEAKER Michalis Petropoulos and Mohamed Soliman Pivotal Orca A Modular Query Optimizer Architecture for Big DataDetailsDate and TimeMarch 7 2 14 3 pmLocationDBH 3 11SpeakerMichalis Petropoulos and Mohamed Soliman Pivotal TitleOrca A Modular Query Optimizer Architecture for Big DataAbstractThe performance of analytical query processing in data management systems depends primarily on the capabilities of the system s query optimizer Increased data volumes and heightened interest in processing complex analytical queries have prompted Pivotal to build a new query optimizer In this talk we present the architecture of Orca the new query optimizer for all Pivotal data management products including Pivotal Greenplum Database and Pivotal HAWQ Orca is a comprehensive development uniting state of the art query optimization technology with own original research resulting in a modular and portable optimizer architecture In addition to describing the overall architecture we highlight several unique features and present performance comparisons against other systems Speaker Bio Michalis Petropoulos is managing the query processing team at Pivotal Inc His R and D team develops the query optimizer and executor for Pivotal s massively parallel and distributed data management products Pivotal Greenplum Database and Pivotal HAWQ Before that Michalis was an Assistant Professor in the Computer Science and Engineering Department at SUNY Buffalo from 2 6 to 2 1 He received his PhD in Computer Science from the University of California San Diego in 2 5 In 2 6 Michalis co authored a publication that was awarded an Honorable Mention as top 3 finalist in the SIGMOD 2 6 Best Paper Award competition In 2 1 he co authored a publication that received the Best Interdisciplinary Paper Award at the ACM Conference on Information and Knowledge Management CIKM Mohamed Soliman is a Staff 1 at Pivotal where he works on building massively distributed database systems for efficient support of data warehousing and analytics His work at Pivotal is mainly in the research and development of Orca a next generation query optimizer for Big Data Prior to that Mohamed has conducted graduate studies at University of Waterloo where he received his PhD in computer science in 2 1 on the topic of rank aware retrieval in probabilistic databases Feb 21 2 14SPEAKER Inci Cetindil UCI ISG DetailsDate and TimeFeb 21 2 14 3 pmLocationDBH 3 11Speaker Inci Cetindil UCI ISG Title Abstract Speaker Bio Feb 14 2 14SPEAKER Siripen Pongpaichet UCI ISG EventShopDetailsDate and TimeFeb 14 2 14 3 pmLocationDBH 3 11SpeakerSiripen Pongpaichet UCI ISG Title EventShopAbstract EventShop is a computational framework that has the ability to integrate and process streaming data from heterogeneous data sources Data from all data sources are first transformed into a Space Time Theme STT data model with a hierarchical extension of STT being used to handle data coming from sources that have different resolutions in space and or time Various types of spatio temporal operators can then be applied to recognize and predict actionable situations Appropriate actions recommendations can be sent to individuals based on their circumstances This talk will provide an overview of the EventShop project and the sorts of use cases it is intending to address Here is the link to our website http eventshop ics uci edu 8 8 sln Speaker Bio Siripen is a UCI CS Ph D student working in Ramesh Jain s EventShop group Feb 7 2 14SPEAKER Inci Cetindil UCI ISG Postponed due to illness DetailsDate and TimeFeb 7 2 14 3 pmLocationDBH 3 11Speaker Inci Cetindil UCI ISG Title Postponed due to illness Abstract Speaker Bio Jan 31 2 14 Special Location SPEAKER Padhraic Smyth UCI Statistical Machine Learning with Count Data Informatics Seminar DetailsDate and TimeJan 31 2 14 Special Location 3 pmLocationDBH 6 11 SpeakerPadhraic Smyth UCI TitleStatistical Machine Learning with Count Data Informatics Seminar Abstract Regular ISG Seminar attendees are encouraged to attend this week s very interesting Informatics Seminar we don t want to conflict with this talk Data represented in the form of sets of counts is easy to acquire and can be surprisingly useful in practice For example a simple way to represent a set of documents is as a bag of words where each document is represented just by the counts of words that occur in the document a representation that has been the basis for many successful applications of machine learning to text data In this talk we will review some important developments over the past 1 years in modeling data represented in the form of counts combining ideas from statistics and machine learning The talk will describe the general principles involved and then illustrate how these ideas can be applied to text documents email communications and social networks including recent work in my research group The talk will conclude with some speculative comments on future directions Speaker BioPadhraic Smyth is a Professor in the Department of Computer Science with a joint appointment in Statistics and Director of the Center for Machine Learning and Intelligent Systems at the University of California Irvine His research interests include machine learning data mining pattern recognition and applied statistics He received a first class honors degree in Electronic Engineering from University College Galway National University of Ireland in 1984 and the MSEE and PhD degrees from the Electrical Engineering Department at the California Institute of Technology in 1985 and 1988 respectively From 1988 to 1996 he was a Technical Group Leader at the Jet Propulsion Laboratory Pasadena and has been on the faculty at UC Irvine since 1996 Dr Smyth is an ACM Fellow a AAAI Fellow and recieved the ACM SIGKDD Innovation Award in 2 9 He is co author of two well known research texts in data mining Modeling the Internet and the Web Probabilistic Methods and Algorithms with Pierre Baldi and Paolo Frasconi in 2 3 and Principles of Data Mining MIT Press August 2 1 co authored with David Hand and Heikki Mannila He has served in editorial positions for journals such as the Journal of the American Statistical Association the IEEE Transactions on Knowledge and Data Engineering and the Journal of Machine Learning Research His research has been funded by a variety of government agencies such as NSF NIH ONR DARPA and DOE as well by companies such as Google IBM Microsoft and Yahoo In addition to his academic research he is also active in consulting working with companies such as Samsung Netflix eBay Oracle Microsoft Yahoo Nokia and ATT Jan 24 2 14SPEAKER Inna Giguere Data Architect Disney Interactive Media BI Web Analytics at the happiest place on earthDetailsDate and TimeJan 24 2 14 3 pmLocationDBH 3 11SpeakerInna Giguere Data Architect Disney Interactive Media BI TitleWeb Analytics at the happiest place on earthAbstract Business analytics requirements at Disney Interactive have pushed the limits of the Omniture reporting systems that has been used for the past decade into building an internal tracking and data warehouse solution Consequently we have built a data warehouse and enabled Video and Game Producers to fine tune new content in near real time as well as provide an exhaustive platform for Data Scientists to build recommendation systems The presentation will focus on current data pipeline architecture at Disney Interactive and cover specific steps and challenges I will discuss how we BI team were able to leverage Hadoop s map reduce processing capabilities and Vertica MPP engine to load data continuously from multiple sources However one of our biggest challenges remains handling memory intensive hash joins in Vertica without sacrificing performance Speaker BioInna Giguere is Data Architect at Disney Interactive Media Business Intelligence group For the last 2 years she has been leading the architecture design and implementation of the Analytics Data Warehouse utilizing Hadoop Vertica and Scribe technology Previously based out of San Francisco Bay Area and London Inna has 16 years on industry experience creating scalable Data Warehouse solutions with focus on DB performance optimization in transactional and reporting systems Her experience spans across technologies starting from COBOL DB2 to Oracle 8i 11g to SQL Server 2 5 2 12 to Vertica 6 1 working on datasets ranging from hundreds of megabytes to hundreds of terabytes She has earned MS in Statistics in 2 1 Jan 17 2 14SPEAKER Phillip Sheu Department of EECS Semantic Computing and ApplicationsDetailsDate and TimeJan 17 2 14 3 pmLocationDBH 3 11SpeakerPhillip Sheu Department of EECS TitleSemantic Computing and ApplicationsAbstract Semantic Computing SC is an emerging field that addresses computing technologies which allow users to search create manipulate and connect computational resources including data documents tools people agents devices etc based on semantics Semantic Computing includes the computing technologies e g artificial intelligence natural language software engineering data and knowledge engineering computer systems signal processing etc and their interactions that may be used to extract or process computational content and descriptions While some areas of Semantic Computing have appeared as pieces in different disciplines Semantic Computing glues these pieces together into an integrated theme with synergetic interactions It addresses not only the analysis and transformation of signals e g pixels words into useful information but also how such information can be accessed and used to synthesize new signals The National Science Foundation has approved the planning of an Industry University Cooperative Research Center I UCRC for Semantic Computing currently involving UCI UCSD and UCLA The missions of the I UCRC are to develop semantic technologies that may facilitate the transition of the Internet into its next generation and develop new business models to stimulate strengthen and grow the economy An important outcome of this I UCRC is a Semantic Problem Solving Network SPSN which is a public consortium of resources from all domains including data documents devices products services and people The resources are interconnected and integrated with a service oriented architecture and a semantic layer to help the public to solve general problems and professional users to solve domain specific problems e g finance IT health defense entertainment education manufacturing This talk will introduce Semantic Computing and its applications the operations of the I UCRC the architecture of the SPSN how companies and academic researchers can join or affiliate with the I UCRC and SPSN and how companies and academic researchers can benefit Speaker Bio Phillip C Y Sheu is a professor of EECS Computer Science and Biomedical Engineering at the University of California Irvine He received his B S degree in EE from National Taiwan University and MS and Ph D degrees in EECS from the University of California at Berkeley Dr Sheu s current research interests include semantic computing and complex biomedical systems He is a fellow of IEEE a founder of the IEEE Computer Society Technical Committee on Semantic Computing TCSEM IEEE International Conference on Semantic Computing ICSC International Journal of Semantic Computing IJSC the NSF I UCRC Industry University Cooperative Research Center for Semantic Computing ISC being planned and a main author of the book Semantic Computing SC eds P Sheu H Yu C V Ramamoorthy A Joshi and L A Zadeh IEEE and Wiley 2 1 Nov 15 2 13SPEAKER Jos A Blakeley Microsoft Corporation Microsoft SQL Server Parallel Data Warehouse Architecture OverviewDetailsDate and TimeNov 15 2 13 3 pmLocationDBH 3 11SpeakerJos A Blakeley Microsoft Corporation TitleMicrosoft SQL Server Parallel Data Warehouse Architecture OverviewAbstract In this talk I will present an architectural overview of the SQL Server Parallel Data Warehouse DBMS system PDW is a massively parallel processing share nothing scale out version of SQL Server for data warehouse and big data workloads The product is packaged as a database appliance built on industry standard hardware Speaker BioJos Blakeley is Partner Architect in the Modern Data Warehousing Unit of the Server and Tools Division at Microsoft where he contributes to the development of the SQL Server Parallel Data Warehouse PDW DBMS product Jos joined Microsoft in 1994 Some of his contributions at Microsoft include the development of the OLE DB data access interfaces the integration of the NET runtime with SQL Server 2 5 the extensibility features in SQL Server and the creation of the ADO NET Entity Framework in Visual Studio 2 8 Jos has authored many conference papers book chapters and journal articles on design aspects of relational and object database management systems and data access Jose has 2 patents awarded and 22 patents pending He became an ACM Fellow in 2 9 Before joining Microsoft Jos was a member of the technical staff with Texas Instruments where he was co principal investigator of the DARPA Open OODB system He received a B Eng from ITESM Monterrey Mexico and a Ph D in computer science from University of Waterloo Canada Oct 25 2 13SPEAKER David Lomet joint work with Justin Levandoski and Sudipta Sengupta MSR LLAMA A Cache Storage Subsystem for Modern HardwareDetailsDate and TimeOct 25 2 13 3 pmLocationDBH 3 11SpeakerDavid Lomet joint work with Justin Levandoski and Sudipta Sengupta MSR TitleLLAMA A Cache Storage Subsystem for Modern HardwareAbstract LLAMA is a subsystem designed for new hardware environments that supports an API for page oriented access methods providing both cache and storage management Caching CL and storage SL layers use a common mapping table that separates a page s logical and physical location CL supports data updates and management updates e g for index re organization via latch free compare and swap atomic state changes on its mapping table SL uses the same mapping table to cope with page location changes produced by log structuring on every page flush To demonstrate LLAMA s suitability we tailored our latch free Bw tree implementation to use LLAMA The Bw tree is a B tree style index Layered on LLAMA it has higher performance and scalability using real workloads compared with BerkeleyDB s B tree which is known for good performance Speaker Bio David Lomet Ph D from Penn is a Principal Researcher and manager of the Database Group at Microsoft Research Redmond Earlier he was at Digital s CRL Wang Institute and IBM Research Lomet has over 1 papers on databases indexing concurrency and recovery including two SIGMOD best papers He is an inventor of transactions Lomet has served on SIGMOD VLDB and ICDE PCs being co chair of ICDE 2 and VLDB 2 6 He won SIGMOD s Contributions Award for his service as Data Engineering Bulletin Editor in Chief since 1992 He has been editor of ACM TODS VLDB Journal and DAPD He has served on the VLDB Endowment and ICDE Steering Committee has been IEEE TCDE Chair and is a Fellow of AAAS ACM and IEEE Oct 18 2 13SPEAKER Tyson Condie Microsoft and UCLA Big Learning SystemsDetailsDate and TimeOct 18 2 13 3 pmLocationDBH 3 11SpeakerTyson Condie Microsoft and UCLA TitleBig Learning SystemsAbstract A new wave of systems is emerging in the space of Big Data Analytics that open the door to programming models beyond Hadoop MapReduce HMR It is well understood that HMR is not ideal for applications in the domain of machine learning and graph processing This realization is fueling a number of new Big Data system efforts Berkeley Spark Google Pregel GraphLab CMU and AsterixDB UC Irvine to name a few Each of these add unique capabilities but form islands around key functionalities fault tolerance resource allocation and data caching In this talk I will provide an overview of some Big Data systems starting with Google s MapReduce which defined the foundational architecture for processing large data sets I will then identify a key limitation in this architecture namely its inability to efficiently support iterative workflows I will then describe real world examples of systems that aim to fill this computational void I will conclude with a description of my own work on a layering that unifies key runtime functionalities fault tolerance resource allocation data caching and more for workflows both iterative and acyclic that process large data sets Speaker Bio Tyson Condie is a principal scientist with the Cloud and Information Services Lab at Microsoft and an Assistant Professor at UCLA He received his Ph D from Berkeley His research focuses on data analytics distributed systems Internet scale query processing and optimization and declarative language design and implementation His current work involves building a system software stack for large scale data processing tasks on resource managers like Apache YARN Berkeley Mesos Google Omega and Facebook Corona Oct 11 2 13SPEAKER Anhai Doan University of Wisconsin and WalmartLabs Toward Hands Off Crowdsourcing Crowdsourced Entity Matching for the MassesDetailsDate and TimeOct 11 2 13 3 pmLocationDBH 3 11SpeakerAnhai Doan University of Wisconsin and WalmartLabs TitleToward Hands Off Crowdsourcing Crowdsourced Entity Matching for the MassesAbstractEntity matching EM finds data records that refer to the same real world entity Recent work has applied crowdsourcing to EM and has clearly established the promise of this approach This work however is limited in that it crowdsources only parts of the EM workflow requiring a developer who knows how to code to execute the remaining parts Consequently this work does not scale to the growing EM need at enterprises and crowdsourcing startups and cannot handle scenarios where ordinary users i e the masses want to leverage crowdsourcing to match entities To address these problems we propose the notion of hands off crowdsourcing HOC which crowdsources the entire workflow of a task thus requiring no developers We show how HOC can represent a next logical direction for crowdsourcing research scale up EM at enterprises and crowdsourcing startups and open up crowdsourcing for the masses We describe Corleone a HOC solution for EM We show how Corleone uses the crowd to generate blocking rules applies active learning to learn matchers estimates accuracy given severe skew and identifies difficult to match pairs to which Corleone can apply more complex matchers Finally we discuss the implications of our work to executing crowdsourced RDBMS joins cleaning learning models and soliciting complex information types from crowd workers Speaker BioAnHai Doan is an Associate Professor in the database group at the University of Wisconsin Madison His current interests include crowdsourcing knowledge bases data integration and information extraction He received the ACM Doctoral Dissertation Award in 2 3 and a Sloan fellowship in 2 7 AnHai was Chief Scientist of Kosmix a social media startup acquired by Walmart in 2 11 Currently he also works as Chief Scientist of WalmartLabs a research and development lab devoted to analyzing and integrating data for e commerce AnHai is a co author of Principles of Data Integration with Alon Halevy and Zack Ives a textbook published by Morgan Kaufmann in 2 12 Sept 2 2 13SPEAKER Li Xiong Emory University Real Time Aggregate Monitoring with Differential PrivacyDetailsDate and TimeSept 2 2 13 2 pmLocationDBH 3 11SpeakerLi Xiong Emory University TitleReal Time Aggregate Monitoring with Differential PrivacyAbstract While Big Data promises significant economic and social benefits it also raises serious privacy concerns Real time aggregate statistics of data collected from individuals can be shared to enable many applications such as disease surveillance and traffic monitoring However it must be ensured that the privacy of individuals is not compromised While differential privacy has emerged as a de facto standard for private data analysis directly applying the differential privacy mechanisms on time series has limited utility due to high correlations between data values In this talk I will present FAST a novel Filtering and Adaptive Sampling based framework for monitoring aggregate Time series under differential privacy FAST adaptively samples long time series according to detected data dynamics and simultaneously uses filtering techniques to dynamically predict and correct released data values I will present experimental studies using real datasets demonstrating the feasibility and benefit of FAST and conclude with open questions Speaker Bio Li Xiong is an Associate Professor in the Department of Mathematics and Computer Science and the Department of Biomedical Informatics at Emory University where she directs the Assured Information Management and Sharing AIMS research group She holds a PhD from Georgia Institute of Technology an MS from Johns Hopkins University and a BS from University of Science and Technology of China all in Computer Science She also worked as a software engineer in IT industry for several years prior to pursuing her doctorate Her areas of research are in data privacy and security distributed data management and biomedical informatics She is a recent recipient of the Career Enhancement Fellowship by Woodrow Wilson Foundation a Cisco Research Award and an IBM Faculty Innovation Award Her current research is supported by NSF and AFOSR Sep 13 2 13SPEAKER Raman Grover ISG PhD candidate Scalable Fault tolerant Elastic Data FeedsDetailsDate and TimeSep 13 2 13 3 pmLocationDBH 3 11SpeakerRaman Grover ISG PhD candidate TitleScalable Fault tolerant Elastic Data FeedsAbstractIn this ISG talk thesis proposal I describe and study the support for data feed ingestion in AsterixDB a Big Data Management System BDMS that provides a platform for the scalable storage searching and analysis of very large volumes of semi structured data Data feeds are a mechanism for having continuous data arrive into a database system from external sources that produce data continuously and to have that data incrementally populate a persisted dataset and associated indexes To my knowledge this will be the first system to explore the challenges involved in building a data ingestion facility that deals with semi structured data and employs partitioned parallelism to scale the facility and couple it with high volume and or parallel external data sources I describe language level support for modeling defining a feed and present the methodology for providing tolerance to software hardware failures Mechanisms by which a feed can dynamically adapt to different workloads for optimum usage of resources are provided May 17 2 13SPEAKER Charles Boicey UCI Irvine Health and Information Services Apache Hadoop in the Healthcare SettingDetailsDate and TimeMay 17 2 13 3 pmLocationDBH 3 11SpeakerCharles Boicey UCI Irvine Health and Information Services TitleApache Hadoop in the Healthcare SettingAbstractApache Hadoop is open source software that enables distributed processing of large data sets across clusters of computers Hadoop can scale up to thousands of computers each able to store and process data Hadoop is capable of ingesting and storing the types of data found in healthcare structured unstructured image and video Hadoop also has an advantage for healthcare in its ability to interoperate with other open source software This interoperability combined with scalability makes Hadoop an ideal platform for the development of a software ecosystem that fills in the gaps left by the Electronic Medical Record and Enterprise Data Warehouse Speaker Bio Charles Boicey is the Informatics Solutions Architect for the UC Irvine Health At UCI Charles is responsible for the development and implementation of the enterprise data warehouse health information exchange home health integration and UC Irvine Health s Big Data initiative Charles has 2 years of experience in the healthcare field cope of clinical expertise encompasses trauma critical care nursing Charles is Vice President of the American Nursing Informatics Association May 1 2 13SPEAKER No SeminarDetailsDate and TimeMay 1 2 13 3 pmLocationDBH 3 11SpeakerTitleNo SeminarAbstract No ISG seminar Leaving this time free so that ISG affiliates can attend today s ICS Trends in Society and Information Technology talk see www ics uci edu trends Speaker Bio April 19 2 13SPEAKER Michael J Carey with the AsterixDB dev team Want To Kick My Asterix DB DetailsDate and TimeApril 19 2 13 3 pmLocationDBH 3 11SpeakerMichael J Carey with the AsterixDB dev team TitleWant To Kick My Asterix DB Abstract Due to several faculty traveling and thus being MIA this coming Friday the planned ISG seminar by Teradata is being postponed until later in the quarter Instead this week s Friday ISG seminar slot will be used to invite ISG and ICS community participation in the forthcoming Beta Release of a new open source BDMS Big Data Management System that members of UCI s ASTERIX project have been working on for nearly four years We want this new product to be called AsterixDB to be very high quality and we are hereby inviting interested helpers at UCI to come hear about it and then help us polish it by downloading it and playing with it trying out its data model query language and API for apps kicking its tires this Friday Our goal is to get a handful of outside the team folks to join us in using the system ahead of the Beta Release and then filing any issues using the GoogleCode issue tracking infrastructure so that when we release this publically it s well polished and well shaken out To date we have only delivered an Alpha Release and only very recently to one of our industrial partners So if you like database technology and would like to help us deliver Big Data 2 to the world in a month or so and you have time interest in playing a bit in the very near term PLEASE COME FRIDAY and we will show you what AsterixDB is all about This will be an informal presentation based on giving a tour of our Alpha documentation and the release info on the GoogleCode wiki and then having the team give a demo and even help you get the system working in real time if you bring your favorite laptop when you come We hope to see some of you there Refreshments will be provided as usual for the ISG seminar but we might upgrade the refreshments a little for this event we ll see We will also surely do something nice later for any outside folks who do end up significantly contributing in this manner to the quality of the release If you plan to come on Friday please RSVP to the speaker mjcarey ics uci edu so we know what to maybe expect in terms of potential turnout Thx Speaker Bio Mike Carey is a Professor in the ISG subgroup of the UCI CS department His goal is to eventually change the Big Data management landscape forever through the great work that our AsterixDB team has done and is now preparing to share April 12 2 13SPEAKER Shahram Ghandeharizadeh USC DetailsDate and TimeApril 12 2 13 3 pmLocationDBH 3 11SpeakerShahram Ghandeharizadeh USC TitleAbstract Speaker Bio March 1 2 13SPEAKER Pat Helland Salesforce Immutability Changes EverythingDetailsDate and TimeMarch 1 2 13 3 pmLocationDBH 3 11SpeakerPat Helland Salesforce TitleImmutability Changes EverythingAbstractFor a number of decades I ve been saying Computing Is Like Hubble s Universe Everything Is Getting Farther Away from Everything Else It used to be that everything you cared about ran on a single database and the transaction system presented you the abstraction of a singularity your transaction happened at a single point in space the database and a single point in time it looked like it was before or after all other transactions Now we see a more complicated world Across the Internet we put up HTML documents or send SOAP calls and these are not in a transaction Within a cluster we typically write files in a file system and then read them later in a big map reduce job that sucks up read only files crunches and writes files as output Even inside the emerging many core systems we see high performance computation on shared memory but increasing cost to using semaphores Indeed it is clear that Shared Memory Works Great as Long as You Don t Actually SHARE Memory There are emerging solutions which are based on immutable data It seems we need to look back to our grandparents and how they managed distributed work in the days before telephones We realize that Accountants Don t Use Erasers but rather accumulate immutable knowledge and then offer interpretations of their understanding based on the limited knowledge presented to them This talk will explore a number of the ways in which our new distributed systems leverage write once and read many immutable data Speaker BioPat Helland has been working on databases transaction processing messaging and distributed systems for 34 years In the 198 s he was chief architect of the Tandem NonStop s transaction system called TMF Transaction Monitoring Facility From 1991 to 1994 he worked at HaL Computers a subsidiary of Fujitsu and designed and architected a CC NUMA Cache Coherent Non Uniform Memory Architecture multiprocessor which Fujitsu shipped Starting in 1994 Pat worked at Microsoft where he was the chief architect for MTS Microsoft Transaction Server and DTC Distributed Transaction Coordinator Later he built SQL Service Broker which offers high performance 1 K msg sec transactional exactly once messaging integrated with SQL Server From 2 5 to 2 7 Pat work at Amazon on the product catalog and then returned in 2 7 to Microsoft By 2 9 he was working on Cosmos the multi peta byte storage and computational plumbing behind Bing This year Pat moved to San Francisco to be by the grandkids and joined Salesforce com working on database and filesystem technology Feb 22 2 13SPEAKER Swaroop Jagadish and Kapil Surlaker LinkedIn On Brewing Fresh Espresso LinkedIn s Distributed Data Serving PlatformDetailsDate and TimeFeb 22 2 13 3 pmLocationDBH 3 11SpeakerSwaroop Jagadish and Kapil Surlaker LinkedIn TitleOn Brewing Fresh Espresso LinkedIn s Distributed Data Serving PlatformAbstractAs LinkedIn has grown our core data sets and request processing requirements have grown as well The development of Espresso was motivated by our desire to migrate LinkedIn s online serving infrastructure from monolithic commercial RDBMS systems running on high cost specialized hardware to elastic clusters of commodity servers running free software and to improve agility by enabling rapid development by simplifying the programming model separating scalability routing caching from business logic Espresso is a document oriented distributed data serving platform that has been built to address LinkedIn s requirements for a scalable performant source of truth primary store It provides a hierarchical document model transactional support for modifications to related documents real time secondary indexing on the fly schema evolution and provides a timeline consistent change capture stream This talk describes the motivation and design principles involved in building Espresso its architecture and presents a set of experimental results that characterize the performance of the system along various dimensions Speaker Bio Swaroop Jagadish is a member of the Data Infrastructure team at Linkedin where he works on distributed data systems such as Databus Helix and Espresso Prior to that he worked at Yahoo where he built one of the first real time bidding engines in the display ads industry He holds B E from BMS College of Engineering and M S from University of California Santa Barbara Kapil Surlaker is a member of the Data Infrastructure team at Linkedin where he works on distributed data systems such as Databus Helix and Espresso Prior to that he worked at Kickfire acquired by Teradata where he built high performance Database systems Earlier in his career he worked on replication technology at Oracle where he was part of the team that built Oracle Streams He holds B Tech CS from IIT Bombay and M S From University of Minnesota Feb 8 2 13SPEAKER Ronen Vaisenberg Google Practice Talk Scheduling Sensors for Monitoring Sentient Spaces using an Approximate POMDP Policy Percom2 13 DetailsDate and TimeFeb 8 2 13 3 pmLocationDBH 3 11SpeakerRonen Vaisenberg Google TitlePractice Talk Scheduling Sensors for Monitoring Sentient Spaces using an Approximate POMDP Policy Percom2 13 AbstractWe present a framework for sensor actuation and control in sentient spaces in which sensors are used to observe a physical phenomena Our framework utilizes the spatio temporal statistical properties of an observed phenomena with the goal of maximizing an application specified reward Specifically we define an observation of a phenomena by assigning it a discrete value state and we model its semantics as the transition between these values states This semantic model is used to predict the future states in which the phenomena is likely to be at based on partially observed past states To accomplish real time agility we designed an approximate adaptive grid solution for POMDPs that yields practically good results and in some cases guarantees on the quality of the approximation We instantiate the framework in a camera network and use it perform real time actuation of large scale sensor networks To the best of our knowledge we are the first to address the problem of actuating a large scale sensor network based on an approximated POMDP formulation Our semantic model is simple enough to be implemented in real time yet powerful enough to capture meaningful semantics of typical behavior Our action selection process is as fast as a table lookup in real time Speaker Bio Feb 15 2 13SPEAKER Hongzhi Wang ISG DetailsDate and TimeFeb 15 2 13 3 pmLocationDBH 3 11SpeakerHongzhi Wang ISG TitleAbstract Speaker Bio Feb 1 2 13SPEAKER Marco Sanvido Pure Storage The Why and How of an All Flash Enterprise Storage ArrayDetailsDate and TimeFeb 1 2 13 3 pmLocationDBH 3 11SpeakerMarco Sanvido Pure Storage TitleThe Why and How of an All Flash Enterprise Storage ArrayAbstractEnterprise storage is an 3 billion a year industry dominated by spinning disks Flash storage is poised to take a large chunk of the market having grown significantly in capacity and production driven by consumer electronics Flash s technical advantages over disk promise storage arrays that are faster and easier to use while consuming less power and costing less The downsides of flash inc large erase blocks limited overwrites and higher price mean that using flash as a drop in replacement for disk leads to increased price volatile performance and decreased reliability In this talk we describe the design of the Pure FlashArray an enterprise storage array built around consumer flash storage The array and its software Purity play to the advantages of flash while minimizing the downsides Purity writes to flash in multiples of the erase block size and stores its metadata in a key value store that minimizes overwrites and stores approximate answers trading extra reads for fewer writes And Purity reduces data stored on flash through a range of techniques including compression deduplication and thin provisioning The net result is a flash array that deliver a sustained read write workload of over 1 4kb I O requests per second while maintaining sub millisecond latency With many customers seeing 4x or greater data reduction the Pure FlashArray ends up being cheaper than disk too Speaker Bio Dr Marco Sanvido holds a Dipl Ing degree 1996 and a Dr techn degree 2 2 in Computer Science from the Swiss Federal Institute of Technology in Z rich Switzerland ETHZ He was a co founder of weControl an ETHZ spin off where he developed low power and real time embedded systems for autonomous flying vehicles He was a postdoctoral researcher in Computer Science at the University of California at Berkeley from 2 2 to 2 4 and thereafter he worked on virtualization at VMware In 2 5 he then became a researcher at Hitachi Global Storage Technologies where he worked on hard disk drive and solid state drive architectures Since 2 1 Marco joined Pure Storage as a Principal Software Engineer Jan 25 2 13SPEAKER Silvius Rus Quantcast Petabyte Scale Data Processing at QuantcastDetailsDate and TimeJan 25 2 13 3 pmLocationDBH 3 11SpeakerSilvius Rus Quantcast TitlePetabyte Scale Data Processing at QuantcastAbstractThe talk will present the big data storage processing and query systems in production at Quantcast We receive up to 5 TB of new data every day respond to 5 events per second process up to 3 PB per day and store tens of petabytes of data We have implemented our own MapReduce software stack that scales better and has significantly lower resource requirements than Hadoop The QFS file system is available open source at https github com quantcast qfs wiki Speaker BioSilvius Rus leads Big Data Platforms at Quantcast He directs manages and participates in the development of cluster language runtimes SQL Sawzall petabyte scale map reduce interactive big data analytics cluster resource management distributed file systems and large scale realtime processing Before Quantcast he was at Google working on Gmail load balancing across datacenters parallel memory allocation performance server performance and C compiler and library optimization Silvius holds a PhD in computer science from Texas A and M University where he worked on full program optimization based on hybrid static and dynamic analysis of memory reference patterns Jan 18 2 13 Special Time SPEAKER Joe Hellerstein UC Berkeley Keep CALM and Query OnDetailsDate and TimeJan 18 2 13 Special Time 11 amLocationDBH 6 11SpeakerJoe Hellerstein UC Berkeley TitleKeep CALM and Query OnAbstract Any modern software system of note has two key characteristics it is a distributed system and it manages significant amounts of data As a result the topic of distributed data consistency has become a key problem in the engineering of modern software systems Conventional distributed systems wisdom dictates that perfect consistency is too expensive to guarantee in general and consistency mechanisms if they are used at all should be reserved for infrequent small scale mission critical tasks Like most design maxims these ideas are not so easy to translate into practice all kinds of unavoidable tactical questions pop up For example Exactly where in my multifaceted system is loose consistency good enough to meet application needs How do I know that my mission critical software isn t tainted by my best effort components How do I ensure that my design maxims are maintained as software and developer teams evolve Until recently answers to these questions have been more a matter of folklore than mathematics In this talk I will describe the CALM Theorem which links Consistency And Logical Monotonicity and discuss how it can inform distributed software development I ll also describe Bloom a disorderly distributed programming language developed in my group Bloom admits a form of automated CALM analysis which enables a compiler to answer questions like the ones above Time permitting I will also point out some additional results from my two main research projects the BOOM project on large scale system development and the d p project on human interaction in the data analysis lifecycle Speaker Bio Joseph M Hellerstein is a Chancellor s Professor of Computer Science at the University of California Berkeley whose research focuses on data centric systems and the way they drive computing A Fellow of the ACM his work has been recognized via awards including an Alfred P Sloan Research Fellowship MIT Technology Review s TR1 and TR1 lists Fortune Magazine s Smartest in Tech list and two ACM SIGMOD Test of Time awards He has led a number of influential open source projects including Bloom MADlib Telegraph and TinyDB In 2 12 Joe co founded Trifacta Inc which develops productivity software for data analysts Dec 14 2 12SPEAKER Bijit Hore UCI ISG Hide and Seek in the cloud How to securely store and query your data in untrusted environmentsDetailsDate and TimeDec 14 2 12 3 pmLocationDBH 3 11SpeakerBijit Hore UCI ISG TitleHide and Seek in the cloud How to securely store and query your data in untrusted environmentsAbstractSecurity and privacy of data is a major concern for organizations and many individuals that use cloud based services to cater to their IT needs This is cited as the central reason why many federal healthcare and financial organizations have not embraced cloud computing in a major way in spite of its many benefits In this talk we consider the central problem of data confidentiality that arises while storing sensitive data in the cloud While data encryption is an obvious solution for ensuring confidentiality standard algorithms like AES make the data unusable in the cloud For example keyword search or database queries cannot be evaluated against the encrypted data Over the past decade many new schemes have been developed that admit a variety of computations directly on the encrypted representation We give a brief overview of some of the important techniques proposed in this arena specifically for evaluating keyword match and range queries Finally we describe our own contributions to this area and conclude with a discussion about open problems and future directions Speaker Bio Dec 7 2 12SPEAKER No SeminarDetailsDate and TimeDec 7 2 12 3 pmLocationSpeakerTitleNo SeminarAbstract No ISG seminar Leaving this time free so that ISG affiliates can attend today s ICS Trends in Society and Information Technology talk see www ics uci edu trends Speaker Bio Nov 3 2 12SPEAKER Peter Bailis UC Berkeley Probabilistically Bounded Staleness for Practical Partial QuorumsDetailsDate and TimeNov 3 2 12 3 pmLocationDBH 3 11SpeakerPeter Bailis UC Berkeley TitleProbabilistically Bounded Staleness for Practical Partial QuorumsAbstractData store replication results in a fundamental trade off between operation latency and data consistency In this talk we examine this trade off in the context of quorum replicated data stores Under partial or non strict quorum replication a data store waits for responses from a subset of replicas before answering a query without guaranteeing that read and write replica sets intersect As deployed in practice these configurations provide only basic eventual consistency guarantees with no limit to the recency of data returned However anecdotally partial quorums are often good enough for practitioners given their latency benefits We explain why partial quorums are regularly acceptable in practice analyzing both the staleness of data they return and the latency benefits they offer We introduce Probabilistically Bounded Staleness PBS consistency which provides expected bounds on staleness with respect to both versions and wall clock time We derive a closed form solution for versioned staleness as well as model real time staleness for representative Dynamo style systems under internet scale production workloads Using PBS we measure the latency consistency trade off for partial quorum systems We quantitatively demonstrate how and why eventually consistent systems frequently return consistent data within tens of milliseconds while offering significant latency benefits This is joint work with Shivaram Venkataraman Mike Franklin Joe Hellerstein and Ion Stoica at UC Berkeley An earlier version of this work appeared at VLDB 2 12 selected for Best of VLDB 2 12 and an implementation of PBS is slated for release in Cassandra 1 2 Demo http pbs cs berkeley edu demoSpeaker BioPeter Bailis is a graduate student in Computer Science at UC Berkeley where he works closely with Joe Hellerstein Ion Stoica and Ali Ghodsi He currently studies distributed systems with a particular focus on distributed consistency models Peter received his A B from Harvard College in 2 11 where he worked with Margo Seltzer and Matt Welsh and was a 2 11 CRA Outstanding Undergraduate Researcher He is the recipient of the NSF Graduate Research Fellowship and the Berkeley Fellowship for Graduate Study and is a co founder of TinyToCS the premiere journal for Computer Science research of 14 characters or less Nov 9 2 12SPEAKER Chaitan Baru SDSC at UCSD Data Initiatives at SDSCDetailsDate and TimeNov 9 2 12 3 pmLocationDBH 3 11SpeakerChaitan Baru SDSC at UCSD TitleData Initiatives at SDSCAbstract As a data oriented supercomputer center SDSC is engaged in a variety of activities that support data intensive computing and big data from research and development to fielding production systems and enabling end applications This talk will provide an overview of several data activities at SDSC including the Gordon supercomputer data intensive applications on Gordon the SDSC Cloud with Globus Online interface for OpenStack and new initiatives such as the Center for Large scale Data Systems Research CLDS We will present two CLDS programs one on establishing industry standards for Big Data Benchmarking and another on Data Growth and Data Value A new initiative targeted at long tail scientific data motivated partly by needs identified by the NSF EarthCube initiative and by the challenges faced by a typical research university will also be presented There are many opportunities for joint collaborations and student projects across these initiatives Speaker Bio Chaitan Baru is Associate Director for Data Initiatives at the San Diego Supercomputer Center Director UC San Diego where he also directs the Center for Large scale Data Systems research CLDS His technical interests are in the areas of scientific data management large scale data systems data integration data analytics and parallel database systems He has been involved in cyberinfrastructure projects across a range of science disciplines e g earth sciences ecological sciences hydrology earthquake engineering biomedical sciences and others He is PI of the OpenTopography project coordinator of the Data Discovery Mining and Access community group for the NSF EarthCube project and Chair Coordinating Committee for Big Data Benchmarking Before joining SDSC 16 years ago Baru led one of the development teams at IBM for DB2 Parallel Edition a shared nothing database engine Prior to that he was on the faculty of the EECS Dept University of Michigan Baru has a B Tech in Electronics Engineering from IIT Madras and an ME and PhD in Electrical Engineering from the University of Florida Gainesville Nov 2 2 12SPEAKER No SeminarDetailsDate and TimeNov 2 2 12 3 pmLocationSpeakerTitleNo SeminarAbstract No ISG seminar Leaving this time free so that ISG affiliates can attend today s ICS Trends in Society and Information Technology talk see www ics uci edu trends Speaker Bio Oct 26 2 12SPEAKER Yingyi Bu ISG PhD student Pregelix Think Like a Vertex Scale like SpandexDetailsDate and TimeOct 26 2 12 3 pmLocationDBH 3 11SpeakerYingyi Bu ISG PhD student TitlePregelix Think Like a Vertex Scale like SpandexAbstract Recently there are more and more demands for analyzing Big Graph Data For example the scale of the world wide web keeps expanding to billions of web pages and hyper links the key social network sites like Facebook LinkedIn Twitter all have a rapidly growing gigantic social graph and the biology science people assemble genomes from huge de Bruijn graphs To analyze such Big graphs requires a system which can not only scale out to hundreds or thousands of machines but also do the computation very efficiently In this talk I will introduce the Pregelix system which supports easy programming and scales to large commodity machine clusters I will first illustrate the programming model application programmers need zero knowledge of the parallel distributed system but just think like a vertex and write a couple of functions that encapsulate the logic for what one graph vertex does After that I will detail the shining internals of Pregelix including the system architecture the scalable dataflow runtime the execution strategies and the out of core support Then I will walk through a few examples built on top of Pregelix such as PageRank and connected components Finally I will demonstrate our performance numbers and conclude the talk Truth in lending disclosure the programming model and API were shamelessly borrowed from Google s Pregel graph analytics platform hence the name Speaker Bio Yingyi Bu is a PhD student in the ISG group of UC Irvine He is working on the ASTERIX project that aims at an open source data intensive computing platform with new technologies for ingesting storing managing indexing querying analyzing and subscribing intensive semi structured data Within the project Yingyi has been working on the data model independent algebra optimization layer the ASTERIX query optimizer and the Pregelix system Oct 19 2 12SPEAKER David Lomet Microsoft Research The Bw Tree A B tree for New Hardware PlatformsDetailsDate and TimeOct 19 2 12 3 pmLocationDBH 3 11SpeakerDavid Lomet Microsoft Research TitleThe Bw Tree A B tree for New Hardware PlatformsAbstractThe emergence of new hardware and platforms has led to reconsideration of how data management systems are designed However certain basic functions such as key indexed access to records remain essential While we exploit the common architectural layering of prior systems we make radically new design decisions about each layer Our new form of B tree called the Bw tree achieves its very high performance via a latch free approach that effectively exploits the processor caches of modern multi core chips Our storage manager uses a unique form of log structuring that blurs the distinction between a page and a record store and works well with flash storage This paper describes the architecture and algorithms for the Bw tree focusing on the main memory aspects The paper includes results of our experiments that demonstrate that this fresh approach produces outstanding performance Speaker Bio David Lomet has been a principal researcher managing the Microsoft Research Database Group at Microsoft Research since 1995 Earlier he spent seven and a half years at Digital Equipment Corporation He has been at IBM Research in Yorktown and a Professor at Wang Institute Dr Lomet spent a sabbatical at University of Newcastle upon Tyne working with Brian Randell He has a Computer Science Ph D from the University of Pennsylvania Dr Lomet has done research and product development in architecture programming languages and distributed systems His primary interest is database systems focusing on access methods concurrency control and recovery He is one of the inventors of the transaction concept and is an author of over 1 papers and 45 patents Two papers won SIGMOD best paper awards He received the 2 1 SIGMOD Contributions Award for his work as editor in chief of the Data Engineering Bulletin since 1992 Dr Lomet has served on program committees including SIGMOD PODS VLDB and ICDE He was ICDE 2 PC co chair and VLDB 2 6 PC core chair He is a member of the ICDE Steering Committee and VLDB Board He is a past editor of ACM TODS and the VLDB Journal Dr Lomet is IEEE Golden Core Member and has received IEEE Outstanding Contribution and Meritorious Service Awards Dr Lomet is a Fellow of the ACM IEEE and AAAS Oct 5 2 12SPEAKER Thomas Bodner TU Berlin A Taxonomy of Platforms for Analytics on Big Data Stratosphere talk series 5 DetailsDate and TimeOct 5 2 12 4 3 pm 5pmLocationDBH 3 11SpeakerThomas Bodner TU Berlin TitleA Taxonomy of Platforms for Analytics on Big Data Stratosphere talk series 5 Abstract Within the past few years industrial and academic organizations designed a wealth of systems for data intensive analytics including MapReduce SCOPE Dryad ASTERIX Stratosphere Spark and many others These systems are being applied to new applications from diverse domains other than traditional relational OLAP making it difficult to understand the tradeoffs between them and the workloads for which they were built We present a taxonomy of existing system stacks based on their architectural components and the design choices made related to data processing and programmability to sort this space We further demonstrate a web repository for sharing Big Data analytics platform information and use cases The repository enables researchers and practitioners to store and retrieve data and queries for their use case and to easily reproduce experiments from others on different platforms simplifying comparisons Speaker Bio Thomas Bodner is a second year Master s student in the computer science department at the Technische Universit t Berlin working in the Database Systems and Information Management DIMA group on the Stratosphere project He received his B S from the University of Cooperative Education at Stuttgart In the course of his studies Thomas Bodner studied abroad at University of California Irvine and Royal Melbourne Institute of Technology He worked as an intern at the IBM Almaden Research Center and the IBM B blingen Laboratory His research interests include benchmarking of and query optimization for Big Data analytics systems Oct 5 2 12SPEAKER Alexander AlexandrovGenerating a Myriad of Atoms in the Blink of an Eye Stratosphere talk series 4 DetailsDate and TimeOct 5 2 12 4 pm 4 3 pmLocationDBH 3 11SpeakerAlexander AlexandrovTitleGenerating a Myriad of Atoms in the Blink of an Eye Stratosphere talk series 4 Abstract Data from real world applications is regarded as the golden standard for database systems evaluation Unfortunately finding appropriate real world datasets is often hard due to various privacy related constraints To overcome this problem we developed the Myriad Parallel Data Generator Toolkit a generic toolkit for declarative specification of synthetic data generators that provides built in parallelization support for the specified data generation programs In this talk I will motivate and present the main technical challenges solved by the highly parallel execution model of the Myriad Toolkit In addition to demonstrate the usability of the toolkit I will also give a brief overview of the supported data generator specification syntax and explain how different statistical constraints for the generated data can be implemented using the appropriate combination of specification routines Speaker Bio Alexander Alexandrov is a research associate at the Database Systems and Information Management research group at the Technische Universit t Berlin Before moving to Berlin for a Master in Computer Science at TU Berlin he received his Bachelor of Science in Software and Internet Technologies at the University of Mannheim Alexander has been working on the Stratosphere project both as student and research assistant since 2 9 His research interests include data generation evaluation and query optimization for large scale parallel batch processing systems with partial operator semantics Oct 5 2 12SPEAKER Stephan Ewen TU Berlin Spinning Fast Iterative Data Flows Stratosphere talk series 3 DetailsDate and TimeOct 5 2 12 3 3 pm 4pmLocationDBH 3 11SpeakerStephan Ewen TU Berlin TitleSpinning Fast Iterative Data Flows Stratosphere talk series 3 Abstract Parallel data flow systems are a central part of most analytic pipelines for big data The iterative nature of many analysis and machine learning algorithms however is still a challenge for current systems While certain types of bulk iterative algorithms are supported by novel data flow frameworks these systems cannot exploit computational dependencies present in many algorithms such as graph algorithms As a result these algorithms are inefficiently executed and have led to specialized systems based on other paradigms such as message passing or shared memory We propose a method to integrate incremental iterations a form of workset iterations with parallel data flows After showing how to integrate bulk iterations into a dataflow system and its optimizer we present an extension to the programming model for incremental iterations The extension alleviates for the lack of mutable state in dataflows and allows for exploiting the sparse computational dependencies inherent in many iterative algorithms The evaluation of a prototypical implementation shows that those aspects lead to up to two orders of magnitude speedup in algorithm runtime when exploited In our experiments the improved dataflow system is highly competitive with specialized systems while maintaining a transparent and unified data flow abstraction Speaker Bio Stephan Ewen is a research associate at the department for Database Systems and Information Management DIMA at the Technische Universit t Berlin He is working on the Stratosphere Project that aims at creating a versatile and efficient analytics engine for deep analysis of Big Data on cloud platforms Within the project Stephan works on the system s data flow programming abstraction the data flow optimization and the parallel runtime system Prior to joining the DIMA group Stephan completed the Applied Computer Science program at the University of Cooperative Education Stuttgart jointly with IBM Germany and got his Diploma from the University of Stuttgart In the course of his studies Stephan Ewen worked among others for the IBM Almaden Research Centre and the IBM Development Laboratory B blingen Oct 5 2 12SPEAKER Kostas Tzoumas TU Berlin Query Optimization with MapReduce Functions Stratosphere talk series 2 DetailsDate and TimeOct 5 2 12 3 pm 3 3 pmLocationDBH 3 11SpeakerKostas Tzoumas TU Berlin TitleQuery Optimization with MapReduce Functions Stratosphere talk series 2 Abstract Many systems for big data analytics employ a data flow programming abstraction to define parallel data processing tasks In this setting custom operations expressed as user defined functions are very common We address the problem of performing data flow optimization at this level of abstraction where the semantics of operators are not known Traditionally query optimization is applied to queries with known algebraic semantics In this work we find that a handful of properties rather than a full algebraic specification suffice to establish reordering conditions for data processing operators We show that these properties can be accurately estimated for black box operators using a shallow static code analysis pass based on reverse data and control flow analysis over the general purpose code of their user defined functions We design and implement an optimizer for parallel data flows that does not assume knowledge of semantics or algebraic properties of operators Our evaluation confirms that the optimizer can apply common rewritings such as selection reordering bushy join order enumeration and limited forms of aggregation push down hence yielding similar rewriting power as modern relational DBMS optimizers Moreover it can optimize the operator order of non relational data flows a unique feature among today s systems Speaker Bio Kostas Tzoumas is a postdoctoral researcher co leading the Stratosphere research project at the Technische Universit t Berlin He received his PhD from Aalborg University in 2 11 with a thesis on discovering and exploiting correlations for query optimization He was a visiting researcher at the University of Maryland College Park and an intern at Microsoft Research He received a Diploma in Electrical and Computer Engineering from the National Technical University of Athens in 2 7 His research interests are centered around systems for data analytics including query processing and optimization in massively parallel environments Oct 5 2 12SPEAKER Volker Markl TU Berlin The Current State of the Stratosphere Stratosphere talk series 1 DetailsDate and TimeOct 5 2 12 3 pm 5pmLocationDBH 3 11SpeakerVolker Markl TU Berlin TitleThe Current State of the Stratosphere Stratosphere talk series 1 Abstract Introduction to the Stratosphere system Speaker Bio Volker Markl is a Full Professor and Chair of the Database Systems and Information Management DIMA group at the Technische Universit t Berlin TU Berlin Prior to joining TU Berlin Dr Markl lead a research group at FORWISS the Bavarian Research Center for Knowledge based Systems in Munich Germany and was a Research Staff member and Project Leader at the IBM Almaden Research Center in San Jose California USA His research interests include information as a service new hardware architectures for information management information integration autonomic computing query processing query optimization data warehousing electronic commerce and pervasive computing Volker has presented over 1 invited talks in numerous industrial settings and at major conferences and research institutions worldwide He has authored and published more than 5 research papers at world class scientific venues Volker regularly serves as member and chair for program committees of major international database conferences He also is a member of the Board of Trustees of the VLDB Endowment Volker has 5 patent awards and he has submitted over 2 invention disclosures to date Over the course of his career he has garnered many prestigious awards including the European Information Society and Technology Prize an IBM Outstanding Technological Achievement Award an IBM Shared University Research Grant an HP Open Innovation Award and the Pat Goldberg Memorial Best Paper Award Jun 8 2 12SPEAKER Kerim Yasin Oktay and Bijit Hore ISG CloudProtecti and Risk Aware Workload Distribution in Hybrid CloudsDetailsDate and TimeJun 8 2 12 3 pmLocationDBH 3 11Speaker Kerim Yasin Oktay and Bijit Hore ISG TitleCloudProtecti and Risk Aware Workload Distribution in Hybrid CloudsAbstract In this talk we describe the CloudProtect system from the recently accepted paper in IEEE Cloud 2 12 The CloudProtect middleware empowers users to encrypt sensitive data stored within various cloud applications However most web applications require data in plaintext for implementing the various functionalities and in general do not support encrypted data management Therefore CloudProtect strives to carry out the data transformations encryption decryption in a manner that is transparent to the application i e preserves all functionalities of the application including those that require data to be in plaintext Additionally CloudProtect allows users flexibility in trading off performance for security in order to let them optimally balance their privacy needs and usage experience This paper explores an efficient and secure mechanism to partition computations across public and private machines in a hybrid cloud setting We propose a principled framework for distributing data and processing in a hybrid cloud that meets the conflicting goals of performance sensitive data disclosure risk and resource allocation costs The proposed solution is implemented as an add on tool for a Hadoop and Hive based cloud computing infrastructure Our experiments demonstrate that the developed mechanism can lead to a major performance gain by exploiting both the hybrid cloud components without violating any pre determined public cloud usage constraints Jun 1 2 12SPEAKER Ken Slocum UCSD Scalable Lineage Capture for DISCDetailsDate and TimeJun 1 2 12 3 pmLocationDBH 3 11SpeakerKen Slocum UCSD TitleScalable Lineage Capture for DISCAbstract Scale out data processing architectures enable sophisticated big data analytics but understanding and debugging multi step dataflows that ingest large volumes of data remains a fundamental challenge We are building a system called Newt a scalable architecture for capturing fine grain record level provenance from these data intensive scalable compute DISC systems in a generic manner Developers leverage a unique API to instrument these systems actively capturing fine grain lineage across multi step perhaps non relational transformations We report on our experiences instrumenting Hyracks and Hadoop and find that Newt s capture incurs 16 26 time overheads for the PigMix benchmark and a 14 overhead on a complex 145 stage de novo genomic assembler Speaker Bio Ken Yocum is an associate research scientist in the Department of Computer Science at UC San Diego where he runs the Synoptic Systems Lab While he once worked on high speed networking briefly holding the land speed record for gigabit TCP he has since become enamored with the myriad systems challenges of big data processing and software defined networks He received his Ph D from Duke University and his B S from Stanford When he s not working he enjoys his children cycling and going to the race track May 29 2 12 Special Time SPEAKER Murali Mani University of Michigan Flint Algebraic Manipulation of Encrypted DatabasesDetailsDate and TimeMay 29 2 12 Special Time 12 pmLocationDBH 3 11SpeakerMurali Mani University of Michigan Flint Title Algebraic Manipulation of Encrypted DatabasesAbstract Can we improve on the work that received the 1 year ACM SIGMOD test of time award In this talk we will outline our preliminary approach at doing the entire query processing on the server cloud while the client is involved only with encryption and decryption Our work is based on Craig Gentry s revolutionary recent work on fully homomorphic encryption first such scheme was published in 2 9 We utilize Craig Gentry s scheme for query processing while maintaining the algebraic framework that is a key aspect of database systems There are several avenues for future investigation exploring physical implementations for algebraic operators beyond what we have investigated exploring query optimization and utilization of indexes exploring feasibility of Craig Gentry s fully homomorphic encryption in the context of databases as some aspects of his scheme are very time consuming Speaker Bio Murali Mani finished his PhD in Computer Science from UCLA in 2 3 Since then he has worked at WPI and is currently an assistant professor at University of Michigan Flint His areas of interest are database systems and his significant projects have been on event stream processing processing of XML streaming data provenance metadata management and data modeling using XML schemas His research on XML stream processing and provenance have been supported by NSF May 25 2 12SPEAKER Jimmy Lin Twitter Flexibility without Anarchy Analytics Infrastructure at TwitterDetailsDate and TimeMay 25 2 12 3 pmLocationDBH 3 11SpeakerJimmy Lin Twitter TitleFlexibility without Anarchy Analytics Infrastructure at TwitterAbstractThe data analytics infrastructure at Twitter supports a myriad of technologies Hadoop Pig with Python and JRuby Cascading Scalding HBase MySQL Vertica and ZooKeeper Our philosophy is to let developers and data scientists use whatever tools they are most comfortable with while allowing individual components to be weaved together into complex analytic tapestries Managing complex workflows that cross language boundaries e g Java vs Pig vs Scala as well as architectures with significant impedance mismatches e g Hadoop vs Vertica has been and continues to remain a significant challenge In this talk I ll detail some of these issues and our present solutions Speaker Bio Jimmy Lin is a visiting scientist at Twitter currently on leave from the University of Maryland His current research focuses on scalable algorithms for data analytics particularly on text and graph data At Twitter he works on services designed to surface relevant content for users and the distributed infrastructure that supports mining relevance signals from massive amounts of data May 18 2 12SPEAKER Raman Grover ISG Ph D student ASTERIX Scalable Warehouse Style Web Data IntegrationDetailsDate and TimeMay 18 2 12 3 pmLocationDBH 3 11SpeakerRaman Grover ISG Ph D student TitleASTERIX Scalable Warehouse Style Web Data IntegrationAbstract A growing wealth of digital information is being generated on a daily basis in social networks blogs online communities etc Organizations and researchers in a wide variety of domains recognize that there is tremendous value and insight to be gained by warehousing this emerging data and making it available for querying analysis and other purposes This new breed of Big Data applications poses challenging requirements against data management platforms in terms of scalability flexibility manageability and analysis capabilities At UC Irvine we are building a nextgeneration database system called ASTERIX in response to these trends We present ongoing work that approaches the following questions How does data get into the system What primitives should we provide to better cope with dirty noisy data How can we support efficient data analysis on spatial data Using real examples we show the capabilities of ASTERIX for ingesting data via feeds supporting set similarity predicates for fuzzy matching and answering spatial aggregation queries Speaker Bio May 11 2 12SPEAKER Inci Cetindil ISG Ph D student Analysis of Instant Search Query LogsDetailsDate and TimeMay 11 2 12 3 pmLocationDBH 3 11SpeakerInci Cetindil ISG Ph D student TitleAnalysis of Instant Search Query LogsAbstractInstant search is a new search paradigm that shows results as a user types in a query It has become increasingly popular in recent years due to its simplicity and power In an instant search system every keystroke from a user triggers a new request to the server Therefore its log has a richer content than that of a traditional search system and previous log analysis research is not applicable to this type of log In this study we present the problem of analyzing the query log of an instant search system We propose a classification scheme for user typing behaviors We also compare the log of an instant search system and that of a traditional search system on the same data The results show that on a people directory search system instant search can typically save 2 seconds per search reduce the typing effort by showing the results with fewer characters entered and increase the success rate Speaker Bio April 27 2 12SPEAKER Afsin Akdogan University of Southern California Voronoi based Geospatial Query Processing with MapReduceDetailsDate and TimeApril 27 2 12 3 pmLocationDBH 3 11SpeakerAfsin Akdogan University of Southern California TitleVoronoi based Geospatial Query Processing with MapReduceAbstract Geospatial queries GQ have been used in a wide variety of applications such as decision support systems profile based marketing bioinformatics and GIS Most of the existing query answering approaches assume non parallel processing on a single machine although GQs are intrinsically parallelizable There are some approaches that have been designed for parallel databases and cluster systems however these only apply to the systems with limited parallel processing capability far from that of cloud based platforms In this study I present the problem of parallel geospatial query processing with MapReduce programming model Our approach creates a spatial index Voronoi diagram for given data points in 2D space and enables efficient processing of GQs We evaluated the performance of our proposed techniques and correspondingly compared them with their closest related work while varying the number of employed nodes Speaker BioAfsin Akdogan received his master s degree in computer science from Cornell University in 2 9 He received a best paper award in IEEE Cloud Computing Technology and Science conference in 2 1 He has also interned at Yahoo He is currently working towards his Ph D degree in computer science at the University of Southern California and his research focuses on cloud computing parallel data processing languages and geo spatial databases April 2 2 12SPEAKER Leila Jalali Ph D student in ISG A Reflective Approach to Synchronization for Consistent MultisimulationsDetailsDate and TimeApril 2 2 12 3 pmLocationDBH 3 11SpeakerLeila Jalali Ph D student in ISG TitleA Reflective Approach to Synchronization for Consistent MultisimulationsAbstractIn this talk I consider the challenge of designing a framework that supports the integration of multiple existing autonomous simulation models into an integrated simulation environment multisimulation In particular I focus on solutions for synchronization problem in multisimulation to orchestrate consistent information flow through multiple simulator 1 a transaction based approach to modeling the synchronization problem in multisimulations by mapping it to a problem similar to multidatabase concurrency we express multisimulation synchronization as a scheduling problem where the goal is to generate correct schedules for time advancement and data exchange across simulators that meets the dependencies without loss of concurrency 2 a hybrid scheduling strategy which adapts itself to the right level of pessimism optimism based on the state of the execution and underlying dependencies and 3 relaxation model for dependencies which guarantee bounded violation of consistency to support higher levels of concurrency We also develop two key optimizations a efficient checkpointing rollback techniques and b relaxation model for dependencies which guarantee bounded violation of consistency to support higher levels of concurrency We evaluate our proposed techniques via a detailed case study from the emergency response domain by integrating three disparate simulators a fire simulator CFAST an evacuation simulator Drillsim and a communication simulator LTEsim April 13 2 12 Special Time Place SPEAKER Jennifer Widom Stanford Data Centric Human Computation From 1 Students to 1 DetailsDate and TimeApril 13 2 12 Special Time Place 11 amLocationDBH 6 11SpeakerJennifer Widom Stanford TitleData Centric Human Computation From 1 Students to 1 AbstractThis talk will have two completely independent parts one related to research and the other to education In the first part of the talk I ll describe our ongoing research in leveraging human computation for tasks related to data Human computation crowdsourcing augments traditional computation with the use of human abilities to solve sub problems that are difficult for computers e g object or image comparisons information extraction relevance judgements and data gathering We are addressing two different types of data centric human computation 1 Fundamental algorithms such as sorting clustering and data cleaning in which the basic operations e g compare filter are performed by humans 2 A database system like platform in which declarative queries are posed by users and the system orchestrates a combination of stored and crowdsourced data to answer them Common to both areas is the need to formalize and optimize new tradeoffs among latency humans are much slower than computers cost humans require real money to perform tasks and quality humans are inaccurate and inconsistent In the second part of the talk I ll describe my recent experience teaching introductory databases to 6 students Admittedly only 25 of them submitted their homework and a mere 65 achieved a strong final score But even with 65 students I more than quadrupled the total number of students I ve taught in my entire 18 year academic career I began by flipping the way I teach my Stanford course and as a side effect making all components of the course freely available online But the big inflection point came when I offered the online course in a structured fashion with a schedule automatically graded assignments and exams and most importantly a worldwide community of students I ll cover a variety of topics related to the massive online course both logistical and social while avoiding speculation on the future of higher education Speaker BioJennifer Widom is the Fletcher Jones Professor and Chair of the Computer Science Department at Stanford University She received her Bachelor s degree from the Indiana University School of Music in 1982 and her Computer Science Ph D from Cornell University in 1987 She was a Research Staff Member at the IBM Almaden Research Center before joining the Stanford faculty in 1993 Her research interests span many aspects of nontraditional data management She is an ACM Fellow and a member of the National Academy of Engineering and the American Academy of Arts and Sciences she received the ACM SIGMOD Edgar F Codd Innovations Award in 2 7 and was a Guggenheim Fellow in 2 she has served on a variety of program committees advisory boards and editorial boards March 16 2 12 Special Time Place SPEAKER Cyrus Shahabi USC TransDec A Data Driven Framework for Decision Making in Transportation SystemsDetailsDate and TimeMarch 16 2 12 Special Time Place 11 amLocationDBH 6 11SpeakerCyrus Shahabi USC TitleTransDec A Data Driven Framework for Decision Making in Transportation SystemsAbstractThe vast amounts of transportation datasets traffic flow incidents etc collected by various federal and state agencies are extremely valuable in 1 real time decision making planning and management of the transportation systems and 2 conducting research to develop new policies to enhance the efficacy of the transportation systems In this talk I will present our data driven framework dubbed TransDec short for Transportation Decision Making which enables real time integration visualization querying and analysis of dynamic and archived transportation data I will show that considering the large size of the transportation data variety of the data different modalities and resolutions and frequent changes of the data implementation of such a scalable system that allows for effective querying and analysis of both archived and real time data is an intrinsically challenging data management task Subsequently I will focus on a route planning problem where the weights on the road network edges vary as a function of time due to the variability of traffic congestion I will show that na ve approaches to address this problem are either inaccurate or slow motivating the need for new solutions Consequently I will discuss our initial approach to this problem and demonstrate its implementation within the TransDec framework Speaker BioCyrus Shahabi is a Professor and the Director of the Information Laboratory InfoLAB at the Computer Science Department and also the Director of the NSF s Integrated Media Systems Center IMSC at the University of Southern California He is also the CTO and co founder of a USC spin off Geosemble Technologies He received his B S in Computer Engineering from Sharif University of Technology in 1989 and then his M S and Ph D Degrees in Computer Science from the University of Southern California in May 1993 and August 1996 respectively He authored two books and more than hundred fifty research papers in the areas of databases GIS and multimedia Dr Shahabi has received funding from several agencies such as NIJ NSF NASA NIH DARPA AFRL and DHS as well as several industries such as Google Microsoft NCR NGC and Chevron He was an Associate Editor of IEEE Transactions on Parallel and Distributed Systems TPDS from 2 4 to 2 9 He is currently on the editorial board of the VLDB Journal IEEE Transactions on Knowledge and Data Engineering TKDE ACM Computers in Entertainment and Journal of Spatial Information Science He is the founding chair of IEEE NetDB workshop and also the general co chair of ACM GIS 2 7 2 8 and 2 9 He chaired the nomination committee of ACM SIGSPATIAL for the 2 11 2 14 terms He regularly serves on the program committee of major conferences such as VLDB ACM SIGMOD IEEE ICDE ACM SIGKDD and ACM Multimedia Dr Shahabi is a recipient of the ACM Distinguished Scientist award in 2 9 the 2 3 U S Presidential Early Career Awards for Scientists and Engineers PECASE the NSF CAREER award in 2 2 and the 2 1 Okawa Foundation Research Grant for Information and Telecommunications He was the recipient of US Vietnam Education Foundation VEF faculty fellowship award in 2 11 an organizer of the 2 11 National Academy of Engineering Japan America Frontiers of Engineering program an invited speaker in the 2 1 National Research Council of the National Academies Committee on New Research Directions for the National Geospatial Intelligence Agency and a participant in the 2 5 National Academy of Engineering Frontiers of Engineering program March 9 2 12SPEAKER Nga Dang Ph D student in ISG QuARES A Quality Aware Renewable Energy driven Sensing FrameworkDetailsDate and TimeMarch 9 2 12 3 pmLocationDBH 3 11SpeakerNga Dang Ph D student in ISG TitleQuARES A Quality Aware Renewable Energy driven Sensing FrameworkAbstract Mobile devices such as smartphones and tablets are getting increasingly popular and continue to generate record high amount of mobile data traffic For example a recent Cisco report indicates that mobile data traffic will increase 39 times by 2 15 while 66 of such boost is due to video traffic Network capacity issue may be partially coped by deploying more cellular base stations installing dedicated broadcast networks or upgrading the cellular base stations to support 4G However these approaches all result in additional costs on new network infrastructure and might not be fully compatible with existing obile devices Also according to the report the network capacity provided by cellular network providers is predicted to be only 1 time increasing by 2 15 which implies that the above methods do not still meet the requirement for increasing mobile traffic A better way is moving data to other networks to reduce heavy traffic in cellular networks In our research we study motivations and methods to offload part of mobile traffic from cellular networks to other networks such as WiFi or Ad Hoc which are available in most modern smartphones Such these methods are cheap practical and easily implemented March 1 2 12 Special Time Place SPEAKER Archan Misra Singapore Management University Real time Mobile Sensing Analytics and the LiveLabs Experimentation PlatformDetailsDate and TimeMarch 1 2 12 Special Time Place 11 amLocationDBH 4 11SpeakerArchan Misra Singapore Management University TitleReal time Mobile Sensing Analytics and the LiveLabs Experimentation PlatformAbstract This talk explores the ongoing transformation of the mobile device into a combined sensing and analytics platform distinguished by two key features a efficient localized processing of sensor data streams and b localized coordination and distributed computation among a set of proximal mobile nodes I will first introduce the LiveLabs Experimentation Platform a unique urban behavioral testbed that combines innovations in wireless networks mobile sensing and App deployment to enable an ecosystem of industry partners to test next generation context based applications on approx 3 real life users in urban environments such as the SMU campus 2 major shopping malls and a resort theme park I will then describe ongoing research on offline and near real time energy efficient continuous smartphone based human context estimation or activity mining with a special focus on how such analytics can utilize proximity driven social interactions I will then briefly cover two ongoing projects that exploit such context sensing to a optimize the delivery of mobile advertising and b perform real time adaptation of femtocellular indoor networks Feb 17 2 12SPEAKER Russell Sears Yahoo Research A general purpose Log Structured Merge TreeDetailsDate and TimeFeb 17 2 12 3 pmLocationDBH 3 11SpeakerRussell Sears Yahoo Research TitleA general purpose Log Structured Merge TreeAbstract Data management workloads are increasingly write intensive and subject to strict latency SLAs This presents a dilemma Traditional update in place systems have unmatched latency properties but poor write throughput In contrast existing log structured techniques significantly improve write throughput but generally sacrifice read performance and exhibit unacceptable latency spikes We begin by presenting a new performance metric read fanout and argue that along with read amplification and write amplification it better characterizes the real world performance of index algorithms than existing approaches such as asymptotic analysis and price performance We then present a Log Structured Merge LSM tree implementation that combines the best properties of B Trees and log structured approaches 1 Unlike existing log structured trees our implementation has near optimal read and scan performance and 2 we present merge algorithms that bound write latencies without impacting write throughput or allowing merges to block application writes for extended periods of time We do this by introducing a new spring and gear scheduler that ensures merges at each level of the tree make steady progress This allows us to avoid blocking application writes without resorting to techniques that degrade read performance We use Bloom filters to improve index performance and find that a number of subtleties arise First it is important to ensure that reads can safely stop after finding the first version of a record Otherwise frequently written items will incur multiple disk lookups Second many applications and data management architectures check for preexisting values at insertion time Avoiding the disk seek performed by the check is crucial for such applications This work will appear in Sigmod 2 12 Feb 1 2 12 Special Time Place SPEAKER Anhai Doan U Wisconsin and Walmart Labs ex Kosmix Social Media Data Integration and Human ComputationDetailsDate and TimeFeb 1 2 12 Special Time Place 11 amLocationDBH 6 11SpeakerAnhai Doan U Wisconsin and Walmart Labs ex Kosmix TitleSocial Media Data Integration and Human ComputationAbstractSocial media has emerged as a major frontier on the World Wide Web with applications ranging from helping teenagers track Justin Bieber to e commerce to fostering revolutions In this talk I will discuss our work in this area as carried out at Wisconsin Kosmix and WalmartLabs I describe how we integrate data from traditional Web sources to build a global taxonomy greatly expand it with social media data then leverage it to build consumer facing applications Example applications include building topic pages detecting Twitter events and monitoring these events I discuss the critical role of data integration and human computation in processing social media Finally I discuss how all of these can help the emerging area of social commerce and why Walmart recently acquired Kosmix to make inroads into this new and exciting area Speaker BioAnHai Doan is an Associate Professor at the University of Wisconsin Madison His interests cover databases AI and Web with a current focus on data integration large scale knowledge bases social media crowdsourcing human computation and information extraction He received the ACM Doctoral Dissertation Award in 2 3 a CAREER Award in 2 4 and a Sloan Fellowship in 2 7 AnHai was Chief Scientist of Kosmix a social media startup acquired by Walmart in 2 11 Currently he also works as Chief Scientist of WalmartLabs a research and development lab devoted to integrating social and mobile data for e commerce Feb 3 2 12 Special Time Place SPEAKER Yannis Papakonstantinou UCSD Declarative optimizable data driven specifications of web and mobile applicationsDetailsDate and TimeFeb 3 2 12 Special Time Place 11 amLocationDBH 6 11SpeakerYannis Papakonstantinou UCSD TitleDeclarative optimizable data driven specifications of web and mobile applicationsAbstractDevelopers of web and mobile application development write too much low level plumbing code to efficiently access integrate and coordinate application state that resides on multiple sub systems of the architecture and is accessed using different languages SQL at the database server HTML and Javascript at the browser which in HTML5 includes its own database state Java or other programming languages at the application server The FORWARD project replaces such low level code with declarative specifications Its cornerstones are i the unified application state virtual database which enables modeling and manipulating the entire application state in an extension of SQL named SQL ii specification of Ajax pages as essentially rendered views over the unified application state Consequently the following three problems are resolved by appropriate reduction to data management problems where prior database research literature is leveraged and extended 1 The partial change of Ajax pages in response to application state changes is reduced to an incremental view maintenance problem Id s that retain the provenance of the page data play an instrumental efficiency role 2 Efficient data access is reduced to semistructured query processing over an integrated view that involves large database s and small main memory based sources 3 The inherent location transparency of the specifications is exploited in order to perform computation at the appropriate location browser vs server More broadly the talk discusses ongoing and future work in utilizing the increased abilities of HTML5 clients towards achieving low latency mobile web applications applications while location transparency of the specifications is retained Speaker Bio Yannis Papakonstantinou is a Professor of Computer Science and Engineering at the University of California San Diego His research is in the intersection of data management technologies and the web where he has published over eighty research articles He has given multiple tutorials and invited talks has served on journal editorial boards and has chaired and participated in program committees for many international conferences and workshops Yannis was the CEO and Chief Scientist of Enosys Software which built and commercialized an early XML based Enterprise Information Integration platform Enosys Software was acquired in 2 3 by BEA Systems He was the CEO and is the Chief Scientist of app2you which has commercialized UCSD R and D on rapid development of web applications for data driven analytics and business process management He is the Chief Computer Scientist of a pharmaceutical spin off startup in the area of data analytics for the pharmaceutical industry He has been in the technical advisory board of multiple startups currently including Brightscope Inc Yannis holds a Diploma of Electrical Engineering from the National Technical University of Athens MS and Ph D in Computer Science from Stanford University 1997 and an NSF CAREER award for his work on data integration Jan 27 2 12 SPEAKER Kurt Brown EMC Greenplum The Future of Big Data AnalyticsDetailsDate and TimeJan 27 2 12 3 pmLocationDBH 3 11SpeakerKurt Brown EMC Greenplum TitleThe Future of Big Data AnalyticsAbstract Big Data and analytics have both existed in some form for as long as computing itself but only now has technology advanced to the point that together they are starting to qualitatively change the way organizations and individuals perceive understand and predict the world around them In this talk I ll set Big Data Analytics in a historical context to help sort out what aspects of current technologies hardware software and programming models are simply transient artifacts or long term trends and to project where Big Data Analytics is possibly headed from the perspective of Greenplum and EMC Speaker BioKurt Brown is currently Director of Advanced R and D at Greenplum EMC Prior to EMC he co directed Intel s Berkeley Research Lab spent 13 years with IBM in operating systems and database R and D on the East and West coasts and co founded three startups in database middleware small business marketing services and residential energy management He received his PhD in 1995 from the University of Wisconsin for work in automated database performance tuning Jan 13 2 11SPEAKER Thomas BodnerThe Stratosphere Parallel Analysis Framework Present and FutureDetailsDate and TimeJan 13 2 11 3 pmLocationDBH 3 11SpeakerThomas BodnerTitleThe Stratosphere Parallel Analysis Framework Present and FutureAbstractData intensive computing is a much investigated topic in current research Next to parallel databases new flavors of data processors have established themselves most prominently the MapReduce programming and execution model The new systems provide key features that current parallel databases lack such as flexibility in the data models the ability to parallelize custom functions and fault tolerance that enables them to scale out to thousands of machines This talk presents the current state of Stratosphere system a cloud data and query processor that has been released as open source in spring 2 11 The system consists of the parallel data programming model PACT an extension of the MapReduce programming model for the specification of complex data intensive tasks in the cloud and the elastic massively parallel execution engine Nephele a Dryad like parallel data processor Furthermore I give a demo of the most recent Stratosphere release And finally I report on future enhancements for Stratosphere particularly for the compilation optimization and parallel execution of data intensive operations in the system Speaker Bio Since October 2 1 Thomas Bodner is a Master s student at the department for Database Systems and Information Management DIMA at the Technical University of Berlin Between 2 7 and 2 1 Thomas Bodner completed the Applied Computer Science program at the University of Cooperative Education Stuttgart jointly with IBM Germany as partner In the course of his undergraduate studies he studied abroad for one semester at the Royal Melbourne Institute of Technology Australia and worked as an intern at the IBM Almaden Research Center California USA and the IBM B blingen Laboratory in Germany exploring query optimization and in memory technologies for database management systems His research interests include architectures for information management query processing and optimization benchmarking and machine learning Dec 9 2 11 Special Time Place SPEAKER Pat Helland Microsoft If You Have Too Much Data then Good Enough Is Good EnoughDetailsDate and TimeDec 9 2 11 Special Time Place 11 amLocationDBH 6 11SpeakerPat Helland Microsoft TitleIf You Have Too Much Data then Good Enough Is Good EnoughAbstractClassic database systems offer crisp answers for a relatively small amount of data These systems hold their data in one or a relatively small number of computers With a tightly defined schema and transactional consistency the results returned from queries are crisp and accurate New systems have humongous amounts of data content change rates and querying rates and take lots of computers to hold and process The data quality and meaning are fuzzy The schema if present is likely to vary across the data The origin of the data may be suspect and its staleness may vary Today s data systems coalesce data from many sources The Internet B2B and enterprise application integration EAI combine data from different places No computer is an island This large amount of interconnectivity and interdependency has led to a relaxation of many database principles In this talk consider the some of the ways in which today s answers differ from what we used to expect Speaker Bio Pat Helland has been working in distributed systems transaction processing databases and similar areas since 1978 For most of the 198 s he was the chief architect of Tandem Computers TMF Transaction Monitoring Facility which provided distributed transactions for the NonStop System With the exception of a two year stint at Amazon Helland has worked at Microsoft Corporation since 1994 where he was the architect for Microsoft Transaction Server and SQL Service Broker Until September 2 11 he was working on Cosmos a distributed computation and storage system that provides back end support for Bing Pat recently relocated to San Francisco with his wife to be close to the grandchildren and to explore new opportunities in Big Data and or Cloud Computing Nov 18 2 11SPEAKER Yi Pan and Masood Mortazavi Yahoo Scalability and Programming Model in Serving Storage SystemsDetailsDate and TimeNov 18 2 11 3pmLocationDBH 3 11SpeakerYi Pan and Masood Mortazavi Yahoo TitleScalability and Programming Model in Serving Storage SystemsAbstractWe will review some of the storage technologies Yahoo applications use in Yahoo s cloud platform These serving storage systems can scale to extremely large numbers of records After discussing overall architecture of these scalable storage systems we will focus on Sherpa PNUTS Sherpa is a multi tenant distributed highly elastic key value store with a well defined transaction semantics that serves data for 1 s of Yahoo applications To exemplify the type of scalability challenges we face we will describe how we re evolving Sherpa along various dimensions We will then focus on the programmability dimension and explain how we have implemented a highly scalable eventually consistent indexing system for Sherpa Design decisions we have made to balance concerns related to consistency and availability will be discussed and we hope to elucidate the basic questions that come up repeatedly when evolving such massively scalable systems while they are in operation Speaker BioDr Masood Mortazavi works as a senior principal architect at Yahoo s serving storage systems group His interests include distributed systems scalability multi tenancy and cloud serving systems Masood has also worked for Huawei Technologies Sun Microsystems Tecknowledge and Hughes Aircrafts Masood s LinkedIn profile can be found here http www linkedin com in mortazavi At Yahoo he helps advance cloud platform and storage technologies Dr Yi Pan graduated with a Ph D degree in computer science from University of California at Irvine He got his B S and M S Degree from Fudan University in Shanghai China His main interests expand across many areas in large scale distributed computer networks and applications Currently he works as a principal software engineer in Yahoo s Cloud Platform Group His main goal is to push forward Yahoo s state of art cloud storage systems with innovative features Nov 4 2 11SPEAKER Thomas BodnerMyriad Parallel Data Generation on Shared Nothing ArchitecturesDetailsDate and TimeNov 4 2 11 3 3 pmLocationDBH 3 11SpeakerThomas BodnerTitleMyriad Parallel Data Generation on Shared Nothing ArchitecturesAbstract The need for efficient data generation for the purposes of testing and benchmarking newly developed data intensive computing systems has increased with the emergence of big data problems As synthetic data model specifications evolve over time the data generator programs implementing these models have to be continuously adapted a task that might become complex as the set of model constraints grows This talk presents Myriad a new parallel data generation toolkit Data generators created with the toolkit can produce very large datasets by exploiting a completely parallel execution model while at the same time maintain cross partition dependencies correlations and distributions in the generated data In addition I report on our efforts towards a benchmark suite for large scale parallel analysis systems that uses Myriad for the generation of large social network graphs and OLAP style relational datasets Speaker Bio Since October 2 1 Thomas Bodner is a Master s student at the department for Database Systems and Information Management DIMA at the Technical University of Berlin Between 2 7 and 2 1 Thomas Bodner completed the Applied Computer Science program at the University of Cooperative Education Stuttgart jointly with IBM Germany as partner In the course of his undergraduate studies he studied abroad for one semester at the Royal Melbourne Institute of Technology Australia and worked as an intern at the IBM Almaden Research Center California USA and the IBM B blingen Laboratory in Germany exploring query optimization and in memory technologies for database management systems His research interests include architectures for information management query processing and optimization benchmarking and machine learning Oct 21 2 11SPEAKER David Lomet Microsoft Research Deuteronomy Transaction Support for Cloud DataDetailsDate and TimeOct 21 2 11 3pmLocationDBH 3 11SpeakerDavid Lomet Microsoft Research TitleDeuteronomy Transaction Support for Cloud DataAbstractThe Deuteronomy system supports efficient and scalable ACID transactions in the cloud by decomposing the storage engine into a a transactional component TC that manages transactions and their logical concurrency control and undo redo recovery and b a data component DC that knows about the access methods and supports a record oriented interface with atomic operations but knows nothing about transactions The Deuteronomy TC can be applied to data anywhere in the cloud local etc with a variety of deployments for both the TC and DC components In this talk we first describe the architecture of our TC and the considerations that led to it We next describe the contract between TC and DC how we changed the operation protocol to simplify it and make it more efficient We have implemented both TC and multiple DCs and will describe our TC implementation in detail We will end a few words about observed performance and scalability Speaker Bio David Lomet is a principal researcher managing the Microsoft Research Database Group Earlier he worked at Digital IBM Research and Wang Institute He has a CS Ph D from the University of Pennsylvania He is author of over 1 papers two SIGMOD best papers and has 45 patents He has served on program committees SIGMOD PODS VLDB ICDE was ICDE 2 PC co chair VLDB 2 6 PC core chair and is on the ICDE Steering Committee the VLDB Board is TCDE Chair and has been an editor for TODS VLDBJ and JDPD He is the Data Engineering Bulletin EIC for which he received the SIGMOD Contributions Award He received IEEE Golden Core Outstanding and Meritorious Service Awards and is a Fellow of IEEE ACM and AAAS Oct 21 2 11 Special Time Place SPEAKER Danny Sullivan Editor In Chief Search Engine Land From Search 1 to Search 4 DetailsDate and TimeOct 21 2 11 Special Time Place 11amLocationDBH 6 11SpeakerDanny Sullivan Editor In Chief Search Engine Land TitleFrom Search 1 to Search 4 AbstractWhen search engines first began they focused on crawling web pages and words on the page ranking analysis That system quickly failed being far too easy to game Search 2 gave us ranking where links were used as votes Search 3 a third generational system introduced blending vertical search results with web matches Currently underway the fourth generational trend of Search 4 taps into human signals from social networks and personalization to refine search results The how and why of this evolution has unfolded Speaker BioWidely considered a leading search engine guru Danny Sullivan has been helping webmasters marketers and everyday web users understand how search engines work for over a decade Danny s expertise about search engines is often sought by the media and he has been quoted in places like The Wall St Journal USA Today The Los Angeles Times Forbes The New Yorker and Newsweek and ABC s Nightline Danny began covering search engines in late 1995 when he undertook a study of how they indexed web pages The results were published online as A Webmaster s Guide To Search Engines a pioneering effort to answer the many questions site designers and Internet publicists had about search engines Danny currently heads up Search Engine Land as editor in chief which covers all aspects of search marketing and search engine news Danny also serves as Third Door Media s chief content officer which owns Search Engine Land and the SMX Search Marketing Expo conference series Danny also maintains a personal blog called Daggle and microblogs on Twitter dannysullivan Oct 14 2 11SPEAKER Tyson Condie Yahoo Research Scal a ing up Machine Learning and Graph based AnalyticsDetailsDate and TimeOct 14 2 11 3pmLocationDBH 3 11SpeakerTyson Condie Yahoo Research TitleScal a ing up Machine Learning and Graph based AnalyticsAbstract Machine learning practitioners are increasingly interested in applying their algorithms to Big Data Unfortunately current high level languages for data analytics e g Hive Pig Sawzall Scope do not fully cover this domain One key missing ingredient is the means to efficiently support iteration over the data Zaharia et al were the first to answer this call from a systems perspective with Spark Spark adds the notion of a working set to data parallel workflows and has published speed ups of 3 x over Hadoop MapReduce for many machine learning and graph algorithms Unfortunately Spark does cover the whole pipeline of Big Data analytics at Yahoo it is common to compose Pig MPI and direct MapReduce program modules into workflows This fractioning of individual processing steps can be a major pain e g for optimization debugging and code readability Our prescription to this dilemma is a new DSL for data analytics called ScalOps Like Pig ScalOps combines the declarative style of SQL and the low level procedural style of MapReduce Like Spark ScalOps can optimize its runtime the Hyracks parallel database engine for repeated access to data collections ScalOps is part of a broader research agenda to explore new abstractions for machine learning and graph based analytics In this talk I will present example workflows from the machine learning domain expressed in ScalOps and their translation to Hyracks recursive query plans Sept 3 2 11SPEAKER Grad studentsSystem DemoDetailsDate and TimeSept 3 2 11 3pmLocationDBH 3 11SpeakerGrad studentsTitleSystem DemoSept 23 2 11SPEAKER ISG memebersISG GatheringDetailsDate and TimeSept 23 2 11 3pmLocationDBH 3 11SpeakerISG memebersTitleISG GatheringJune 3 2 11SPEAKER Donald KossmanPredictable Performance for Unpredictable WorkloadsDetailsDate and TimeJune 3 2 11 2pmLocationDBH 3 11SpeakerDonald KossmanTitlePredictable Performance for Unpredictable WorkloadsAbstractThis talk presents the design of SwissBox SwissBox is a database appliance designed to process thousands of concurrent queries and updates with bounded query response times and strict data freshness guarantees The system was designed to aggressively share operations between concurrent queries and updates This talk shows the design of the storage manager called Crescando and the design of the query processor called SharedDB Furthermore the talk presents the results of performance experiments with workloads from an airline reservation system Speaker BioDonald Kossmann is a professor for Computer Science at ETH Zurich Switzerland He received his MS from the University of Karlsruhe and completed his PhD at the University of Aachen After that he held positions at the University of Maryland the IBM Almaden Research Center the University of Passau the University of Munich and the University of Heidelberg He is an ACM fellow member of the board of trustees of the VLDB endowment and was the program committee chair of the ACM SIGMOD Conf 2 9 He is a co founder of i TV T 1998 XQRL Inc acquired by BEA in 2 2 and 28msec Inc 2 7 His research interests lie in the area of databases and information systems May 2 2 11SPEAKER Ronen VaisenbergScheduling and Actuating Camera Networks to Maximize Event DetectionDetailsDate and TimeMay 2 2 11 2pmLocationDBH 3 11SpeakerRonen VaisenbergTitleScheduling and Actuating Camera Networks to Maximize Event DetectionAbstractA distributed camera network allows for many compelling applications such as large scale tracking face recognition occupancy monitoring or event detection In most practical systems resources are either constrained or mutually exclusive Constraints arise from network bandwidth restrictions I O and disk usage from writing images and CPU usage needed to extract features from the images Detecting events in real time requires dynamically choosing a subset of the available sensors for processing at any given time Furthermore certain camera configurations are not feasible For example a camera cannot zoom into two different regions in its field of view Zooming into a specific area in the field of view of a camera would generate a high resolution image of the region in the expense of a wider field of view Thus the field of view needs to be changed dynamically to get a higher resolution images of certain regions of the space at the expanse other regions In order to illustrate the complexity of this problem consider a face recognition application which is only interested in high resolution by means of optical zoom facial images If we always zoom into a region to look for a high res face we might miss presence of a person in different region and hence opportunity for zooming later to get the face in next time step In this talk we examine the problem of scheduling sensors for data collection and actuating them on real time to maximize some user specified objective e g detecting as much motion as possible or collect as many high resolution facial images The main idea behind our approach is the use of sensor semantics to guide the scheduling process We learn a dynamic probabilistic model of motion correlations between cameras and use the model to guide resource allocation for our sensor network Although previous work has leveraged probabilistic models for sensor scheduling our work is distinct in its focus on real time building monitoring using a camera network We validate our approach using a sensor network of a dozen cameras spread throughout a university building recording measurements of unscripted human activity over a two week period We automatically learn a semantic model of typical behaviors and show that one can significantly improve efficiency of resource allocation and actuation by exploiting this model May 13 2 11 Special SPEAKER Prof John Ousterhout Stanford RAMCloud Scalable High Performance Storage Entirely in DRAMDetailsDate and TimeMay 13 2 11 Special 11amLocationDBH 6 11SpeakerProf John Ousterhout Stanford TitleRAMCloud Scalable High Performance Storage Entirely in DRAMAbstractDisk oriented approaches to online storage are becoming increasingly problematic they do not scale gracefully to meet the needs of new large scale Web applications and improvements in disk capacity have out stripped improvements in access speed In this talk I will describe a new approach to datacenter storage called RAMCloud where information is kept entirely in DRAM and large scale systems are created by aggregating the main memories of thousands of commodity servers A RAMCloud can provide durable and available storage with 1 1 x the throughput of disk based systems and 1 1 x lower access latency By combining low latency and large scale RAMClouds will enable a new class of applications that manipulate large datasets more intensively than has ever been possible Speaker BioJohn Ousterhout is Professor Research of Computer Science at Stanford University His current research focuses on infrastructure for Web applications and cloud computing Ousterhout s prior positions include 14 years in industry where he founded two companies Scriptics and Electric Cloud preceded by 14 years as Professor of Computer Science at U C Berkeley He is the creator of the Tcl scripting language and is also well known for his work in distributed operating systems and file systems Ousterhout received a BS degree in Physics from Yale University and a PhD in Computer Science from Carnegie Mellon University He is a member of the National Academy of Engineering and has received numerous awards including the ACM Software System Award the ACM Grace Murray Hopper Award the National Science Foundation Presidential Young Investigator Award and the U C Berkeley Distinguished Teaching Award May 9 2 11 Special SPEAKER Prof Barton P MillerScaling Up to Large Really Large SystemsDetailsDate and TimeMay 9 2 11 Special 11amLocationDBH 3 11SpeakerProf Barton P MillerTitleScaling Up to Large Really Large SystemsAbstractI will discuss the problem of developing tools and middleware for large scale parallel environments We are especially interested in systems both leadership class parallel computers and clusters that have 1 s or even millions of processors The infrastructure that we have developed to address this problem is called MRNet the Multicast Reduction Network MRNet s approach to scale is to structure control and data flow in a tree based overlay network TBON that allows for efficient request distribution and flexible data reductions I will then present an overview of the MRNet design architecture and computational model and then discuss several of the applications of MRNet The applications include scalable automated performance analysis a vision clustering application and most recently an effort to develop our first petascale debugging tool STAT a scalable stack trace analyzer running currently on 1 s of processors on both the Cray XT and IBM BlueGene Speaker BioProf Barton Miller is a Professor of Computer Sciences at the University of Wisconsin Bart is a product of the UC System he received his BA degree from UC San Diego in 1977 and his MS and PhD in Computer Science from UC Berkeley in 198 and 1984 respectively His research interests include distributed and parallel program performance and tools binary code analysis and instrumentation computer security scalable systems operating systems and software testing Bart is a Fellow of the ACM May 6 2 11SPEAKER Matthias Nicola IBM A Matter of Time Temporal Data Management in DB2 for z OS DetailsDate and TimeMay 6 2 11 2pmLocationDBH 3 11SpeakerMatthias Nicola IBMTitle A Matter of Time Temporal Data Management in DB2 for z OS AbstractTime is a critical dimension in data management For many enterprises it is useful or even required to have the ability to go back in time and look at a past state of the database Many applications also need to manage time in their business records such as contract start and end dates expiration dates or effective dates to indicate that information is valid for a certain period in the past presence or future This presentation describes typical use cases for temporal data management and describes the temporal capabilities in DB2 including system time business time and bitemporal support Speaker BioMatthias Nicola is a senior software engineer at IBM s Silicon Valley Lab in San Jose CA USA He focuses on DB2 performance and benchmarking XML temporal data management in database analytics and other emerging technologies Matthias also works closely with customers and business partners to help them design optimize and implement DB2 solutions Previously Matthias worked on data warehouse performance at Informix Software Matthias received his PhD in computer science from the Technical University of Aachen Germany April 25 2 11 Special SPEAKER Prof Christos Faloutsos CMUMining Billion node GraphsDetailsDate and TimeApril 25 2 11 Special 11amLocationDBH 6 11SpeakerProf Christos Faloutsos CMUTitleMining Billion node GraphsAbstractWhat do graphs look like How do they evolve over time How to handle a graph with a billion nodes We present a comprehensive list of static and temporal laws and some recent observations on real graphs like e g eigenSpokes We present tools and specifically oddBall for discovering anomalies and patterns as well as fast algorithms for immunization Finally we present an overview of the PEGASUS system which is designed to handle billion node graphs running on top of the hadoop system Speaker BioChristos Faloutsos is a Professor at Carnegie Mellon University He has received the Presidential Young Investigator Award by the National Science Foundation 1989 the Research Contributions Award in ICDM 2 6 the SIGKDD Innovations Award 2 1 seventeen best paper awards including two test of time and four teaching awards He has served as a member of the executive committee of SIGKDD he is an ACM Fellow he has published over 2 refereed articles 11 book chapters and one monograph He holds five patents and he has given over 3 tutorials and over 1 invited distinguished lectures His research interests include data mining for graphs and streams fractals database performance and indexing for multimedia and bio informatics data April 22 2 11SPEAKER Jerome Simeon IBM Research T J WatsonAlgebraic Comprehensions Database Optimization for Web 2 Queries DetailsDate and TimeApril 22 2 11 2pmLocationDBH 3 11SpeakerJerome Simeon IBM Research T J WatsonTitleAlgebraic Comprehensions Database Optimization for Web 2 Queries AbstractDirect support for querying is becoming a must have for programming languages targeting Web 2 and Cloud development Most of those languages Microsoft s Linq University of Edinburgh s Links EPFL s Scala Yahoo s Pig Latin IBM s Thorn etc rely on the classic notion of comprehensions over collections At the language level comprehensions are a perfect choice being well understood programming constructs and capturing the expressive power of SQL iterators At the compiler level however they are at odds with database optimizers which mostly rely on relational or nested relational algebras That mismatch was clearly on display during the design of XQuery whose semantics is based on comprehensions and for which most implementations target relational backends We propose a alternative functional semantic formulation of XQuery to the one proposed by W3C which is also based on comprehensions but has the benefit of corresponding precisely to compilation into a typed algebra that supports traditional database optimizations First this provides a formal foundation for XQuery implementations that want to ensure semantics integrity with the standard along with modern database optimization techniques Also it provides key insights into the nature of database compilers that we believe is essential for the integration of database and programming languages technology We notably discover that type systems for database algebras require an original solution to the old problem of subtyping with record concatenation and that such a type system can eliminate the need for complex side conditions used in query language optimization Speaker BioJerome Simeon is a Researcher for the Scalable XML Infrastructure Group at IBM T J Watson He holds a degree in Engineering from EcolePolytechnique and a Ph D from Universite d Orsay Previously Jerome worked at INRIA from 1995 to 1999 and Bell Laboratories from 1999 to 2 4 His research interests include databases programming languages compilers and semantics with a focus on Web development He has put his work into practice in areas ranging from telecommunication infrastructure to music He is a co editor for five of the W3C XML Query specifications and has published more than 5 papers in scientific journals and international conferences He is also a project lead for the Galax open source XQuery implementation and a co author of XQuery from the Experts Addison Wesley 2 4 April 15 2 11 SPEAKER Tyson Condie Yahoo ResearchRubySky Exploring Big Data with Transparency and AdjustabilityDetailsDate and TimeApril 15 2 11 2pmLocationDBH 3 11SpeakerTyson Condie Yahoo ResearchTitleRubySky Exploring Big Data with Transparency and AdjustabilityAbstractIn this talk I will introduce a new scripting language for ad hoc exploration of large data sets called RubySky As with several prior efforts RubySky scripts execute either in a local environment or in the cloud Hadoop Typically cloud based execution is highly opaque and hands off rendering debugging and iterative code development very difficult RubySky on the other hand aims for a more transparent and adjustable paradigm It includes the ability to peek into intermediate cloud execution pathways integrated as a first class language construct Also integrated into the language is a way for the user to make last minute code revisions at any point at which troublesome data is encountered in the cloud Combined these features aim to improve usability for users who develop and run single use scripts that explore new data sets This is joint work with Christopher Olston at Yahoo Research April 1 2 11 SPEAKER Doug Terry Microsoft ResearchReplicated Data Consistency Explained through BaseballDetailsDate and TimeApril 1 2 11 2pmLocationDBH 3 11SpeakerDoug Terry Microsoft ResearchTitleReplicated Data Consistency Explained through BaseballAbstract A variety of relaxed consistency models for replicated data have been proposed and studied as an alternative to one copy serializability and some of these are being used in cloud storage systems The designers of such systems particularly avoid two phase commit for updates to geo replicated data that spans multiple data centers on different continents Instead many cloud services including systems from Amazon Yahoo and Microsoft have adopted techniques that provide eventual consistency This talk explores the hows and whys of different consistency models The discussion will be driven by a simple example maintaining the score of a baseball game We ll see that people with various roles in the game can tolerate and benefit from different types of consistency when accessing the score Speaker BioDoug Terry is a Principal Researcher in the Microsoft Research Silicon Valley lab His research focuses on the design and implementation of novel distributed systems including mobile and cloud services He currently is serving as Chair of ACM s Special Interest Group on Operating Systems SIGOPS and as a member of the ACM Council Prior to joining Microsoft Doug was the co founder and CTO of a start up company named Cogenia Chief Scientist of the Computer Science Laboratory at Xerox PARC and an Adjunct Professor in the Computer Science Division at U C Berkeley where he still occasionally teaches a graduate course on distributed systems Doug has a Ph D in Computer Science from U C Berkeley and is an ACM Fellow Mar 31 2 11 SPEAKER Doug Terry Microsoft ResearchCimbiosys Content based Replication for Mobile Devices and the CloudDetailsDate and TimeMar 31 2 11 11amLocationDBH 6 11SpeakerDoug Terry Microsoft ResearchTitleCimbiosys Content based Replication for Mobile Devices and the CloudAbstract As people increasingly use mobile devices and cloud services to share large data collections exploiting communication proximity and selectively replicating content is essential Cimbiosys is a replicated storage platform that permits each device to define its own content based filtering criteria and to exchange data directly with other devices This talk focuses on the key challenge of ensuring eventual consistency in the face of fluid network connectivity redefinable content filters and arbitrary updates Notably Cimbiosys guarantees that each device eventually stores precisely those items whose latest version matches its custom filter and represents its replication specific metadata in a compact form resulting in low data synchronization overhead This permits ad hoc replication between newly encountered devices and frequent synchronization between established partners even over low bandwidth wireless networks or across geo distributed data centers This talk will be a Ted and Janice Smith Distinguished lecture and not at the normal time or place for ISG Seminars Speaker BioDoug Terry is a Principal Researcher in the Microsoft Research Silicon Valley lab His research focuses on the design and implementation of novel distributed systems including mobile and cloud services He currently is serving as Chair of ACM s Special Interest Group on Operating Systems SIGOPS and as a member of the ACM Council Prior to joining Microsoft Doug was the co founder and CTO of a start up company named Cogenia Chief Scientist of the Computer Science Laboratory at Xerox PARC and an Adjunct Professor in the Computer Science Division at U C Berkeley where he still occasionally teaches a graduate course on distributed systems Doug has a Ph D in Computer Science from U C Berkeley and is an ACM Fellow Mar 25 2 11 SPEAKER Alexander Behm UCI PhD studentAnswering Approximate String Queries on Large Data Sets Using External MemoryDetailsDate and TimeMar 25 2 11 2pmLocationDBH 3 11SpeakerAlexander Behm UCI PhD studentTitleAnswering Approximate String Queries on Large Data Sets Using External MemoryAbstractAn approximate string query is to find from a collection of strings those that are similar to a given query string Answering such queries is important in many applications such as data cleaning and record linkage where errors could occur in queries as well as the data Many existing algorithms have focused on in memory indexes In this paper we investigate how to efficiently answer such queries in a disk based setting by systematically studying the effects of storing data and indexes on disk We devise a novel physical layout for an inverted index to answer queries and we study how to construct it with limited buffer space To answer queries we develop a cost based adaptive algorithm that balances the I O costs of retrieving candidate matches and accessing inverted lists Experiments on large real datasets verify that simply adapting existing algorithms to a disk based setting does not work well and that our new techniques answer queries efficiently Further our solutions significantly outperform a recent tree based index BED tree This talk is a ICDE practice talk Mar 18 2 11 SPEAKER Pinaki SinhaSummarization of Personal Photo CollectionsDetailsDate and TimeMar 18 2 11 2pmLocationDBH 3 11SpeakerPinaki SinhaTitleSummarization of Personal Photo CollectionsAbstractThe volume of personal photos hosted on photo archives and social sharing platforms has been increasing exponentially According to recent estimates 6 Billion photos are uploaded on Facebook per month It is difficult to get an overview of a large collection of personal photos without browsing though the entire database manually In this talk I will discuss a framework to generate representative subset summaries from photo collections present on personal archives or social networks I will define salient properties of an effective photo summary and model summarization as an optimization of these properties given the size constraints Computer vision and IR based techniques will be used to generate summaries that look good as well as are informative I will also introduce information theory based metrics for evaluating photo summaries based on their information content and the ability to satisfy user s information needs I will also discuss the manual evaluation experiments that were done to evaluate summaries Mar 11 2 11 SPEAKER Dmitri V Kalashniknov Entity resolutionDetailsDate and TimeMar 11 2 11 2pmLocationDBH 3 11Speaker Dmitri V Kalashniknov TitleEntity resolutionMar 4 2 11 SPEAKER Rares Vernica Efficient Processing of Set Similarity Joins on Large ClustersDetailsDate and TimeMar 4 2 11 2pmLocationDBH 3 11SpeakerRares VernicaTitle Efficient Processing of Set Similarity Joins on Large ClustersFeb 23 2 11 SPEAKER Dr Terence SimGetting More From FisherDetailsDate and TimeFeb 23 2 11 3pmLocationDBH 3 11Speaker Dr Terence SimTitleGetting More From FisherAbstractThe Fisher Linear Discriminant FLD is commonly used in classification to find a subspace that maximally separates class patterns according to the Fisher Criterion It was previously proven that a pre whitening step can be used to truly optimize the Fisher Criterion In this talk we show that more insight and more applications may be derived from this classical technique First we explore the subspaces induced by this whitened FLD In particular we show how the Identity Space and Variation Space are useful for decomposing and representing data We give sufficient conditions for these spaces to exist Through experiments we also show how these spaces may be used for classification and image synthesis Second we further extend classical Fisher to handle data exhibiting multiple factors modes e g face images that exhibit personal identity illumination and pose We call our method Multimodal Discriminant Analysis MMDA which is useful for decomposing a dataset into independent modes For face images MMDA effectively separates identity illumination and pose into mutually orthogonal subspaces MMDA is based on maximizing the Fisher Criterion on all modes simultaneously and is therefore well suited for multimodal and mode invariant pattern recognition We also show that MMDA may be used for dimension reduction and for synthesizing face images under novel illumination and even novel personal identity Speaker BioTerence Sim is an Asst Prof at the School of Computing National University of Singapore He teaches an undergraduate course in computer vision as well as a graduate course in multimedia fundamentals For research he works primarily in these areas face recognition biometrics and computational photography He is also interested in computer vision problems in general such as shape from shading photometric stereo object recognition On the side he dabbles with some aspects of music processing such as polyphonic music transcription Dr Sim serves as Vice Chairman of the Biometrics Technical Committee BTC Singapore and Chairman of the Cross Jurisdictional and Societal Aspects Working Group WG6 within the BTC The interesting issues here are the legal and privacy aspects of using biometrics He also serves as Vice President of the Pattern Recognition and Machine Intelligence Association PREMIA a national professional body for pattern recognition Dr Sim obtained his PhD from Carnegie Mellon in 2 2 his MSc from Stanford University in 1991 and his SB from MIT in 199 Feb 16 2 11SPEAKER Laura Haas IBM New Principles for Information Integration DetailsDate and TimeFeb 16 2 11 11amLocationDBH 4 11Speaker Laura Haas IBM TitleNew Principles for Information Integration Abstract Ten years ago Clio introduced nonprocedural schema mappings to describe the relationship between data in heterogeneous schemas This enabled powerful tools for mapping discovery and integration code generation greatly simplifying the integration process However further progress is needed We see an opportunity to raise the level of abstraction further and propose two new principles that the next generation of integration systems should embody Holistic information integration supports iteration across the various integration tasks leveraging information about both schema and data to improve the integrated result Integration independence allows applications to be independent of how when and where information integration takes place making materialization and the timing of transformations an optimization decision that is transparent to applications This talk introduces these principles and describes some promising recent work in these directions Speaker Bio Laura Haas is an IBM Fellow and has been director of computer science at IBM Almaden Research Center since 2 5 Previously Dr Haas was responsible for Information Integration Solutions IIS architecture in IBM s Software Group after leading the IIS development team through its first two years She joined the development team in 2 1 as manager of DB2 UDB Query Compiler development Before that Dr Haas was a research staff member and manager at the Almaden lab for nearly twenty years In IBM Research she worked on and managed a number of exploratory projects in distributed database systems Dr Haas is best known for her work on the Starburst query processor from which DB2 UDB was developed on Garlic a system which allowed federation of heterogeneous data sources and on Clio the first semi automatic tool for heterogeneous schema mapping Garlic technology married with DB2 UDB query processing is the basis for the IBM WebSphere Information Server s federation capabilities while Clio capabilities are a core differentiator in IBM s Rational Data Architect Dr Haas has received several IBM awards for Outstanding Technical Achievement and Outstanding Innovation and an IBM Corporate Award for her work on federated database technology In 2 1 she was recognized with the Anita Borg Institute Technical Leadership Award She is a member of the National Academy of Engineering and the IBM Academy of Technology an ACM Fellow and Vice Chair of the board of the Computing Research Association Dr Haas received her PhD from the University of Texas at Austin and her bachelor degree from Harvard University Feb 4 2 11 POSTPONED SPEAKER Amy VoidaHomebrew DatabasesDetailsDate and TimeFeb 4 2 11 POSTPONED 2pmLocationDBH 3 11Speaker Amy VoidaTitleHomebrew Databases For more information on CS distinguished lectures please visit Computer Science Department Seminar Series topLast Updated on January 7 2 11", "_id": "http://isg.ics.uci.edu/events.html", "title": "isg", "html": "<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\" xml:lang=\"en\"><head><meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n<link rel=\"stylesheet\" type=\"text/css\" href=\"isg.css\"></link><title>ISG</title></head><body><div id=\"container\"><div id=\"header\"><div id=\"logosection\"><table><tr><td style=\"padding-left:15px;\"><a href=\"http://www.ics.uci.edu/~rares/isg-logo/\"><img src=\"images/isg-website.png\" height=\"100\"></img></a></td><td><h1>ISG</h1><h2><a href=\"http://isg.ics.uci.edu\">Information Systems Group</a></h2><h3><a href=\"http://www.ics.uci.edu\">Bren School of ICS</a></h3><h4><a href=\"http://www.uci.edu\">UC Irvine</a></h4></td></tr></table></div><div id=\"picture\"><img src=\"images/ics3.jpg\" height=\"80\"></img></div></div><div id=\"navigation\"><ul><li class=\"\"><a href=\"index.html\">About</a></li><li class=\"\"><a href=\"news.html\">News</a></li><li class=\"\"><a href=\"people.html\">People</a></li><li class=\"\"><a href=\"research.html\">Research</a></li><li class=\"\"><a href=\"publications.html\">Publications</a></li><li class=\"selected\"><a href=\"events.html\">Events</a></li><li class=\"\"><a href=\"courses.html\">Courses</a></li><li class=\"\"><a href=\"partnerships.html\">Partnerships</a></li><li class=\"\"><a href=\"visitors.html\">Visitors</a></li></ul></div><div id=\"subcontent\"><div class=\"box\"><ul class=\"menublock\"><li><a href=\"#seminars\">ISG Seminars</a></li><li><a href=\"#invited\">Invited Talks</a><ul><li><a href=\"#upcomingE\">Upcoming</a></li><li><a href=\"#pastE\">Past</a></li></ul></li></ul></div></div><div class=\"content\"><h2 id=\"seminars\">ISG Seminars</h2><h3>Regular ISG seminar </h3>Time: Every Fri afternoon, 3pm - 4pm; Location: Bren Hall 3011\n\t\t<p>2009-2010 ISG Scalable Data Management Seminar Series <a href=\"http://isg.ics.uci.edu/scalable_dm_lectures2009-10.html\">[talks]</a></p><p>Support for the ISG Seminar Series from Yahoo! is gratefully acknowledged.\n        </p></div><div class=\"content\"><h2 id=\"invited\">Invited Talks</h2><h3 id=\"upcomingE\"> Upcoming Events </h3><table id=\"tb1\"><tr><td><div class=\"eventDate\">Feb. 20, 2015</div></td><td><div class=\"eventInfor\">SPEAKER: Karthik Ramasamy (Twitter)</div><div class=\"eventInfor\"> Real Time Analytics@Twitter </div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99299\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99299\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Feb. 20, 2015 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Karthik Ramasamy (Twitter)</td></tr><tr><td><b>Title</b></td><td> Real Time Analytics@Twitter </td></tr><tr><td><b>Abstract</b></td><td>Real time analytics seems to be a buzz word these days. Twitter identified the need for real time analytics early on and invested in a massive data pipeline that collects, aggregates, processes large volumes of data in real time. At the heart of the pipeline is Twitter Storm, a real-time stream processing engine widely used in Twitter. Storm is used for real-time data analytics, time series aggregation, and powering real-time features like trending topics. In this talk, we will give an overview of real time analytics, discuss the twitter real time data pipeline and how Storm is used for extracting analytics. We will also discuss the challenges we faced and lessons we have learned while building this infrastructure at Twitter. </td></tr><tr><td><b>Speaker Bio</b></td><td>Karthik is the engineering manager and technical lead for Real Time Analytics at Twitter. He has two decades of experience working in parallel databases, big data infrastructure and networking. He cofounded Locomatix, a company that specializes in real timestreaming processing on Hadoop and Cassandra using SQL that was acquired by Twitter. Before Locomatix, he had a brief stint with Greenplum where he worked on parallel query scheduling. Greenplum was eventually acquired by EMC for more than $300M. Prior to Greenplum, Karthik was at Juniper Networks where he designed and delivered platforms, protocols, databases and high availability solutions for network routers that are widely deployed in the Internet. Before joining Juniper at University of Wisconsin, he worked extensively in parallel database systems, query processing, scale out technologies, storage engine and online analytical systems. Several of these research were spun as a company later acquired by Teradata.\n             \n             He is the author of several publications, patents and one of the best selling book \"Network Routing: Algorithms, Protocols and Architectures.\" He has a Ph.D. in Computer Science from UW Madison with a focus on databases.</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Feb. 27, 2015</div></td><td><div class=\"eventInfor\">SPEAKER: Fatma Ozcan (IBM Research - Almaden)</div><div class=\"eventInfor\">SQL Comes Back, But This is not Your Father's DBMS!</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99300\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99300\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Feb. 27, 2015 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Fatma Ozcan (IBM Research - Almaden)</td></tr><tr><td><b>Title</b></td><td>SQL Comes Back, But This is not Your Father's DBMS!</td></tr><tr><td><b>Abstract</b></td><td>Recent years have seen the resurgence of SQL; this time in the context of Big Data Platforms. SQL-on-Hadoop\n             was one of the hottest topics in 2014, with many newcomers, and adaptations of old systems. There\n             are significant differences between the new incarnation of SQL systems, and the traditional enterprise\n             warehouses. First, semi-structured data is inherent in the Hadoop data as the data frequently\n             comes from noSQL and web sources. Hence JSON data and complex types are more important than in \n             traditional systems. Second, SQL is only one of the steps in the bigger analytical flows. This requires\n             SQL to interact with other frameworks, including streaming, ETL, as well as advanced analytics and \n             machine learning. Finally, we see more user-defined function in big data platforms, because\n             a lot of business logic needs to be executed closer to the data. \n              \n              In this talk, I will first describe IBM Big SQL, an SQL-on-Hadoop offering that works on all Hadoop\n              data formats. I will describe how we adapted IBM database technology to this new world. In the second\n              part of the talk, I will describe a couple of research projects in IBM Almaden that focus on new aspects\n              of the Hadoop SQL engines and the big data eco-system.</td></tr><tr><td><b>Speaker Bio</b></td><td>Fatma \u00d6zcan is a Research Staff Member and a manager at IBM Almaden\n             Research Center. Her current research focuses on platforms and infra-structure for large-scale\n             data analysis, Hadoop and database integration, and query optimization for semi-structured data. \n             Dr \u00d6zcan got her PhD degree in computer science from University of Maryland, College Park. She has\n             over 10 years of experience in semi-structured and structured data management, query processing and\n             optimization, and has delivered core technologies into IBM DB2 and BigInsights products. \n             She is the co-author of the book \"Heterogeneous Agent Systems\", and \n             co-author of several conference papers and patents. \n             She has chaired program committees for various conferences, and \n             served on NSF (National Science Foundation) panels. She is a member of the ACM.</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Mar. 6, 2015</div></td><td><div class=\"eventInfor\">SPEAKER: Raman Grover (AsterixDB)</div><div class=\"eventInfor\"></div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99301\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99301\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Mar. 6, 2015 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Raman Grover (AsterixDB)</td></tr><tr><td><b>Title</b></td><td></td></tr><tr><td><b>Abstract</b></td><td></td></tr><tr><td><b>Speaker Bio</b></td><td></td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Mar. 13, 2015</div></td><td><div class=\"eventInfor\">SPEAKER: Lada Adamic, David Kempe, Mark Handcock, Carter Butts</div><div class=\"eventInfor\">Networks, Algorithms, Statistics and Social Science (Data Science Initiative Sponsored Event)</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99302\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99302\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Mar. 13, 2015 10am - 5pm</td></tr><tr><td><b>Location</b></td><td>Calit2 Auditorium</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Lada Adamic, David Kempe, Mark Handcock, Carter Butts</td></tr><tr><td><b>Title</b></td><td>Networks, Algorithms, Statistics and Social Science (Data Science Initiative Sponsored Event)</td></tr><tr><td><b>Abstract</b></td><td>See http://datascience.uci.edu/event-registration/?ee=14 for more details</td></tr><tr><td><b>Speaker Bio</b></td><td></td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Apr. 10, 2015</div></td><td><div class=\"eventInfor\">SPEAKER: Liuba Shrira (Brandeis University)</div><div class=\"eventInfor\">Modular and efficient past state protocols for transactional systems</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99305\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99305\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Apr. 10, 2015 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Liuba Shrira (Brandeis University)</td></tr><tr><td><b>Title</b></td><td>Modular and efficient past state protocols for transactional systems</td></tr><tr><td><b>Abstract</b></td><td>The remarkable drop in storage costs makes it possible and attractive to capture past application states \n             and store them for a long time.\n             This opens the possibility that kinds of demanding analysis like forecasting, formerly dependent on\n             data warehouses and temporal databases, can become available to everyday applications in off-the-shelf data stores. The challenge is how to organize past states so that they are ``not in the way'' and ``always there'' when needed.\n             \n             Our  approach, called Retro, integrates a low-level consistent snapshot system into a data store\n             storage manager, allowing to run unmodified data store programs against the snapshots, \n             side by side with programs running against the current state. The approach is attractive for several reasons.\n             An application can take snapshots efficiently with any frequency, keep them indefinitely,\n             or garbage-collect them at low cost, a useful feature in long-lived systems. \n             A principled methodology derives the snapshot protocols from the native data store storage manager mechanisms, allowing to implement the snapshot system in a modular way,\n             without extensive modifications to the data store internals, making the approach suitable in off-the-shelf data \n             stores.\n             The talk will describe the new techniques that underly Retro\n             and present preliminary performance results from a prototype we built in Berkeley DB, indicating Retro\n             is efficient, imposing moderate performance penalty on the native data store, on expected common workloads. </td></tr><tr><td><b>Speaker Bio</b></td><td>Liuba Shrira is a Professor in the Computer Science Department at Brandeis University, \n             and is affiliated with the Computer Science and Artificial Intelligence Laboratory at MIT. \n             She received her Ph.D. from Technion, Israeli Institute of Technology, and\n             has been affiliated with Microsoft Research, Cambridge, UK, Microsoft Research Asia, Beijing, and Computer Science Department, in the Technion, Haifa.\n             Her research interests span aspects of design and implementation of distributed systems and especially storage systems. \n             This includes fault-tolerance, availability and performance issues. Her recent focus is on long-lived transactional  storage, time travel (in storage), software upgrades, and support for collaborative access to long-lived objects.</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Apr. 17, 2015</div></td><td><div class=\"eventInfor\">SPEAKER: Xifeng Yan (UCSB)</div><div class=\"eventInfor\"></div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99306\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99306\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Apr. 17, 2015 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Xifeng Yan (UCSB)</td></tr><tr><td><b>Title</b></td><td></td></tr><tr><td><b>Abstract</b></td><td></td></tr><tr><td><b>Speaker Bio</b></td><td></td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">May 1, 2015 (Special Time\\Place)</div></td><td><div class=\"eventInfor\">SPEAKER: C. Mohan (IBM Research - Almaden)</div><div class=\"eventInfor\"></div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99308\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99308\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>May 1, 2015 (Special Time\\Place) 11 am</td></tr><tr><td><b>Location</b></td><td>DBH 6011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>C. Mohan (IBM Research - Almaden)</td></tr><tr><td><b>Title</b></td><td></td></tr><tr><td><b>Abstract</b></td><td></td></tr><tr><td><b>Speaker Bio</b></td><td></td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">May 1, 2015</div></td><td><div class=\"eventInfor\">SPEAKER: C. Mohan (IBM Research - Almaden)</div><div class=\"eventInfor\"></div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99309\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99309\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>May 1, 2015 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>C. Mohan (IBM Research - Almaden)</td></tr><tr><td><b>Title</b></td><td></td></tr><tr><td><b>Abstract</b></td><td></td></tr><tr><td><b>Speaker Bio</b></td><td></td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">May 29, 2015 (Special Time\\Place)</div></td><td><div class=\"eventInfor\">SPEAKER: Michael Franklin, UC Berkeley Computer Science</div><div class=\"eventInfor\">Big Data, Data Science, and other Buzzwords that Really Matter</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99323\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99323\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>May 29, 2015 (Special Time\\Place) 11 am</td></tr><tr><td><b>Location</b></td><td>DBH 6011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Michael Franklin, UC Berkeley Computer Science</td></tr><tr><td><b>Title</b></td><td>Big Data, Data Science, and other Buzzwords that Really Matter</td></tr><tr><td><b>Abstract</b></td><td>Data is all the rage across industry and across campuses.  While it may be temping to dismiss the buzz as just another spin of the hype cycle, there are substantial shifts and realignments underway that are fundamentally changing how Computer Science, Statistics and virtually all subject areas will be taught, researched, and perceived as  disciplines.  In this talk I will give my personal perspectives on this new landscape based on experiences organizing a large, industry-engaged academic Computer Science research project (the AMPLab), in helping to establish a campus-wide Data Science research initiative (the Berkeley Institute for Data Science), and my participation on a campus task force charged with mapping out Data Science Education for all undergraduates at Berkeley.</td></tr><tr><td><b>Speaker Bio</b></td><td>Michael Franklin is the Thomas M. Siebel Professor of Computer Science and Chair of the Computer Science Division of the EECS Department at UC Berkeley.   He is director of the Berkeley AMPLab, a 70+ person effort fusing scalable computing, machine learning, and human computation to make sense of data at scale.   AMPLab software including: Spark, Shark, and Mesos, plays a significant role in the emerging Big Data ecosystem. The lab is funded by an NSF CISE Expeditions Award, the Darpa XData program, and 26 companies including founding sponsors Amazon Web Services, Google, and SAP.</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Jun 5, 2015</div></td><td><div class=\"eventInfor\">SPEAKER: Michael Carey (UCI)</div><div class=\"eventInfor\"></div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99324\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99324\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Jun 5, 2015 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Michael Carey (UCI)</td></tr><tr><td><b>Title</b></td><td></td></tr><tr><td><b>Abstract</b></td><td></td></tr><tr><td><b>Speaker Bio</b></td><td></td></tr></table></div><div style=\"height: 5px;\"></div></td></tr></table></div><div class=\"content\"><h3 id=\"pastE\"> Past Events </h3><table id=\"tb2\"><tr><td><div class=\"eventDate\">Feb. 13, 2015</div></td><td><div class=\"eventInfor\">SPEAKER: Yannis Papakonstantinou (UCSD)</div><div class=\"eventInfor\">The SQL++ Query Language: Support for native JSON, while backwards-compatible with SQL</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99298\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99298\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Feb. 13, 2015 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Yannis Papakonstantinou (UCSD)</td></tr><tr><td><b>Title</b></td><td>The SQL++ Query Language: Support for native JSON, while backwards-compatible with SQL</td></tr><tr><td><b>Abstract</b></td><td>SQL-on-Hadoop, NewSQL and NoSQL databases provide semi-structured data models (typically JSON-based). They now drive towards declarative, SQL-alike query languages. However, their idiomatic, non-SQL language constructs, the many variations and the lack of formal syntax and semantics pose problems. Notably, database vendors end up with unclear semantics and complicated implementations, as they add one feature at-a-time.\n             \n             The presented SQL++ semi-structured data model bridges JSON and the SQL data model. The SQL++ query language is backwards compatible with SQL, while supporting native JSON. SQL++ includes configuration options that describe different options of language semantics and formally capture the variations of existing database languages. SQL++ is unifying: By appropriate choices of configuration options, the SQL++ semantics can morph into the semantics of any of eleven popular semistructured databases, which we surveyed, as the experimental validation shows. In this way, SQL++ allows a formal characterization of the capabilities of the emerging query languages.\n             \n             We briefly discuss the key role of SQL++ and SQL++ Incremental View Maintenance in the FORWARD application and visualization development platform. SQL++ also is the query language of the FORWARD middleware query processor. We briefly discuss issues and opportunities in federated queries over SQL and non-SQL database. </td></tr><tr><td><b>Speaker Bio</b></td><td>Yannis Papakonstantinou is a Professor of Computer Science and Engineering at the University of California, San Diego. His research is in the intersection of data management technologies and the web, where he has published over ninety research articles and received over 10,000 citations. He has given multiple tutorials and invited talks, has served on journal editorial boards and has chaired and participated in program committees for many international conferences and workshops. He also teaches for UCSD's Master of Advanced Studies in Data Science.\n             \n             Yannis enjoys to commercialize his research and to inform his research accordingly. He was the CEO and Chief Scientist of Enosys Software, which built and commercialized an early Enterprise Information Integration platform for structured and semistructured data, which became part of BEA's Aqualogic. His lab's recent FORWARD platform is in use by UCSD and commercial applications. He is in the technical advisory board of Brightscope Inc and GraphSQL Inc. </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Feb. 6, 2015</div></td><td><div class=\"eventInfor\">SPEAKER: Ansgar Scherp</div><div class=\"eventInfor\">Extraction and Analyses of Schema Information on the Linked Open Data Cloud</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99297\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99297\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Feb. 6, 2015 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Ansgar Scherp</td></tr><tr><td><b>Title</b></td><td>Extraction and Analyses of Schema Information on the Linked Open Data Cloud</td></tr><tr><td><b>Abstract</b></td><td>The Linked Open Data (LOD) cloud interlinks information about entities from different data sources and across various domains using the Resource Description Framework (RDF). In contrast to traditional relational databases, the LOD cloud does not provide a fixed, pre-defined schema. Rather, RDF allows for flexibly modeling the data schema by attaching RDF types to the entities and by using domain-specific RDF properties to describe the entities. The talk presents recent developments on the extraction and analysis of schema information from the LOD cloud. For example, with SchemEX, we have developed an efficient approach and tool for a stream-based extraction and indexing of schema information from Linked Open Data (LOD) at web-scale. The schema index provided by SchemEX can be used to locate distributed data sources in the LOD cloud. The SchemEX approach is used in LODatio, a Google-inspired search engine designed for data engineers to find relevant sources of LOD. Further analysis of schema structures on the LOD cloud include investigating the redundancy between type and property information, use of vocabularies in pay-level domains, and change of schema information over weekly snapshots of a larger amount of LOD data. The talk will conclude with current developments and future work.</td></tr><tr><td><b>Speaker Bio</b></td><td>Ansgar Scherp is a professor at the Leibniz Information Center for Economics and Kiel University, Kiel, Germany</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Jan. 30, 2015</div></td><td><div class=\"eventInfor\">SPEAKER: Chris Jermaine (Rice University)</div><div class=\"eventInfor\">Large-Scale Machine Learning with the SimSQL System</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99295\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99295\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Jan. 30, 2015 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Chris Jermaine (Rice University)</td></tr><tr><td><b>Title</b></td><td>Large-Scale Machine Learning with the SimSQL System</td></tr><tr><td><b>Abstract</b></td><td>In this talk, I'll describe the SimSQL system, which is a platform for writing and executing statistical codes over large data sets, particularly for machine learning applications. Codes that run on SimSQL can be written in a very high-level, declarative language called Buds. A Buds program looks a lot like a mathematical specification of an algorithm, and statistical codes written in Buds are often just a few lines long.\n             \n             At its heart, SimSQL is really a relational database system, and like other relational systems, SimSQL is designed to support data independence. That is, a single declarative code for a particular statistical inference problem can be used regardless of data set size, compute hardware, and physical data storage and distribution across machines. One concern is that a platform supporting data independence will not perform well. But we've done extensive experimentation, and have found that SimSQL performs as well as other competitive platforms that support writing and executing machine learning codes for large data sets.</td></tr><tr><td><b>Speaker Bio</b></td><td>Chris Jermaine is an associate professor of computer science at Rice University. He is the recipient of an Alfred P. Sloan Foundation Research Fellowship, a National Science Foundation CAREER award, and an ACM SIGMOD Best Paper Award. In his spare time, Chris enjoys outdoor activities such as hiking, climbing, and whitewater boating. In one particular exploit, Chris and his wife floated a whitewater raft (home-made from scratch using a sewing machine, glue, and plastic) over 100 miles down the Nizina River (and beyond) in Alaska.</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Jan. 16, 2015</div></td><td><div class=\"eventInfor\">SPEAKER: Ryan Compton (Howard Hughes Research Laboratories)</div><div class=\"eventInfor\">Geotagging One Hundred Million Twitter Accounts with Total Variation\nMinimization </div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99293\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99293\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Jan. 16, 2015 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Ryan Compton (Howard Hughes Research Laboratories)</td></tr><tr><td><b>Title</b></td><td>Geotagging One Hundred Million Twitter Accounts with Total Variation\nMinimization </td></tr><tr><td><b>Abstract</b></td><td> Geographically annotated social media is extremely valuable for modern\ninformation retrieval. However, when researchers can only access\npublicly-visible data, one quickly finds that social media users\nrarely publish location information. In this work, we provide a method\nwhich can geolocate the overwhelming majority of active Twitter users,\nindependent of their location sharing preferences, using only\npublicly-visible Twitter data.\n\nOur method infers an unknown user's location by examining their\nfriend's locations. We frame the geotagging problem as an optimization\nover a social network with a total variation-based objective and\nprovide a scalable and distributed algorithm for its solution.\nFurthermore, we show how a robust estimate of the geographic\ndispersion of each user's ego network can be used as a per-user\naccuracy measure, allowing us to discard poor location inferences and\ncontrol the overall error of our approach.\n\nLeave-many-out evaluation shows that our method is able to infer\nlocation for 101,846,236 Twitter users at a median error of 6.38 km,\nallowing us to geotag over 80% of public tweets.\n\nhttp://arxiv.org/abs/1404.7152</td></tr><tr><td><b>Speaker Bio</b></td><td> Ryan Compton is postdoc in the Information and System Sciences\nLaboratory at Howard Hughes Research Laboratories in Malibu, CA. His\nwork focuses on social media data mining for early detection of\nnewsworthy events. In 2012 Ryan finished a mathematics PhD at UCLA with\na thesis on sparsity promoting optimization for quantum mechanical\nsignal processing. His website is http://www.ryancompton.net.</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Dec. 12, 2014</div></td><td><div class=\"eventInfor\">SPEAKER: Heri Ramampia (Norwegian University of Science and Technology)</div><div class=\"eventInfor\">Boosting Event-Related Image Retrieval with Spatiotemporal Distribution of Tag Terms </div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99288\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99288\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Dec. 12, 2014 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Heri Ramampia (Norwegian University of Science and Technology)</td></tr><tr><td><b>Title</b></td><td>Boosting Event-Related Image Retrieval with Spatiotemporal Distribution of Tag Terms </td></tr><tr><td><b>Abstract</b></td><td>Media sharing applications, such as Flickr and Panoramio, contain a large amount of pictures \nrelated to real life events.  For this reason,  although still being a challenging task, the development of \neffective methods to retrieve these pictures is important. Recognizing this importance, and to improve \nthe retrieval effectiveness of tag-based event retrieval systems, we have proposed a new \neffective method to extract a set of geographical tag features from raw geo-spatial profiles of user tags.  \nThe main idea is to use these features to select the best expansion terms in a machine learning-based\nquery expansion approach. Specifically, we apply rigorous statistical exploratory analysis of spatial \npoint patterns to extract the geo-spatial features. Then, we used the features both to summarize the spatial \ncharacteristics of the spatial distribution of a single term, and to determine the similarity between \nthe spatial profiles of two terms -- i.e., term-to-term spatial similarity. To further improve our image retrieval \napproach, we investigated the effect of combining our geo-spatial features with temporal features. \nIn this presentation, I will try to give an overview of the methods we used\n(1) to extract the spatio-temporal featrues from image tags, and (2) how to use these features to\nimprove the retrieval performance, focusing on retrieval of event-related images. Finally, I will\ndiscuss the results from our experiments, and show how our method has improved the\nstate-of-the-art approach.</td></tr><tr><td><b>Speaker Bio</b></td><td>Heri Ramampiaro is an Associate Professor at the Dept of Computer and Information Science,\nNorwegian University of Science and Technology (NTNU). He is Head of the Data and Information \nManagement group. His main research interests include Information Retrieval, BigData,\nInformation Extraction/Text Mining, Bioinformatics and Health Informatics. Ramampiaro is currently\non a one-year research sabbatical, visiting the ISG group, UC Irvine.</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Dec. 5, 2014</div></td><td><div class=\"eventInfor\">SPEAKER: Daniel Wood (DELL)</div><div class=\"eventInfor\">Dell and Big Data Software: Data replication and Reorganization</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99287\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99287\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Dec. 5, 2014 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Daniel Wood (DELL)</td></tr><tr><td><b>Title</b></td><td>Dell and Big Data Software: Data replication and Reorganization</td></tr><tr><td><b>Abstract</b></td><td>The role of an enterprise independent software vendor (ISV) is to develop tools and technologies that support the information systems of their customers. Customers cannot easily switch technologies or adapt them to their needs without causing disruptions to their business. This is where software vendors are able to help. I will discuss how an ISV like Quest managed to go from startup to acquisition and the details of two of the relevant enterprise technologies. The first technology, database replication, has become critical in scaling many of the household names we know. We will explore this technology and its evolution from homogeneous database replication to heterogeneous database replication that includes Oracle, SQL Server, and Hadoop systems. The second technology, data reorganization, is crucial to curbing storage hungry databases and improving database performance by defragmenting data. </td></tr><tr><td><b>Speaker Bio</b></td><td>Daniel Wood is a manager of software development inside Dell Software Group (Formerly Quest Software) where he has worked for 13 years. Daniel focuses on database management tools and problems at scale. Daniel holds a BA in physics from University of California Santa Barbara. </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Nov. 21, 2014 (Special Time/Place)</div></td><td><div class=\"eventInfor\">SPEAKER: Prof. Wei Wang (UCLA)</div><div class=\"eventInfor\">Big Data Analytics in Science</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99285\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99285\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Nov. 21, 2014 (Special Time/Place) 11 am</td></tr><tr><td><b>Location</b></td><td>DBH 6011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Prof. Wei Wang (UCLA)</td></tr><tr><td><b>Title</b></td><td>Big Data Analytics in Science</td></tr><tr><td><b>Abstract</b></td><td>Big data analytics is the process of examining large amounts of data of a variety of types (big data) to uncover hidden patterns, unknown correlations and other useful information. Its revolutionary potential is now universally recognized. Data complexity, heterogeneity, scale, and timeliness make data analysis a clear bottleneck in many biomedical applications, due to the complexity of the patterns and lack of scalability of the underlying algorithms. Advanced machine learning and data mining algorithms are being developed to address one or more challenges listed above. It is typical that the complexity of potential patterns may grow exponentially with respect to the data complexity, and so is the size of the pattern space. To avoid an exhaustive search through the pattern space, machine learning and data mining algorithms usually employ a greedy approach to search for a local optimum in the solution space, or use a branch-and-bound approach to seek optimal solutions, and consequently, are often implemented as iterative or recursive procedures. To improve efficiency, these algorithms often exploit the dependencies between potential patterns to maximize in-memory computation and/or leverage special hardware for acceleration. In this talk, I will present some open challenges faced by data scientist in biomedical fields and our approaches to tackle these challenges through examples such as multi-locus QTL analysis and transcriptome quantification using RNAseq data.\n</td></tr><tr><td><b>Speaker Bio</b></td><td>Wei Wang is a professor in the Department of Computer Science at University of California at Los Angeles and the director of the Scalable Analytics Institute (ScAi). She is a member of the UCLA Jonsson Comprehensive Cancer Center. She received her PhD degree in Computer Science from the University of California at Los Angeles in 1999. Before she rejoined UCLA, she was a professor in Computer Science and a member of the Carolina Center for Genomic Sciences and Lineberger Comprehensive Cancer Center at the University of North Carolina at Chapel Hill from 2002 to 2012, and was a research staff member at the IBM T. J. Watson Research Center between 1999 and 2002. Dr. Wang's research interests include big data, data mining, bioinformatics and computational biology, and databases.\n </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Nov. 18, 2014 (Special Time/Place)</div></td><td><div class=\"eventInfor\">SPEAKER: Hwanjo Yu, Associate Professor\n          POSTECH (Pohang University of Science and Technology)</div><div class=\"eventInfor\">Search and Mining for Big Data</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99284\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99284\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Nov. 18, 2014 (Special Time/Place) 4 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Hwanjo Yu, Associate Professor\n          POSTECH (Pohang University of Science and Technology)</td></tr><tr><td><b>Title</b></td><td>Search and Mining for Big Data</td></tr><tr><td><b>Abstract</b></td><td>Big data is recently defined (by Gartner) as high volume, high velocity, and/or high variety information assets that require new forms of processing to enable enhanced decision making, insight discovery and process optimization. In this talk, we first present key challenges in Big data programming, that are distinct from conventional parallel processing. After that, we introduce several research projects dealing with large volume of data in the data mining lab at POSTECH, that are, PubMed relevance feedback search engine, blackbox video search, novel recommendation, and timing when to recommend.</td></tr><tr><td><b>Speaker Bio</b></td><td> Hwanjo Yu received his PhD in Computer Science at the University of Illinois at Urbana-Champaign at June 2004 under the supervision of Prof. Jiawei Han. From July 2004 to January 2008, he had been an assistant professor at the University of Iowa. He is now an associate professor at POSTECH (Pohang University of Science and Technology). He developed influential algorithms and systems in the areas of data mining, database, and machine learning, including (1) algorithms for classifying without negative examples (PEBL, SVMC), (2) privacy-preserving SVM algorithms, (3) SVM-JAVA : an educational java open source for SVM, (4) RefMed : relevance feedback search engine for PubMed, (5) TurboGraph : a fast parallel graph engine handling billion-scale graphs in a single PC. His methods and algorithms were published in prestigious journals and conferences including ACM SIGMOD, ACM SIGKDD, IEEE ICDE, IEEE ICDM, ACM CIKM, etc., where he is also serving as a program committee.</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Nov. 14, 2014</div></td><td><div class=\"eventInfor\">SPEAKER: Dr. Jiannan Wang (UC Berkeley)</div><div class=\"eventInfor\">SampleClean: Fast and Accurate Query Processing on Dirty Data</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99283\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99283\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Nov. 14, 2014 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Dr. Jiannan Wang (UC Berkeley)</td></tr><tr><td><b>Title</b></td><td>SampleClean: Fast and Accurate Query Processing on Dirty Data</td></tr><tr><td><b>Abstract</b></td><td>The vision of AMPLab is to integrate Algorithms (Machine Learning), Machines (Cloud Computing) and People (Crowdsourcing) to make sense of Big Data. In the past several years, the lab has developed a variety of open-source software (e.g., Spark and MLBase) to integrate the three resources. For the People part, one of our main focuses is on data cleaning. Real-world data is often \u201cdirty\u201d. Data cleaning is usually a tedious and time-consuming process which requires a lot of human work. In the AMPLab, we have exploited the use of crowdsourcing to reduce the human cost. While crowdsourcing makes data cleaning more scalable, it is still highly inefficient for large datasets. To overcome this limitation, we started the SampleClean project last year. The project aims to investigate how to obtain accurate query results from dirty data, by only cleaning a small sample of the data. We achieved this goal by marrying data cleaning with sampling-based approximate query processing, and addressing many challenging statistical issues. We build a new system that combines our work on crowdsourcing data cleaning and SampleClean query processing. An initial version of the system has shown that our system can help users to obtain very accurate query results on dirty data, at significantly reduced cleaning cost. \n</td></tr><tr><td><b>Speaker Bio</b></td><td>Jiannan Wang is a postdoc in the AMPLab at UC Berkeley, where he works with Prof. Michael Franklin and leads the SampleClean project. His research is focusing on developing algorithms and systems for extracting value from \u201cdirty\" data. He obtained his PhD from the Computer Science Department at Tsinghua University. During his PhD, he has been a visiting scholar at Chinese University of Hong Kong and UC Berkeley, and an intern at Qatar Computing Research Institute. His PhD research work was supported by Google PhD Fellowship, Boeing Scholarship, and \u201cNew PhD Researcher Award\u201d by Chinese Ministry of Education. His PhD dissertation has won the China Computer Federation (CCF) Distinguished Dissertation Award. His similarity-join algorithm has won the first place of EDBT String Similarity Search/Join Competition.   </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Nov. 7, 2014</div></td><td><div class=\"eventInfor\">SPEAKER: Prof. Shahram Ghandeharizadeh (USC)</div><div class=\"eventInfor\">BG:  A Benchmark for Interactive Social Networking Actions</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99282\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99282\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Nov. 7, 2014 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Prof. Shahram Ghandeharizadeh (USC)</td></tr><tr><td><b>Title</b></td><td>BG:  A Benchmark for Interactive Social Networking Actions</td></tr><tr><td><b>Abstract</b></td><td>BG is a benchmark for interactive social networking actions (also known as\nsimple or small data operations).  It is motivated by the flurry of novel data\nstore designs ranging from SQL to NoSQL and NewSQL, Cache Augmented SQL, graph\ndatabases and others.  More than 40 data stores have been introduced in the past\ndecade including systems contributed by the social networking sites,\ne.g., Cassandra by Facebook and Voldemort by LinkedIn.  Some systems sacrifice\nstrict ACID (Atomicity, Consistency, Isolation, Durability) properties and opt\nfor BASE (Basically Available, Soft-state, Eventual Consistency) to enhance\nperformance.  BG strives to compare these systems with one another quantitatively.\n\nThis  presentation details the design of BG and its SoAR metric to rate data stores.\nWe describe how BG quantifies the amount of unpredictable (stale, erroneous, or inconsistent)\ndata produced by a data store.  We present ratings from an industrial strength relational\ndatabase management system, a document store named MongoDB, a graph data store named\nNeo4j, and an extensible data store named HBase.  We show the use of SoAR to evaluate\nboth vertical and horizontal scalability of MongoDB and HBase.  We also describe\nthe use of BG to evaluate novel cache replacement algorithms such as CAMP and\nconsistency frameworks such as IQ.  We conclude with the use of BG to demonstrate\na novel SQL middleware named KOSAR.\n\nBG is joint work with Sumita Barahmand.  Visit http://bgbenchmark.org to download BG.</td></tr><tr><td><b>Speaker Bio</b></td><td> Shahram Ghandeharizadeh received his Ph.D. degree in Computer Science from the\nUniversity of Wisconsin, Madison, in 1990. Since then, he has been on the faculty\nat the University of Southern California. In 1992, he received the National Science\nFoundation Young Investigator's Award for his research on the physical design of parallel\ndatabase systems. In 1995, he received an award from the School of Engineering at USC\nin recognition of his research activities. He was a recipient of the ACM Software\nSystem Award 2008.  His primary motivation for developing BG is today's proliferation\nof many data stores and a scarcity of benchmarks to substantiate their claims.</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Oct. 30, 2014 (Special Day/Time)</div></td><td><div class=\"eventInfor\">SPEAKER: Dr. David Lomet (MSR) </div><div class=\"eventInfor\">Achieving Ridiculously High TPS</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99281\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99281\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Oct. 30, 2014 (Special Day/Time) 4-5 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Dr. David Lomet (MSR) </td></tr><tr><td><b>Title</b></td><td>Achieving Ridiculously High TPS</td></tr><tr><td><b>Abstract</b></td><td>The Deuteronomy architecture provides a clean separation of transaction functionality (performed in a transaction component, or TC) from data management functionality (performed in a data component, or DC). In prior work we implemented both a TC and DC that achieved modest performance. We recently built a high performance DC (the Bw-tree key value store) that achieves very high performance on modern hardware via latch-free and log structuring techniques and is currently shipping as an indexing and storage layer in Microsoft systems such as Hekaton and DocumentDB. The new DC executes operations more than 100x faster than the TC we previously implemented.  This talk describes how we achieved two orders of magnitude speedup in TC performance and shows that a full Deuteronomy stack can achieve very high performance overall. We built the TC using techniques analogous to the Bw-tree (latch-free data structures, log-structuring). The TC uses multi-version concurrency control (MVCC) to improve concurrency and performance.  Our new prototype TC scales to 32 cores on our 4 socket NUMA machine and commits more than a million of transactions per second for a variety of workloads.</td></tr><tr><td><b>Speaker Bio</b></td><td>David Lomet has been a principal researcher and manager of the Database Group at Microsoft Research, Redmond since 1995.  Before that, he was at Digital Equipment Corporation, mainly at Cambridge Research Lab.  Earlier, he was a research staff member at IBM Research in Yorktown and subsequently a Professor at Wang Institute.  Lomet spent a sabbatical at Newcastle University working with Brian Randell.  He is best known for his work in database systems and is one of the inventors of the transaction concept.  His database work has focused on access methods, concurrency control, and recovery.  His recent Bw-tree work is part of Microsoft's Hekaton main memory database system. He has published over 100 papers, including two SIGMOD \"best paper\" awards, and has over 40 patents. Lomet has served on many PCs, including SIGMOD, VLDB, and ICDE.  He has been ICDE'2000 PC co-chair, VLDB'2006 Core Track Chair, and ICDE'2001 conference co-chair.  Lomet has been editor-in-chief of the Data Engineering Bulletin since 1992, and won the 2011 SIGMOD Contributions Award for this. He has also been an editor of ACM TODS and the VLDB Journal, has served on the VLDB Endowment Board and ICDE Steering Committee, and has been Chair of the IEEE TC on Data Engineering. Dr. Lomet is a Fellow of AAAS, ACM, and IEEE.  </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Oct. 24, 2014 (Special Time/Place)</div></td><td><div class=\"eventInfor\">SPEAKER: Prof. Padhraic Smyth and others</div><div class=\"eventInfor\">UCI Data Science Kickoff Meeting</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99280\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99280\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Oct. 24, 2014 (Special Time/Place) 1:30-5 PM (with reception to follow)</td></tr><tr><td><b>Location</b></td><td>CalIIT2 Auditorium</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Prof. Padhraic Smyth and others</td></tr><tr><td><b>Title</b></td><td>UCI Data Science Kickoff Meeting</td></tr><tr><td><b>Abstract</b></td><td>This will be the official kickoff event for a new UCI campus-wide Data Sciences Initiative.\nCome hear about the Initiative as well as efforts related to Data Sciences from across the campus.\nThe afternoon's program will be followed by a reception at 5 PM.\nThis event is open to anyone/everyone who is interested.\nA detailed agenda for this afternoon event can be found hanging here: http://datascience.uci.edu/.</td></tr><tr><td><b>Speaker Bio</b></td><td> </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Oct. 17, 2014</div></td><td><div class=\"eventInfor\">SPEAKER: Mark Callaghan (Facebook)</div><div class=\"eventInfor\">Still Doing It Wrong</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99279\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99279\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Oct. 17, 2014 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Mark Callaghan (Facebook)</td></tr><tr><td><b>Title</b></td><td>Still Doing It Wrong</td></tr><tr><td><b>Abstract</b></td><td>Famous people have interesting things to say about my work and my fate. I hope to provide more context on doing \"small data\" (per request, e.g., OLTP) at scale. I will start with a short history of web-scale MySQL from 2005 until today and predict where it is heading in the next 5 years. My current work is to improve storage efficiency for small data (per request) workloads. Algorithms tend to be fixed in their behavior, while both workloads and storage device performance vary. There is thus an opportunity to improve efficiency by making algorithms more dynamic.</td></tr><tr><td><b>Speaker Bio</b></td><td>Mark Callaghan has worked with great teams to make MySQL better for scale-out deployments at Facebook and Google for 9+ years. His current focus at Facebook is the analysis and improvement of database algorithms and storage systems for small data (OLTP) workloads. He also works with WebScaleSQL and RocksDB to make MySQL and MongoDB better. Prior to his web-scale work Mark spent many years working on RDBMS internals at Oracle and Informix. He invented and implemented a very fast general purpose sort algorithm for the Oracle RDBMS. He has an MS in CS from UW-Madison.\n</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Oct. 10, 2014</div></td><td><div class=\"eventInfor\">SPEAKER: Prof. Jimeng Sun (Georgia Institute of Technology)</div><div class=\"eventInfor\">Do it Once, Do it Right - Building a Scalable Predictive Modeling Platform for Healthcare Applications </div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99278\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99278\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Oct. 10, 2014 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Prof. Jimeng Sun (Georgia Institute of Technology)</td></tr><tr><td><b>Title</b></td><td>Do it Once, Do it Right - Building a Scalable Predictive Modeling Platform for Healthcare Applications </td></tr><tr><td><b>Abstract</b></td><td> Predictive models are designed to predict the likelihood of one or more outcomes and are playing an increasing important role in biomedical research. Thanks to the explosion of Electronic Heart Records (EHR), the interest in building predictive models based on EHR data has skyrocketed in recent years.  There are some major challenges that remain to be addressed.  In this talk I will explore two of them. Effective algorithms are lacking in dealing with high-dimensional, longitudinal, sparse, inaccurate and inconsistent EHR data. The methodologies to develop predictive models are still labor intensive and ad-hoc. These rudimentary approaches are hindering the quality and throughput of healthcare and biomedical research.\nIn this talk, we promote a holistic approach that addresses both challenges by combining 1) algorithm development and 2) system building. We believe that a more robust and domain specific big-data platform could significantly speedup the development of robust and accurate predictive models for biomedical research. \nI will present different projects covering both aspects of such a platform:\nAlgorithms: I will first describe our work on computational phenotyping from EHR data using sparse tensor factorization; then I will present a patient similarity method using supervised distance metric learning\nSystem: I will introduce a parallel predictive modeling platform using Hadoop for enabling large scale modeling and exploration of big healthcare data</td></tr><tr><td><b>Speaker Bio</b></td><td>Jimeng Sun is an Associate Professor of School of Computational Science and Engineering at College of Computing in Georgia Institute of Technology. Prior to joining Georgia Tech, he was a research staff member at IBM TJ Watson Research Center. His research focuses on health analytics using electronic health records and data mining, especially in designing novel tensor analysis and similarity learning methods and developing large-scale predictive modeling systems.\nDr. Sun has worked on various healthcare applications such as computational phenotyping from electronic health records, heart failure onset prediction and hypertension control management. He has collaborated with many healthcare institutions including Vanderbilt university medical center, Children's healthcare of Atlanta, Center for Disease Control and Prevention (CDC), Geisinger Health System and Sutter Health.\nHe has published over 70 papers, filed over 20 patents (5 granted). He has received ICDM best research paper award in 2008, SDM best research paper award in 2007, and KDD Dissertation runner-up award in 2008. Dr. Sun received his B.S. and M.Phil. in Computer Science from Hong Kong University of Science and Technology in 2002 and 2003, and a PhD in Computer Science from Carnegie Mellon University in 2007.</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Oct. 3, 2014</div></td><td><div class=\"eventInfor\">SPEAKER: ISG Faculty</div><div class=\"eventInfor\">2014-15 ISG Welcome (Back) Seminar</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99277\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99277\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Oct. 3, 2014 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>ISG Faculty</td></tr><tr><td><b>Title</b></td><td>2014-15 ISG Welcome (Back) Seminar</td></tr><tr><td><b>Abstract</b></td><td></td></tr><tr><td><b>Speaker Bio</b></td><td> </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">May. 30, 2014</div></td><td><div class=\"eventInfor\">SPEAKER:  </div><div class=\"eventInfor\">No Seminar</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99276\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99276\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>May. 30, 2014 11 pm</td></tr><tr><td><b>Location</b></td><td>DBH 6011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td> </td></tr><tr><td><b>Title</b></td><td>No Seminar</td></tr><tr><td><b>Abstract</b></td><td>Go to CS Colloquium for Ed Lazowska's Big Data talk.</td></tr><tr><td><b>Speaker Bio</b></td><td> </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">May. 23, 2014</div></td><td><div class=\"eventInfor\">SPEAKER: Odej Kao (TU Berlin)</div><div class=\"eventInfor\">Dynamic Scheduling and Resource Management for Big Data</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99275\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99275\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>May. 23, 2014 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Odej Kao (TU Berlin)</td></tr><tr><td><b>Title</b></td><td>Dynamic Scheduling and Resource Management for Big Data</td></tr><tr><td><b>Abstract</b></td><td>\t     </td></tr><tr><td><b>Speaker Bio</b></td><td> </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">May. 16, 2014</div></td><td><div class=\"eventInfor\">SPEAKER: Daniel Ford (Dell Research)</div><div class=\"eventInfor\"> The Unintended Consequences of The Internet of Things</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99274\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99274\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>May. 16, 2014 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Daniel Ford (Dell Research)</td></tr><tr><td><b>Title</b></td><td> The Unintended Consequences of The Internet of Things</td></tr><tr><td><b>Abstract</b></td><td> Computer technology is subject to rapid change and evolution.  Each new development seems to be subject to exuberant hyperbole.  The latest round is focusing on embedded electronics and is called The\nInternet of Things, or just \"The IoT.\"  The main force powering this \"hype machine\" is the suggestion of vast new commercial opportunities, estimated by some sources to be in the range of $19 Trillion. This talk begins with the conclusion that the \"hype\" about The Internet of Things is underplayed, and that the commercial implications of The Internet of Things are the smallest parts of a bigger story.  It compares The IoT to other historical technological developments, examining what is similar, and what is without historical precedent.  In particular, it finds the impact of applications of The Internet of Things to be spectacularly unconstrained.  All this leads to the idiom \"Careful what you wish for.\"  So, while commerce is \"wishing for\" a $19 Trillion market, our society, and our economy, are going to get something else. The talk concludes with an examination of some of the potential unintended consequences of The Internet of Things.  It predicts that areas as diverse as Brand Management, Advertising, Propaganda, Healthcare, Law Enforcement, Insurance, Automobile ownership, Politics, and Warfare, to name just a few, will all be affected in ways few are considering.\n            </td></tr><tr><td><b>Speaker Bio</b></td><td>Dr. Ford is Executive Director and Chief Scientist for Mobility and The Internet of Things for Dell Research in San Jose, California. Prior to joining Dell Research, Dr. Ford was CEO and co-founder of\nPaupt Labs LLC, in New York.  He also was with IBM Research, in a variety of positions, for nineteen years before that. His immediate research interests are focused on The Internet of Things, including supporting software architectures, novel applications, and unintended consequences.  Previous research interests have included Healthcare Informatics, Pandemic Modeling, Social Networking, Mobile Computing, Web Search, and High Performance\nTertiary Storage Systems.  Dr. Ford has twenty-eight issued US patents and dozens of peer reviewed publications. Dr. Ford earned his Ph.D. in Computer Science from the University of Waterloo in 1992. \n            </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">May. 9, 2014</div></td><td><div class=\"eventInfor\">SPEAKER: Vinayak Borkar (UC Irvine)</div><div class=\"eventInfor\">An Efficient Platform for Parallel Data Processing on Large Clusters</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99273\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99273\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>May. 9, 2014 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Vinayak Borkar (UC Irvine)</td></tr><tr><td><b>Title</b></td><td>An Efficient Platform for Parallel Data Processing on Large Clusters</td></tr><tr><td><b>Abstract</b></td><td>The growth of user activity on the Internet and the rise of social networks has led to an exponential growth of data. Storage of this data and its subsequent analysis have posed significant challenges. Unlike the business data that drove research and development of relational databases for the past several decades, Web and Social data tend to have rich and varying structure, making traditional database systems a poor choice for their management. The astronomical size and semi-structured nature of this new data has forced companies in the business of managing it to look for other cost-effective solutions. In 2004 Google presented the MapReduce system as a way to harness the power of thousands of commodity machines to solve problems like building a search index over the entire World Wide Web in reasonable time at reasonable cost; MapReduce turned out to be a useful tool for performing other parallel computations over large amounts of data while presenting a simple programming model to users. Soon after the MapReduce paper, the open source community created the Hadoop platform to resemble Google's MapReduce system. Hadoop soon became a popular platform for processing large amounts of data using commodity computers. In an effort to boost user productivity, new declarative languages were designed and built to compile high-level declarative queries down to Hadoop MapReduce programs, making Hadoop the de-facto runtime layer for large-scale parallel data computation.\n\nWhile widely used and popular today, Hadoop was not intentionally designed to be a runtime layer for higher-level declarative languages.\nIn this talk we explore an alternative to the Hadoop platform whose design is rooted in parallel database research from the 1980s and 1990s. Hyracks is an efficient runtime platform that accepts data-parallel jobs from users and from high-level language compilers and executes them on a cluster of commodity machines. We describe the design of Hyracks as well as salient aspects of its implementation. Using Hyracks we study the trade offs involved in building an extensible and reusable set of runtime components for large-scale data processing. We show experimentally that Hyracks is a highly configurable platform and well-suited for several different data processing tasks. We do so via three different use cases: executing queries expressed in high-level declarative languages, running actual Hadoop jobs using the Hadoop Compatibility Layer of Hyracks, and finally, running parallel graph computations using Pregelix, an open source graph analytics platform that uses Hyracks and emulates Google's Pregel programming model for analyzing large graphs in parallel.\n\nA number of new declarative parallel languages have been proposed for querying and analyzing very large data sets.\nTo aid with the construction of declarative parallel query compilers, we propose an extensible algebraic framework called Algebricks. Algebricks is a model-agnostic compilation framework that provides the ability for a compiler to inject its own semantics in an extensible manner. Algebricks includes a reusable and extensible set of logical and physical operators and a large set of general purpose rewrite rules useful to most query compilers. We describe the implementation of three different language compilers (AsterixDB for AQL, Hivesterix for HiveQL, and VXQuery for XQuery) that use the Algebricks compiler framework to create parallel jobs to run on a Hyracks Cluster.</td></tr><tr><td><b>Speaker Bio</b></td><td></td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">May. 2, 2014</div></td><td><div class=\"eventInfor\">SPEAKER: Dick Bulterman (FXPAL)</div><div class=\"eventInfor\">Authoring Support for Social Media Interaction: \nUnderstanding Compound Multimedia Dependencies</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99272\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99272\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>May. 2, 2014 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Dick Bulterman (FXPAL)</td></tr><tr><td><b>Title</b></td><td>Authoring Support for Social Media Interaction: \nUnderstanding Compound Multimedia Dependencies</td></tr><tr><td><b>Abstract</b></td><td>\t   Creating compelling multimedia content is a difficult task. It involves not only the creative process \n\nof developing a compelling media-based story, but it also requires significant technical support for \n\ncontent editing and management. This process is made more complex by an increased desire for \n\nmedia personalization: the story you tell Mom about an event may be different than the version \n\nyou\u2019d like to share with your friends. It is also different from the version you\u2019d like to tell your own \n\nchildren 15 years after the event had taken place. The makes media authoring a context- and time-\nsensitive problem. No wonder most researchers analyze media instead of create it!\n\nIt is tempting to categorize multimedia authoring in terms of component areas: media encoding, \n\nmedia storage, media access, media transport, media rendering and overall presentation \n\ncomposition and control. Unfortunately, this partitioning blurs the dependencies that exist among \n\nthese component areas that ultimately determine the success of an authoring system. Using the \n\nbroad problem of social media interaction as an example, this talk will consider the composite \n\neffects of creating and accessing and transporting and presenting rich media objects for use by non-\ntechnical end users.\n\nThe talk will survey several approaches to describe and manage media interactions. We will focus \n\non the temporal modelling of context-sensitive personalized interactions of complex collections of \n\nindependent media objects. Using the concepts of \u2018togetherness\u2019 being employed in the EU\u2019s FP-7 \n\nproject TA2: Together Anywhere, Together Anytime, we will follow the process of media capture, \n\nprofiling, composition, sharing and end-user manipulation. We will consider the promise of using \n\nautomated tools and contrast this with the reality of letting real users manipulation presentation \n\nsemantics in real time.\n\nThe talk will not present a closed form solution, but will present a series of topics and problems that \n\ncan stimulate the development of a new generation of systems to stimulate social media interaction.      </td></tr><tr><td><b>Speaker Bio</b></td><td> Dr. Dick Bulterman is President of the FX Palo Alto Laboratory (FXPAL) and professor of \n\ncomputer science at the VU University in Amsterdam. Before joining FXPAL in 2013, he was a \n\nsenior researcher at CWI in Amsterdam, where he founded the Distributed Multimedia Languages \n\nand Interfaces group. In 1999, he started Oratrix Development BV, a CWI spin-off company that \n\ntransferred the group's SMIL-based GRiNS software to many parts of the civilized world. Prior to \n\njoining CWI in 1988, he was on the faculty of the Division of Engineering at Brown University, \n\nwhere he was part of the Laboratory for Engineering Man/Machine Systems. Dr. Bulterman \n\nreceived a Ph.D. in computer science from Brown University (USA) in 1982. In 2013 he was \n\nawarded the ACM SIGMM Lifetime Technical Achievement Award. He is a member of Sigma Xi, \n\nthe ACM and the IEEE. </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">April. 18, 2014</div></td><td><div class=\"eventInfor\">SPEAKER: Pekka Kostamaa (Teradata)</div><div class=\"eventInfor\">Big Data at Teradata \u2013 Teradata Unified Data Architecture</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99271\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99271\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>April. 18, 2014 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Pekka Kostamaa (Teradata)</td></tr><tr><td><b>Title</b></td><td>Big Data at Teradata \u2013 Teradata Unified Data Architecture</td></tr><tr><td><b>Abstract</b></td><td>\t \nUnified Data Architecture (UDA) is Teradata\u2019s strategy and program for Big Data. UDA combines three platforms in a unified architecture:\n1.       Data Warehouse;\n2.       Discovery Platform;\n3.       Data Platform.\nThis talk will describe the architecture and present real customer use cases.\n     </td></tr><tr><td><b>Speaker Bio</b></td><td>Pekka Kostamaa is Senior Director of Product Management for the Teradata\n\nDatabase. His team is responsible for the strategy and definition of new releases \n\nof Teradata, from concept phase through development to delivery to customers.\n\nPreviously, Pekka was the Vice President of Engineering and Big Data Lab \n\nfor Teradata Aster and Director of Advanced Development and Enterprise \n\nArchitecture for Teradata R and D.\n\nHe has several publications, holds twenty patents with several pending, and \n\npresented the Keynote Speech at the ICDE 2011 conference and an Invited Talk \n\nat the 2012 DOLAP Workshop. He is a member of the UCLA Computer Science \n\nAdvisory Boards. </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">March. 14, 2014</div></td><td><div class=\"eventInfor\">SPEAKER: Christoph Freytag (Humboldt U)</div><div class=\"eventInfor\">When to say NO to protect Privacy when answering Queries</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99270\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99270\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>March. 14, 2014 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Christoph Freytag (Humboldt U)</td></tr><tr><td><b>Title</b></td><td>When to say NO to protect Privacy when answering Queries</td></tr><tr><td><b>Abstract</b></td><td>This talk presents privacy concepts that keep the balance between utility and privacy when returning \n\nanswers to a sequence of queries. In particular we show how to model the (increasing) knowledge of an \n\nadversary resulting from the answers to queries by a sequence of bipartite graphs. Those provide the \n\nfoundation for deciding when a privacy breach occurs (might occur) and how to balance the need for \n\naccurate responses versus the right for privacy. Examples demonstrate the intricacies of managing this \n\ntrade-off.\t     </td></tr><tr><td><b>Speaker Bio</b></td><td>Johann-Christoph Freytag is currently full professor for Databases and Information Systems (DBIS) at the Computer Science Department of the Humboldt-Universit\u00e4t zu Berlin, Germany. Before joining the department in 1994, he was a research staff member at the IBM Almaden Research Center (1985-1987), a researcher at the European Computer-Industry-Research Centre (ECRC, in Munich, Germany, 1987-1989), and the head of Digital's Database Technology Center (also in Munich, 1990-1993). He holds a Ph.D. in Applied Mathematics/Computer Science from Harvard University, MA.\n\nProf. Freytag's research interests include all aspects of query processing and query optimization in object-relational database systems, new developments in the database area (such as semi-structured data, data quality, databases and security), privacy in database systems, and applying database technology to applications such as GIS, genomics, and bioinformatics/life science. In the last years he received the IBM Faculty Award four times for collaborative work in the areas of databases, middleware, and bioinformatics/life science. He organized the VLDB conference in Berlin in 2003 and was a member of the VLDB Endowment (2001-2007) and in the head of the German database interest group of the GI (Fachbereich DBIS, Gesellschaft fur Informatik). </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">March. 7, 2014</div></td><td><div class=\"eventInfor\">SPEAKER: Michalis Petropoulos and Mohamed Soliman (Pivotal)</div><div class=\"eventInfor\">Orca: A Modular Query Optimizer Architecture for Big Data</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99269\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99269\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>March. 7, 2014 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Michalis Petropoulos and Mohamed Soliman (Pivotal)</td></tr><tr><td><b>Title</b></td><td>Orca: A Modular Query Optimizer Architecture for Big Data</td></tr><tr><td><b>Abstract</b></td><td>The performance of analytical query processing in data management systems depends primarily on the capabilities of the system's query optimizer. Increased data volumes and heightened interest in processing complex analytical queries have prompted Pivotal to build a new query optimizer. In this talk we present the architecture of Orca, the new query optimizer for all Pivotal data management products, including Pivotal Greenplum Database and Pivotal HAWQ. Orca is a comprehensive development uniting state-of-the-art query optimization technology with own original research resulting in a modular and portable optimizer architecture. In addition to describing the overall architecture, we highlight several unique features and present performance comparisons against other systems.     </td></tr><tr><td><b>Speaker Bio</b></td><td> Michalis Petropoulos is managing the query processing team at Pivotal Inc. His R and D team develops the query optimizer and executor for Pivotal\u2019s massively parallel and distributed data management products, Pivotal Greenplum Database and Pivotal HAWQ. Before that, Michalis was an Assistant Professor in the Computer Science and Engineering Department at SUNY Buffalo from 2006 to 2010. He received his PhD in Computer Science from the University of California, San Diego in 2005. In 2006, Michalis co-authored a publication that was awarded an Honorable Mention as top-3 finalist in the SIGMOD 2006 Best Paper Award competition. In 2010, he co-authored a publication that received the Best Interdisciplinary Paper Award at the ACM Conference on Information and Knowledge Management (CIKM).\n\nMohamed Soliman is a Staff 1 at Pivotal, where he works on building massively distributed database systems for efficient support of data warehousing and analytics. His work at Pivotal is mainly in the research and development of Orca, a next generation query optimizer for Big Data. Prior to that, Mohamed has conducted graduate studies at University of Waterloo, where he received his PhD in computer science in 2010 on the topic of rank-aware retrieval in probabilistic databases.</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Feb. 21, 2014</div></td><td><div class=\"eventInfor\">SPEAKER:  Inci Cetindil (UCI ISG)</div><div class=\"eventInfor\">  </div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99267\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99267\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Feb. 21, 2014 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td> Inci Cetindil (UCI ISG)</td></tr><tr><td><b>Title</b></td><td>  </td></tr><tr><td><b>Abstract</b></td><td>\t     </td></tr><tr><td><b>Speaker Bio</b></td><td> </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Feb. 14, 2014</div></td><td><div class=\"eventInfor\">SPEAKER: Siripen Pongpaichet (UCI ISG)</div><div class=\"eventInfor\"> EventShop</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99266\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99266\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Feb. 14, 2014 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Siripen Pongpaichet (UCI ISG)</td></tr><tr><td><b>Title</b></td><td> EventShop</td></tr><tr><td><b>Abstract</b></td><td>\nEventShop is a computational framework that has the ability to integrate and process streaming data from heterogeneous data sources.  Data from all data sources are first transformed into a Space/Time/Theme (STT) data model, with a hierarchical extension of STT being used to handle data coming from sources that have different resolutions in space and/or time.   Various types of spatio-temporal operators can then be applied to recognize and predict actionable situations.  Appropriate actions/recommendations can be sent to individuals based on their circumstances.   This talk will provide an overview of the EventShop project and the sorts of use cases it is intending to address.\n(Here is the link to our website http://eventshop.ics.uci.edu:8080/sln/)\n\t     </td></tr><tr><td><b>Speaker Bio</b></td><td> Siripen is a UCI CS Ph.D. student working in Ramesh Jain's EventShop group.</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Feb. 7, 2014</div></td><td><div class=\"eventInfor\">SPEAKER:  Inci Cetindil (UCI ISG)</div><div class=\"eventInfor\"> (Postponed due to illness) </div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99265\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99265\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Feb. 7, 2014 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td> Inci Cetindil (UCI ISG)</td></tr><tr><td><b>Title</b></td><td> (Postponed due to illness) </td></tr><tr><td><b>Abstract</b></td><td>\t     </td></tr><tr><td><b>Speaker Bio</b></td><td> </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Jan 31, 2014 (Special Location)</div></td><td><div class=\"eventInfor\">SPEAKER: Padhraic Smyth (UCI)</div><div class=\"eventInfor\">Statistical Machine Learning with Count Data (Informatics Seminar)</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99264\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99264\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Jan 31, 2014 (Special Location) 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 6011 </td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Padhraic Smyth (UCI)</td></tr><tr><td><b>Title</b></td><td>Statistical Machine Learning with Count Data (Informatics Seminar)</td></tr><tr><td><b>Abstract</b></td><td>\t(Regular ISG Seminar attendees are encouraged to attend this week's\nvery interesting Informatics Seminar - we don't want to conflict with\nthis talk!)\n\nData represented in the form of sets of counts is easy to acquire and \ncan be surprisingly useful in practice. For example, a simple way to \nrepresent a set of documents is as a \"bag of words\" where each document \nis represented just by the counts of words that occur in the document, a \nrepresentation that has been the basis for many successful applications \nof machine learning to text data. In this talk we will review some \nimportant developments over the past 10 years in modeling data \nrepresented in the form of counts, combining ideas from statistics and \nmachine learning. The talk will describe the general principles involved \nand then illustrate how these ideas can be applied to text documents, \nemail communications, and social networks, including recent work in my \nresearch group. The talk will conclude with some speculative comments on \nfuture directions.\n     </td></tr><tr><td><b>Speaker Bio</b></td><td>Padhraic Smyth is a Professor in the Department of Computer Science \n(with a joint appointment in Statistics) and Director of the Center for \nMachine Learning and Intelligent Systems at the University of \nCalifornia, Irvine. His research interests include machine learning, \ndata mining, pattern recognition, and applied statistics. He received a \nfirst class honors degree in Electronic Engineering from University \nCollege Galway (National University of Ireland) in 1984, and the MSEE \nand PhD degrees from the Electrical Engineering Department at the \nCalifornia Institute of Technology in 1985 and 1988 respectively. From \n1988 to 1996 he was a Technical Group Leader at the Jet Propulsion \nLaboratory, Pasadena, and has been on the faculty at UC Irvine since \n1996. Dr. Smyth is an ACM Fellow, a AAAI Fellow, and recieved the ACM \nSIGKDD Innovation Award in 2009. He is co-author of two well-known \nresearch texts in data mining: Modeling the Internet and the Web: \nProbabilistic Methods and Algorithms (with Pierre Baldi and Paolo \nFrasconi in 2003), and Principles of Data Mining, MIT Press, August \n2001, co-authored with David Hand and Heikki Mannila. He has served in \neditorial positions for journals such as the Journal of the American \nStatistical Association, the IEEE Transactions on Knowledge and Data \nEngineering, and the Journal of Machine Learning Research. His research \nhas been funded by a variety of government agencies such as NSF, NIH, \nONR, DARPA and DOE, as well by companies such as Google, IBM, Microsoft, \nand Yahoo! In addition to his academic research he is also active in \nconsulting, working with companies such as Samsung, Netflix, eBay, \nOracle, Microsoft, Yahoo!, Nokia, and ATT. </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Jan. 24, 2014</div></td><td><div class=\"eventInfor\">SPEAKER: Inna Giguere (Data Architect, Disney Interactive Media BI)</div><div class=\"eventInfor\">Web Analytics at the happiest place on earth</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99260\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99260\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Jan. 24, 2014 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Inna Giguere (Data Architect, Disney Interactive Media BI)</td></tr><tr><td><b>Title</b></td><td>Web Analytics at the happiest place on earth</td></tr><tr><td><b>Abstract</b></td><td>\nBusiness analytics requirements at Disney Interactive have pushed the limits of the Omniture reporting systems that has been used for the past decade into building an internal tracking and data warehouse solution. Consequently, we have built a data warehouse and enabled Video and Game Producers to fine-tune new content in near real-time, as well as provide an exhaustive platform for Data Scientists to build recommendation systems.\nThe presentation will focus on current data pipeline architecture at Disney Interactive and cover specific steps and challenges.  I will discuss how we (BI team) were able to leverage Hadoop\u2019s map/reduce processing capabilities and Vertica MPP engine to load data continuously from multiple sources. However, one of our biggest challenges remains handling memory intensive hash joins in Vertica without sacrificing performance. \n\t     </td></tr><tr><td><b>Speaker Bio</b></td><td>Inna Giguere is Data Architect at Disney Interactive Media Business Intelligence group. For the last 2 years she has been leading the architecture design and implementation of the Analytics Data Warehouse utilizing Hadoop, Vertica, and Scribe technology. Previously based out of San Francisco Bay Area and London, Inna has 16 years on industry experience creating scalable Data Warehouse solutions with focus on DB performance optimization in transactional and reporting systems. Her experience spans across technologies starting from COBOL/DB2 to Oracle (8i \u2013 11g), to SQL Server 2005-2012, to Vertica 6.1 working on datasets ranging from hundreds of megabytes to hundreds of terabytes. She has earned MS in Statistics in 2010.\n</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Jan. 17, 2014</div></td><td><div class=\"eventInfor\">SPEAKER: Phillip Sheu (Department of EECS)</div><div class=\"eventInfor\">Semantic Computing and Applications</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99259\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99259\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Jan. 17, 2014 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Phillip Sheu (Department of EECS)</td></tr><tr><td><b>Title</b></td><td>Semantic Computing and Applications</td></tr><tr><td><b>Abstract</b></td><td>\nSemantic Computing (SC) is an emerging field that addresses computing\ntechnologies which allow users to search, create, manipulate and connect\ncomputational resources (including data, documents, tools, people, agents,\ndevices, etc.) based on semantics.\n\nSemantic Computing includes the computing technologies (e.g., artificial\nintelligence, natural language, software engineering, data and knowledge\nengineering, computer systems, signal processing, etc.), and their\ninteractions, that may be used to extract or process computational content\nand descriptions. While some areas of Semantic Computing have appeared as\npieces in different disciplines, Semantic Computing glues these pieces\ntogether into an integrated theme with synergetic interactions. It\naddresses not only the analysis and transformation of signals (e.g.,\npixels, words) into useful information, but also how such information can\nbe accessed and used to synthesize new signals.\n\nThe National Science Foundation has approved the planning of an\nIndustry/University Cooperative Research Center (I/UCRC) for Semantic\nComputing currently involving UCI, UCSD and UCLA. The missions of the\nI/UCRC are to develop semantic technologies that may facilitate the\ntransition of the Internet into its next generation, and develop new\nbusiness models to stimulate, strengthen, and grow the economy.\n\nAn important outcome of this I/UCRC is a Semantic Problem Solving Network\n(SPSN) which is a public consortium of resources from all domains\nincluding data, documents, devices, products, services, and people. The\nresources are interconnected and integrated with a service-oriented\narchitecture and a semantic layer to help the public to solve general\nproblems and professional users to solve domain specific problems (e.g.,\nfinance, IT, health, defense, entertainment, education, manufacturing).\n\nThis talk will introduce Semantic Computing and its applications, the\noperations of the I/UCRC, the architecture of the SPSN, how companies and\nacademic researchers can join or affiliate with the I/UCRC and SPSN, and\nhow companies and academic researchers can benefit.\n\t     </td></tr><tr><td><b>Speaker Bio</b></td><td>\nPhillip C.-Y. Sheu is a professor of EECS, Computer Science and Biomedical\nEngineering at the University of California, Irvine. He received his B.S.\ndegree in EE from National Taiwan University, and MS and Ph.D degrees in\nEECS from the University of California at Berkeley.\n\nDr. Sheu\u2019s current research interests include semantic computing and\ncomplex biomedical systems. He is a fellow of IEEE, a founder of the IEEE\nComputer Society Technical Committee on Semantic Computing (TCSEM), IEEE\nInternational Conference on Semantic Computing (ICSC), International\nJournal of Semantic Computing (IJSC), the NSF I/UCRC (Industry University\nCooperative Research Center) for Semantic Computing (ISC) being planned,\nand a main author of the book Semantic Computing (SC, eds. P. Sheu, H. Yu,\nC.V. Ramamoorthy, A. Joshi and L.A. Zadeh, IEEE and Wiley, 2010).\n</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Nov. 15, 2013</div></td><td><div class=\"eventInfor\">SPEAKER: Jos\u00e9 A. Blakeley (Microsoft Corporation)</div><div class=\"eventInfor\">Microsoft SQL Server Parallel Data Warehouse - Architecture Overview</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99252\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99252\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Nov. 15, 2013 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Jos\u00e9 A. Blakeley (Microsoft Corporation)</td></tr><tr><td><b>Title</b></td><td>Microsoft SQL Server Parallel Data Warehouse - Architecture Overview</td></tr><tr><td><b>Abstract</b></td><td>\n In this talk I will present an architectural overview of the SQL Server Parallel Data Warehouse DBMS system. PDW is a massively parallel processing, share nothing, scale-out version of SQL Server for data warehouse and big data workloads. The product is packaged as a database appliance built on industry standard hardware.\n\t     </td></tr><tr><td><b>Speaker Bio</b></td><td>Jos\u00e9 Blakeley is Partner Architect in the Modern Data Warehousing Unit of the Server and Tools Division at Microsoft where he contributes to the development of the SQL Server Parallel Data Warehouse (PDW) DBMS product. Jos\u00e9 joined Microsoft in 1994. Some of his contributions at Microsoft include the development of the OLE DB data access interfaces, the integration of the .NET runtime with SQL Server 2005, the extensibility features in SQL Server, and the creation of the ADO.NET Entity Framework in Visual Studio 2008. Jos\u00e9 has authored many conference papers, book chapters and journal articles on design aspects of relational and object database management systems, and data access. Jose has 20 patents awarded and 22 patents pending. He became an ACM Fellow in 2009. Before joining Microsoft, Jos\u00e9 was a member of the technical staff with Texas Instruments where he was co-principal investigator of the DARPA Open-OODB system. He received a B. Eng from ITESM, Monterrey, Mexico, and a Ph.D. in computer science from University of Waterloo, Canada. </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Oct. 25, 2013</div></td><td><div class=\"eventInfor\">SPEAKER: David Lomet (joint work with Justin Levandoski and Sudipta Sengupta)(MSR)</div><div class=\"eventInfor\">LLAMA: A Cache/Storage Subsystem for Modern Hardware</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99248\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99248\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Oct. 25, 2013 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>David Lomet (joint work with Justin Levandoski and Sudipta Sengupta)(MSR)</td></tr><tr><td><b>Title</b></td><td>LLAMA: A Cache/Storage Subsystem for Modern Hardware</td></tr><tr><td><b>Abstract</b></td><td>\nLLAMA is a subsystem designed for new hardware environments that supports an API for page-oriented access methods, providing both cache and storage management. Caching (CL) and storage (SL) layers use a common mapping table that separates a page\u2019s logical and physical location. CL supports data updates and management updates (e.g., for index re-organization) via latch-free compare-and-swap atomic state changes on its mapping table. SL uses the same mapping table to cope with page location changes produced by log structuring on every page flush. To demonstrate LLAMA\u2019s suitability, we tailored our latch-free Bw-tree implementation to use LLAMA. The Bw-tree is a B-tree style index. Layered on LLAMA, it has higher performance and scalability using real workloads compared with BerkeleyDB\u2019s B-tree, which is known for good performance.\n\t     </td></tr><tr><td><b>Speaker Bio</b></td><td>\nDavid Lomet (Ph.D from Penn) is a Principal Researcher and manager of the Database Group at Microsoft Research Redmond.  Earlier, he was at Digital's CRL, Wang Institute, and IBM Research.  Lomet has over 100 papers on databases, indexing, concurrency, and recovery, including two SIGMOD \"best papers\".  He is an inventor of transactions.  Lomet has served on SIGMOD, VLDB, and ICDE PCs, being co-chair of ICDE'2000 and VLDB'2006.  He won SIGMOD's Contributions Award for his service as Data Engineering Bulletin Editor-in-Chief since 1992. He has been editor of ACM TODS, VLDB Journal, and DAPD.  He has served on the VLDB Endowment and ICDE Steering Committee, has been IEEE TCDE Chair and is a Fellow of AAAS, ACM, and IEEE.\n             </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Oct. 18, 2013</div></td><td><div class=\"eventInfor\">SPEAKER: Tyson Condie (Microsoft and UCLA)</div><div class=\"eventInfor\">Big Learning Systems</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99246\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99246\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Oct. 18, 2013 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Tyson Condie (Microsoft and UCLA)</td></tr><tr><td><b>Title</b></td><td>Big Learning Systems</td></tr><tr><td><b>Abstract</b></td><td>\nA new wave of systems is emerging in the space of Big Data Analytics that open the door to programming models beyond Hadoop MapReduce (HMR). It is well understood that HMR is not ideal for applications in the domain of machine learning and graph processing. This realization is fueling a number of new (Big Data) system efforts: Berkeley Spark, Google Pregel, GraphLab (CMU), and AsterixDB (UC Irvine), to name a few. Each of these add unique capabilities, but form islands around key functionalities: fault-tolerance, resource allocation, and data caching. In this talk, I will provide an overview of some Big Data systems starting with Google's MapReduce, which defined the foundational architecture for processing large data sets. I will then identify a key limitation in this architecture; namely, its inability to efficiently support iterative workflows. I will then describe real-world examples of systems that aim to fill this computational void. I will conclude with a description of my own work on a layering that unifies key runtime functionalities (fault-tolerance, resource allocation, data caching, and more) for workflows (both iterative and acyclic) that process large data sets.\n\t     </td></tr><tr><td><b>Speaker Bio</b></td><td>\nTyson Condie is a principal scientist with the Cloud and Information Services Lab at Microsoft and an Assistant Professor at UCLA. He received his Ph.D. from Berkeley. His research focuses on data analytics, distributed systems, Internet-scale query processing and optimization, and declarative language design and implementation. His current work involves building a system software stack for large-scale data processing tasks on resource managers like Apache YARN, Berkeley Mesos, Google Omega, and Facebook Corona.             </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Oct. 11, 2013</div></td><td><div class=\"eventInfor\">SPEAKER: Anhai Doan (University of Wisconsin and WalmartLabs)</div><div class=\"eventInfor\">Toward Hands-Off Crowdsourcing: Crowdsourced Entity Matching for the Masses</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99245\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99245\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Oct. 11, 2013 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Anhai Doan (University of Wisconsin and WalmartLabs)</td></tr><tr><td><b>Title</b></td><td>Toward Hands-Off Crowdsourcing: Crowdsourced Entity Matching for the Masses</td></tr><tr><td><b>Abstract</b></td><td>Entity matching (EM) finds data records that refer to the same\nreal-world entity. Recent work has applied crowdsourcing to EM, and\nhas clearly established the promise of this approach. This work\nhowever is limited in that it crowdsources only parts of the EM\nworkflow, requiring a developer who knows how to code to execute the\nremaining parts. Consequently, this work does not scale to the growing\nEM need at enterprises and crowdsourcing startups, and cannot handle\nscenarios where ordinary users (i.e., the masses) want to leverage\ncrowdsourcing to match entities.\n\nTo address these problems, we propose the notion of hands-off\ncrowdsourcing (HOC), which crowdsources the entire workflow of a task,\nthus requiring no developers. We show how HOC can represent a next\nlogical direction for crowdsourcing research, scale up EM at\nenterprises and crowdsourcing startups, and open up crowdsourcing for\nthe masses. We describe Corleone, a HOC solution for EM. We show how\nCorleone uses the crowd to generate blocking rules, applies active\nlearning to learn matchers, estimates accuracy given severe skew, and\nidentifies difficult-to-match pairs to which Corleone can apply more\ncomplex matchers. Finally, we discuss the implications of our work to\nexecuting crowdsourced RDBMS joins, cleaning learning models, and\nsoliciting complex information types from crowd workers.\n\t     </td></tr><tr><td><b>Speaker Bio</b></td><td>AnHai Doan is an Associate Professor in the database group at the\nUniversity of Wisconsin, Madison. His current interests include\ncrowdsourcing, knowledge bases, data integration, and information\nextraction. He received the ACM Doctoral Dissertation Award in 2003\nand a Sloan fellowship in 2007. AnHai was Chief Scientist of Kosmix, a\nsocial media startup acquired by Walmart in 2011. Currently he also\nworks as Chief Scientist of WalmartLabs, a research and development\nlab devoted to analyzing and integrating data for e-commerce. AnHai is\na co-author of \u201cPrinciples of Data Integration\u201d (with Alon Halevy and\nZack Ives), a textbook published by Morgan Kaufmann in 2012. </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Sept. 20, 2013</div></td><td><div class=\"eventInfor\">SPEAKER: Li Xiong (Emory University)</div><div class=\"eventInfor\">Real-Time Aggregate Monitoring with Differential Privacy</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99244\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99244\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Sept. 20, 2013 2 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Li Xiong (Emory University)</td></tr><tr><td><b>Title</b></td><td>Real-Time Aggregate Monitoring with Differential Privacy</td></tr><tr><td><b>Abstract</b></td><td>\nWhile Big Data promises significant economic and social benefits, it also raises serious privacy concerns.  Real-time aggregate statistics of data collected from individuals can be shared to enable many applications such as disease surveillance and traffic monitoring.  However, it must be ensured that the privacy of individuals is not compromised.  While differential privacy has emerged as a de facto standard for private data analysis, directly applying the differential privacy mechanisms on time-series has limited utility due to high correlations between data values.  In this talk, I will present FAST, a novel Filtering and Adaptive Sampling based framework for monitoring aggregate Time-series under differential privacy.  FAST adaptively samples long time-series according to detected data dynamics and simultaneously uses filtering techniques to dynamically predict and correct released data values.  I will present experimental studies using real datasets demonstrating the feasibility and benefit of FAST and conclude with open questions. \n\t     </td></tr><tr><td><b>Speaker Bio</b></td><td>\nLi Xiong is an Associate Professor in the Department of Mathematics and Computer Science and the Department of Biomedical Informatics at Emory University where she directs the Assured Information Management and Sharing (AIMS) research group. She holds a PhD from Georgia Institute of Technology, an MS from Johns Hopkins University, and a BS from University of Science and Technology of China, all in Computer Science. She also worked as a software engineer in IT industry for several years prior to pursuing her doctorate. Her areas of research are in data privacy and security, distributed data management, and biomedical informatics. She is a recent recipient of the Career Enhancement Fellowship by Woodrow Wilson Foundation, a Cisco Research Award, and an IBM Faculty Innovation Award. Her current research is supported by NSF and AFOSR.\n             </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Sep. 13, 2013</div></td><td><div class=\"eventInfor\">SPEAKER: Raman Grover (ISG PhD candidate)</div><div class=\"eventInfor\">Scalable Fault-tolerant Elastic Data Feeds</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99242\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99242\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Sep. 13, 2013 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Raman Grover (ISG PhD candidate)</td></tr><tr><td><b>Title</b></td><td>Scalable Fault-tolerant Elastic Data Feeds</td></tr><tr><td><b>Abstract</b></td><td>In this ISG talk / thesis proposal, I describe and study\nthe support for data feed ingestion in AsterixDB, a Big Data\nManagement System (BDMS) that provides a platform for the\nscalable storage, searching, and analysis of very large volumes\nof semi-structured data. Data feeds are a mechanism for having\ncontinuous data arrive into a database system from external\nsources that produce data continuously, and to have that data\nincrementally populate a persisted dataset and associated indexes.\nTo my knowledge, this will be the first system to explore the\nchallenges involved in building a data ingestion facility that deals\nwith semi-structured data and employs partitioned parallelism to\nscale the facility and couple it with high-volume and/or parallel\nexternal data sources. I describe language-level support for\nmodeling/defining a feed and present the methodology for providing\ntolerance to software/hardware failures. Mechanisms by\nwhich a feed can dynamically adapt to different workloads for\noptimum usage of resources are provided.</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">May 17, 2013</div></td><td><div class=\"eventInfor\">SPEAKER: Charles Boicey (UCI Irvine Health and Information Services)</div><div class=\"eventInfor\">Apache Hadoop in the Healthcare Setting</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99241\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99241\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>May 17, 2013 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Charles Boicey (UCI Irvine Health and Information Services)</td></tr><tr><td><b>Title</b></td><td>Apache Hadoop in the Healthcare Setting</td></tr><tr><td><b>Abstract</b></td><td>Apache Hadoop is open source software that enables distributed processing of large data sets across clusters of computers. Hadoop can scale up to thousands of computers, each able to store and process data. Hadoop is capable of ingesting and storing the types of data found in healthcare, structured, unstructured, image and video. Hadoop also has an advantage for healthcare in its ability to interoperate with other open source software. This interoperability combined with scalability makes Hadoop an ideal platform for the development of a software ecosystem that fills in the gaps left by the Electronic Medical Record and Enterprise Data Warehouse.</td></tr><tr><td><b>Speaker Bio</b></td><td>\nCharles Boicey is the Informatics Solutions Architect for the UC Irvine Health. At UCI Charles is responsible for the development and implementation of the enterprise data warehouse, health information exchange, home health integration and UC Irvine Health\u2019s \u201cBig Data\u201d initiative. Charles has 20 years of experience in the healthcare field.cope of clinical expertise encompasses trauma critical care nursing. Charles is Vice President of the American Nursing Informatics Association.\n             </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">May 10, 2013</div></td><td><div class=\"eventInfor\">SPEAKER: </div><div class=\"eventInfor\">No Seminar</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99240\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99240\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>May 10, 2013 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td></td></tr><tr><td><b>Title</b></td><td>No Seminar</td></tr><tr><td><b>Abstract</b></td><td>\nNo ISG seminar.  Leaving this time free so that ISG affiliates can attend today's ICS Trends in Society and Information Technology talk (see www.ics.uci.edu/trends).             \n             </td></tr><tr><td><b>Speaker Bio</b></td><td>\n             </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">April 19, 2013</div></td><td><div class=\"eventInfor\">SPEAKER: Michael J. Carey (with the AsterixDB dev team) </div><div class=\"eventInfor\">Want To Kick My Asterix(DB)?</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99233\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99233\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>April 19, 2013 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Michael J. Carey (with the AsterixDB dev team) </td></tr><tr><td><b>Title</b></td><td>Want To Kick My Asterix(DB)?</td></tr><tr><td><b>Abstract</b></td><td>\n\t\tDue to several faculty traveling and thus being MIA this coming Friday, the planned ISG seminar by Teradata is being postponed until later in the quarter.  Instead, this week's Friday ISG seminar slot will be used to invite ISG (and ICS) community participation in the forthcoming Beta Release of a new open source BDMS (Big Data Management System) that members of UCI's ASTERIX project have been working on for nearly four years.  We want this new \"product\", to be called AsterixDB, to be very high quality - and we are hereby inviting interested helpers at UCI to come hear about it and then help us polish it by downloading it and playing with it - trying out its data model, query language, and API for apps - kicking its tires - this Friday!  Our goal is to get a handful of \"outside the team\" folks to join us in using the system ahead of the Beta Release and then filing any issues using the GoogleCode issue tracking infrastructure - so that when we release this publically, it's well-polished and well shaken out.  (To date we have only delivered an Alpha Release, and only very recently, to one of our industrial partners.)  So - if you like database technology and would like to help us deliver \"Big Data 2.0\" to the world in a month or so - and you have time/interest in playing a bit in the very near term - PLEASE COME FRIDAY and we will show you what AsterixDB is all about!  This will be an informal presentation, based on giving a tour of our Alpha documentation and the release info on the GoogleCode wiki, and then having the team give a demo and even help you get the system working in real time if you bring your favorite laptop when you come.  We hope to see some of you there! (Refreshments will be provided, as usual for the ISG seminar, but we might upgrade the refreshments a little for this event; we'll see. We will also surely do something nice later for any outside folks who do end up significantly contributing in this manner to the quality of the release.)  If you plan to come on Friday, please RSVP to the speaker (mjcarey@ics.uci.edu) so we know what to maybe expect in terms of potential turnout.  Thx!          \n             </td></tr><tr><td><b>Speaker Bio</b></td><td>\n\t\tMike Carey is a Professor in the ISG subgroup of the UCI CS department.  His goal is to eventually change the Big Data management landscape forever through the great work that our AsterixDB team has done and is now preparing to share.  :-)\n             </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">April 12, 2013</div></td><td><div class=\"eventInfor\">SPEAKER: Shahram Ghandeharizadeh (USC)</div><div class=\"eventInfor\"></div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99232\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99232\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>April 12, 2013 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Shahram Ghandeharizadeh (USC)</td></tr><tr><td><b>Title</b></td><td></td></tr><tr><td><b>Abstract</b></td><td>          \n             </td></tr><tr><td><b>Speaker Bio</b></td><td>\n             </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">March 1, 2013</div></td><td><div class=\"eventInfor\">SPEAKER: Pat Helland (Salesforce)</div><div class=\"eventInfor\">Immutability Changes Everything</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99224\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99224\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>March 1, 2013 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Pat Helland (Salesforce)</td></tr><tr><td><b>Title</b></td><td>Immutability Changes Everything</td></tr><tr><td><b>Abstract</b></td><td>For a number of decades, I've been saying \"Computing Is Like Hubble's Universe, Everything Is Getting Farther Away from Everything Else\".   It\nused to be that everything you cared about ran on a single database and the transaction system presented you the abstraction of a singularity;\nyour transaction happened at a single point in space (the database) and a single point in time (it looked like it was before or after all other transactions).\n\nNow, we see a more complicated world.  Across the Internet, we put up HTML documents or send SOAP calls and these are not in a transaction.  Within a cluster, we typically write files in a file system and then read them later in a big map-reduce job that sucks up read-only files, crunches, and writes files as output.  Even inside the emerging many-core systems, we see high-performance computation on shared memory but increasing cost to using semaphores.  Indeed, it is clear that \"Shared Memory Works Great as Long as You Don't Actually SHARE Memory\".\n\nThere are emerging solutions which are based on immutable data.  It seems we need to look back to our grandparents and how they managed distributed work in the days before telephones.  We realize that \"Accountants Don't Use Erasers\" but rather accumulate immutable knowledge and then offer interpretations of their understanding based on the limited knowledge presented to them.  This talk will explore a number of the ways in which our new distributed systems leverage write-once and read-many immutable data.         \n             </td></tr><tr><td><b>Speaker Bio</b></td><td>Pat Helland has been working on databases, transaction processing, messaging, and distributed systems for 34 years.  In the 1980s, he was chief architect of the Tandem NonStop's transaction system called TMF (Transaction Monitoring Facility).  From 1991 to 1994, he worked at HaL Computers (a subsidiary of Fujitsu) and designed and architected a CC-NUMA (Cache Coherent Non-Uniform Memory Architecture) multiprocessor which Fujitsu shipped.  Starting in 1994, Pat worked at Microsoft where he was the chief architect for MTS (Microsoft Transaction Server) and DTC (Distributed Transaction Coordinator).  Later, he built SQL Service Broker which offers high performance (&gt;100K msg/sec) transactional exactly-once messaging integrated with SQL Server.  From 2005 to 2007, Pat work at Amazon on the product catalog and then returned in 2007 to Microsoft.  By 2009, he was working on Cosmos, the multi-peta-byte storage and computational plumbing behind Bing.  This year, Pat moved to San Francisco to be by the grandkids and joined Salesforce.com working on database and filesystem technology.\n             </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Feb 22, 2013</div></td><td><div class=\"eventInfor\">SPEAKER: Swaroop Jagadish and Kapil Surlaker (LinkedIn)</div><div class=\"eventInfor\">On Brewing Fresh Espresso: LinkedIn\u2019s Distributed Data Serving Platform</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99223\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99223\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Feb 22, 2013 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Swaroop Jagadish and Kapil Surlaker (LinkedIn)</td></tr><tr><td><b>Title</b></td><td>On Brewing Fresh Espresso: LinkedIn\u2019s Distributed Data Serving Platform</td></tr><tr><td><b>Abstract</b></td><td>As LinkedIn has grown, our core data sets and request processing requirements have grown as well. The development of Espresso was motivated by our desire to migrate LinkedIn\u2019s online serving infrastructure from monolithic, commercial, RDBMS systems running on high cost specialized hardware to elastic clusters of commodity servers running free software; and to improve agility by enabling rapid development by simplifying the programming model, separating scalability, routing, caching from business logic. Espresso is a document-oriented distributed data serving platform that has been built to address LinkedIn\u2019s requirements for a scalable, performant, source-of-truth primary store. It provides a hierarchical document model, transactional support for modifications to related documents, real- time secondary indexing, on-the-fly schema evolution and provides a timeline consistent change capture stream. \nThis talk describes the motivation and design principles involved in building Espresso, its architecture and presents a set of experimental results that characterize the performance of the system along various dimensions.         \n             </td></tr><tr><td><b>Speaker Bio</b></td><td>\nSwaroop Jagadish is a member of the Data Infrastructure team at\nLinkedin, where he works on distributed data systems\nsuch as Databus, Helix and Espresso. Prior to that, he worked at Yahoo where he \nbuilt one of the first real-time bidding engines in the display-ads industry. \nHe holds B.E. from BMS College of Engineering and M.S. from University of California, Santa Barbara.\nKapil Surlaker is a member of the Data Infrastructure team at\nLinkedin, where he works on distributed data systems\nsuch as Databus, Helix and Espresso. Prior to that, he worked at\nKickfire (acquired by Teradata) where he built high-performance\nDatabase systems. Earlier in his career, he worked on replication\ntechnology at Oracle where he was part of the team that built Oracle\nStreams. He holds B.Tech. (CS) from IIT Bombay and M.S. From University\nof Minnesota.\n             </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Feb 8, 2013</div></td><td><div class=\"eventInfor\">SPEAKER: Ronen Vaisenberg (Google)</div><div class=\"eventInfor\">Practice Talk: Scheduling Sensors for Monitoring Sentient Spaces using an Approximate POMDP Policy (Percom2013)</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99222\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99222\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Feb 8, 2013 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Ronen Vaisenberg (Google)</td></tr><tr><td><b>Title</b></td><td>Practice Talk: Scheduling Sensors for Monitoring Sentient Spaces using an Approximate POMDP Policy (Percom2013)</td></tr><tr><td><b>Abstract</b></td><td>We present a framework for sensor actuation and control in sentient spaces, in which sensors are used to observe a physical phenomena. Our framework utilizes the spatio-temporal statistical properties of an observed phenomena, with the goal of maximizing an application specified reward. Specifically, we define an observation of a phenomena by assigning it a discrete value (state) and we model its semantics as the transition between these values (states). This semantic model is used to predict the future states in which the phenomena is likely to be at, based on partially observed past states. To accomplish real-time agility, we designed an approximate, adaptive-grid solution for POMDPs that yields practically good results, and in some cases, guarantees on the quality of the approximation. We instantiate the framework in a camera network and use it perform real- time actuation of large-scale sensor networks. To the best of our knowledge, we are the first to address the problem of actuating a large scale sensor network based on an approximated POMDP formulation. Our semantic model is simple enough to be implemented in real-time, yet powerful enough to capture meaningful semantics of typical behavior. Our action selection process is as fast as a table lookup in real-time.          \n             </td></tr><tr><td><b>Speaker Bio</b></td><td>\n             </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Feb 15, 2013</div></td><td><div class=\"eventInfor\">SPEAKER: Hongzhi Wang (ISG)</div><div class=\"eventInfor\"></div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99222\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99222\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Feb 15, 2013 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Hongzhi Wang (ISG)</td></tr><tr><td><b>Title</b></td><td></td></tr><tr><td><b>Abstract</b></td><td>          \n             </td></tr><tr><td><b>Speaker Bio</b></td><td>\n             </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Feb. 1, 2013</div></td><td><div class=\"eventInfor\">SPEAKER: Marco Sanvido (Pure Storage)</div><div class=\"eventInfor\">The Why and How of an All-Flash Enterprise Storage Array</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99220\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99220\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Feb. 1, 2013 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Marco Sanvido (Pure Storage)</td></tr><tr><td><b>Title</b></td><td>The Why and How of an All-Flash Enterprise Storage Array</td></tr><tr><td><b>Abstract</b></td><td>Enterprise storage is an $30 billion a year industry dominated by spinning disks. Flash storage is poised to take a large\nchunk of the market, having grown significantly in capacity and production, driven by consumer electronics.\nFlash's technical advantages over disk promise storage arrays that are faster and easier to use while consuming less power and costing less.\n\nThe downsides of flash (inc. large erase blocks, limited overwrites, and higher price) mean that using flash as a drop-in\nreplacement for disk leads to increased price, volatile performance, and decreased reliability.\nIn this talk, we describe the design of the Pure FlashArray, an enterprise storage array built around consumer flash storage.\nThe array and its software, Purity, play to the advantages of flash while minimizing the downsides. Purity writes to flash\nin multiples of the erase block size and stores its metadata in a key-value store that minimizes overwrites and stores approximate\nanswers, trading extra reads for fewer writes. And, Purity reduces data stored on flash through a range of techniques, including\ncompression, deduplication, and thin provisioning.\n\nThe net result is a flash array that deliver a sustained read-write workload of over 100,000 4kb I/O requests per second while\nmaintaining sub-millisecond latency. With many customers seeing 4x or greater data reduction, the Pure FlashArray ends up\nbeing cheaper than disk too.\n             </td></tr><tr><td><b>Speaker Bio</b></td><td>\nDr. Marco Sanvido holds a Dipl.-Ing. degree (1996) and a Dr.techn. degree (2002) in Computer\nScience from the Swiss Federal Institute of Technology in Z\u00fcrich, Switzerland (ETHZ).\nHe was a co-founder of weControl, an ETHZ spin-off, where he developed low-power and\nreal-time embedded systems for autonomous flying vehicles. He was a postdoctoral\nresearcher in Computer Science at the University of California at Berkeley from 2002 to 2004,\nand thereafter he worked on virtualization at VMware. In 2005 he then became a researcher\nat Hitachi Global Storage Technologies, where he worked on hard disk drive and solid state drive\narchitectures. Since 2010 Marco joined Pure Storage as a Principal Software Engineer.\n             </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Jan. 25, 2013</div></td><td><div class=\"eventInfor\">SPEAKER: Silvius Rus (Quantcast)</div><div class=\"eventInfor\">Petabyte Scale Data Processing at Quantcast</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99211\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99211\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Jan. 25, 2013 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Silvius Rus (Quantcast)</td></tr><tr><td><b>Title</b></td><td>Petabyte Scale Data Processing at Quantcast</td></tr><tr><td><b>Abstract</b></td><td>The talk will present the big data storage, processing and query systems\nin production at Quantcast.  We receive up to 50 TB of new data every day,\nrespond to 500,000 events per second, process up to 30 PB per day and\nstore tens of petabytes of data.  We have implemented our own MapReduce\nsoftware stack that scales better and has significantly lower resource\n\n\n\n\n\n\nrequirements than Hadoop. The QFS file system is available open source\nat https://github.com/quantcast/qfs/wiki.\n\t\t\t</td></tr><tr><td><b>Speaker Bio</b></td><td>Silvius Rus leads Big Data Platforms at Quantcast.  He directs, manages\nand participates in the development of cluster language runtimes (SQL,\nSawzall), petabyte scale map-reduce, interactive big data analytics,\ncluster resource management, distributed file systems and large scale\nrealtime processing.  Before Quantcast he was at Google working on Gmail\nload balancing across datacenters, parallel memory allocation performance,\nserver performance and C++ compiler and library optimization.\nSilvius holds a PhD in computer science from Texas A and M University,\nwhere he worked on full program optimization based on hybrid\n(static and dynamic) analysis of memory reference patterns.</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Jan. 18, 2013 (Special Time)</div></td><td><div class=\"eventInfor\">SPEAKER: Joe Hellerstein (UC Berkeley)</div><div class=\"eventInfor\">Keep CALM and Query On</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99210\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99210\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Jan. 18, 2013 (Special Time) 11 am</td></tr><tr><td><b>Location</b></td><td>DBH 6011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Joe Hellerstein (UC Berkeley)</td></tr><tr><td><b>Title</b></td><td>Keep CALM and Query On</td></tr><tr><td><b>Abstract</b></td><td>\n\nAny modern software system of note has two key characteristics: it is a distributed system, and it manages significant amounts of data.  As a result, the topic of distributed data consistency has become a key problem in the engineering of modern software systems.  Conventional distributed systems wisdom dictates that perfect consistency is too expensive to guarantee in general, and consistency mechanisms\u2014if they are used at all\u2014should be reserved for infrequent, small-scale, mission-critical tasks.   Like most design maxims, these ideas are not so easy to translate into practice; all kinds of unavoidable tactical questions pop up.  For example:\n\n \u2022 Exactly where in my multifaceted system is loose consistency \u201cgood enough\u201d to meet application needs?\n \u2022 How do I know that my \u201cmission-critical\u201d software isn\u2019t tainted by my \u201cbest effort\u201d components?\n \u2022 How do I ensure that my design maxims are maintained as software and developer teams evolve?\n\nUntil recently, answers to these questions have been more a matter of folklore than mathematics.\n\nIn this talk, I will describe the CALM Theorem, which links Consistency And Logical Monotonicity, and discuss how it can inform distributed software development.  I'll also describe Bloom, a \"disorderly\" distributed programming language developed in my group.  Bloom admits a form of automated CALM analysis, which enables a compiler to answer questions like the ones above.    \n\nTime permitting, I will also point out some additional results from my two main research projects: the BOOM project on large-scale system development, and the d^p project on human interaction in the data analysis lifecycle.\n\n             </td></tr><tr><td><b>Speaker Bio</b></td><td>\nJoseph M. Hellerstein is a Chancellor's Professor of Computer Science at the University of California, Berkeley, whose research focuses on data-centric systems and the way they drive computing. A Fellow of the ACM, his work has been recognized via awards including an Alfred P. Sloan Research Fellowship, MIT Technology Review's TR10 and TR100 lists, Fortune Magazine's \"Smartest in Tech\" list, and two ACM-SIGMOD \"Test of Time\" awards. He has led a number of influential open source projects, including Bloom, MADlib, Telegraph, and TinyDB.\n\nIn 2012, Joe co-founded Trifacta, Inc, which develops productivity software for data analysts.\n             </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Dec. 14, 2012</div></td><td><div class=\"eventInfor\">SPEAKER: Bijit Hore (UCI ISG)</div><div class=\"eventInfor\">Hide-and-Seek in the cloud: How to securely store and query your data in untrusted environments</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99203\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99203\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Dec. 14, 2012 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Bijit Hore (UCI ISG)</td></tr><tr><td><b>Title</b></td><td>Hide-and-Seek in the cloud: How to securely store and query your data in untrusted environments</td></tr><tr><td><b>Abstract</b></td><td>Security and privacy of data is a major concern for organizations (and many individuals) that use cloud-based services to cater to their IT needs. This is cited as the central reason why many federal, healthcare, and financial organizations have  not embraced cloud computing in a major way in spite of its many benefits. In this talk we consider the central problem of \"data confidentiality\", that arises while storing sensitive data in the cloud. While data encryption is an obvious solution for ensuring confidentiality, standard algorithms like AES make the data unusable in the cloud. For example, keyword search or database queries cannot be evaluated against the encrypted data. Over the past decade, many new schemes have been developed, that admit a variety of computations directly on the encrypted representation.  We give a brief overview of some of the important techniques proposed in this arena, specifically, for evaluating keyword-match and range queries. Finally, we describe our own contributions to this area and conclude with a discussion about open problems and future directions.</td></tr><tr><td><b>Speaker Bio</b></td><td>\n             </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Dec. 7, 2012</div></td><td><div class=\"eventInfor\">SPEAKER: </div><div class=\"eventInfor\">No Seminar</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99202\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99202\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Dec. 7, 2012 3 pm</td></tr><tr><td><b>Location</b></td><td></td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td></td></tr><tr><td><b>Title</b></td><td>No Seminar</td></tr><tr><td><b>Abstract</b></td><td>\n\t\t\tNo ISG seminar.  Leaving this time free so that ISG affiliates can attend today's ICS Trends in Society and Information Technology talk (see www.ics.uci.edu/trends).             </td></tr><tr><td><b>Speaker Bio</b></td><td>\n             </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Nov. 30, 2012</div></td><td><div class=\"eventInfor\">SPEAKER: Peter Bailis (UC Berkeley)</div><div class=\"eventInfor\">Probabilistically Bounded Staleness for Practical Partial Quorums</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99200\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99200\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Nov. 30, 2012 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Peter Bailis (UC Berkeley)</td></tr><tr><td><b>Title</b></td><td>Probabilistically Bounded Staleness for Practical Partial Quorums</td></tr><tr><td><b>Abstract</b></td><td>Data store replication results in a fundamental trade-off between operation latency and data consistency. In this talk, we examine this trade-off in the context of quorum-replicated data stores. Under partial, or non-strict quorum replication, a data store waits for responses from a subset of replicas before answering a query, without guaranteeing that read and write replica sets intersect. As deployed in practice, these configurations provide only basic eventual consistency guarantees, with no limit to the recency of data returned. However, anecdotally, partial quorums are often \u201cgood enough\u201d for practitioners given their latency benefits.\n\nWe explain why partial quorums are regularly acceptable in practice, analyzing both the staleness of data they return and the latency benefits they offer. We introduce Probabilistically Bounded Staleness (PBS) consistency, which provides expected bounds on staleness with respect to both versions and wall clock time. We derive a closed-form solution for versioned staleness as well as model real-time staleness for representative Dynamo-style systems under internet-scale production workloads. Using PBS, we measure the latency-consistency trade-off for partial quorum systems. We quantitatively demonstrate how and why eventually consistent systems frequently return consistent data within tens of milliseconds while offering significant latency benefits.\n\nThis is joint work with Shivaram Venkataraman, Mike Franklin, Joe Hellerstein, and Ion Stoica at UC Berkeley. An earlier version of this work appeared at VLDB 2012 (selected for \"Best of VLDB 2012\"), and an implementation of PBS is slated for release in Cassandra 1.2.0. Demo: http://pbs.cs.berkeley.edu/#demo</td></tr><tr><td><b>Speaker Bio</b></td><td>Peter Bailis is a graduate student in Computer Science at UC Berkeley, where he works closely with Joe Hellerstein, Ion Stoica, and Ali Ghodsi. He currently studies distributed systems, with a particular focus on distributed consistency models. Peter received his A.B. from Harvard College in 2011, where he worked with Margo Seltzer and Matt Welsh and was a 2011 CRA Outstanding Undergraduate Researcher. He is the recipient of the NSF Graduate Research Fellowship and the Berkeley Fellowship for Graduate Study and is a co-founder of @TinyToCS, the premiere journal for Computer Science research of 140 characters or less.\n\n             </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Nov. 9, 2012</div></td><td><div class=\"eventInfor\">SPEAKER: Chaitan Baru (SDSC at UCSD)</div><div class=\"eventInfor\">Data Initiatives at SDSC</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99197\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99197\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Nov. 9, 2012 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Chaitan Baru (SDSC at UCSD)</td></tr><tr><td><b>Title</b></td><td>Data Initiatives at SDSC</td></tr><tr><td><b>Abstract</b></td><td>\n\t\t\tAs a data-oriented supercomputer center, SDSC is engaged in a variety of\nactivities that support data-intensive computing and big data, from\nresearch and development to fielding production systems, and enabling end\napplications. This talk will provide an overview of several data\nactivities at SDSC including the Gordon supercomputer; data intensive\napplications on Gordon; the SDSC Cloud, with Globus Online interface for\nOpenStack; and new initiatives such as the Center for Large-scale Data\nSystems Research (CLDS). We will present two CLDS programs, one on\nestablishing industry standards for Big Data Benchmarking and another on\nData Growth and Data Value. A new initiative targeted at long-tail\nscientific data, motivated partly by needs identified by the NSF EarthCube\ninitiative and by the challenges faced by a typical research university,\nwill also be presented. There are many opportunities for joint\ncollaborations and student projects across these initiatives.\n\t\t\t</td></tr><tr><td><b>Speaker Bio</b></td><td>\nChaitan Baru, is Associate Director for Data Initiatives at the San\nDiego Supercomputer Center Director, UC San Diego, where he also directs\nthe Center for Large-scale Data Systems research (CLDS). His technical\ninterests are in the areas of scientific\ndata management, large-scale data systems, data integration, data\nanalytics, and parallel database systems. He has been involved in\ncyberinfrastructure projects across a range of science disciplines, e.g.\nearth sciences, ecological sciences, hydrology, earthquake engineering,\n biomedical sciences, and others. He is PI of the OpenTopography project;\ncoordinator of the Data Discovery, Mining, and Access community group for\nthe NSF EarthCube project; and Chair, Coordinating Committee for Big Data\nBenchmarking. Before joining SDSC 16 years ago, Baru led one of the\ndevelopment teams at IBM for DB2 Parallel Edition (a shared-nothing\ndatabase engine). Prior to that, he was on the faculty of the EECS Dept,\nUniversity of Michigan. Baru has a B.Tech. in Electronics Engineering from\nIIT Madras, and an ME and PhD in Electrical Engineering from the\nUniversity of Florida, Gainesville.\n             </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Nov. 2, 2012</div></td><td><div class=\"eventInfor\">SPEAKER: </div><div class=\"eventInfor\">No Seminar</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99196\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99196\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Nov. 2, 2012 3 pm</td></tr><tr><td><b>Location</b></td><td></td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td></td></tr><tr><td><b>Title</b></td><td>No Seminar</td></tr><tr><td><b>Abstract</b></td><td>\n\t\t\tNo ISG seminar.  Leaving this time free so that ISG affiliates can attend today's ICS Trends in Society and Information Technology talk (see www.ics.uci.edu/trends).             </td></tr><tr><td><b>Speaker Bio</b></td><td>\n             </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Oct. 26, 2012</div></td><td><div class=\"eventInfor\">SPEAKER: Yingyi Bu (ISG PhD student)</div><div class=\"eventInfor\">Pregelix: Think Like a Vertex, Scale like Spandex</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99195\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99195\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Oct. 26, 2012 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Yingyi Bu (ISG PhD student)</td></tr><tr><td><b>Title</b></td><td>Pregelix: Think Like a Vertex, Scale like Spandex</td></tr><tr><td><b>Abstract</b></td><td>\nRecently, there are more and more demands for analyzing Big Graph Data.  For example,  the scale of the world wide web keeps expanding to billions of web pages and hyper-links, the key social network sites like Facebook, LinkedIn, Twitter all have a rapidly growing gigantic social graph, and the biology science people assemble genomes from huge de Bruijn graphs.  To analyze such Big graphs requires a system which can not only scale out to hundreds or thousands of machines, but also do the computation very efficiently.  In this talk, I will introduce the Pregelix system,  which supports easy programming and scales to large commodity machine clusters. I will first illustrate the programming model -- application programmers need zero knowledge of the parallel/distributed system,  but just \"think like a vertex\" and write a couple of functions that encapsulate the logic for what one graph vertex does.  After that, I will detail the shining internals of Pregelix,  including the system architecture,  the scalable dataflow runtime,  the execution strategies, and the out-of-core support.  Then,  I will walk through a few examples built on top of Pregelix, such as PageRank and connected components.  Finally I will demonstrate our performance numbers and conclude the talk. (Truth in lending disclosure: the programming model and API were shamelessly borrowed from Google's Pregel graph analytics platform, hence the name:-))\n             </td></tr><tr><td><b>Speaker Bio</b></td><td>\n Yingyi Bu is a PhD student in the ISG group of UC Irvine.  He is working on the ASTERIX project that aims at an open source data-intensive computing platform, with new technologies for ingesting, storing, managing, indexing, querying, analyzing, and subscribing intensive semi-structured data.  Within the project, Yingyi has been working on the data-model independent algebra/optimization layer,  the ASTERIX query optimizer, and the Pregelix system.\n             </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Oct. 19, 2012</div></td><td><div class=\"eventInfor\">SPEAKER: David Lomet (Microsoft Research)</div><div class=\"eventInfor\">The Bw-Tree: A B-tree for New Hardware Platforms</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99194\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99194\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Oct. 19, 2012 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>David Lomet (Microsoft Research)</td></tr><tr><td><b>Title</b></td><td>The Bw-Tree: A B-tree for New Hardware Platforms</td></tr><tr><td><b>Abstract</b></td><td>The emergence of new hardware and platforms has led to reconsideration of how data management \n            \tsystems are designed. However, certain basic functions such as key indexed access to records remain essential. \n            \tWhile we exploit the common architectural layering of prior systems, we make radically new design decisions about each layer. \n            \tOur new form of B-tree, called the Bw-tree achieves its very high performance via a latch-free approach that effectively \n            \texploits the processor caches of modern multi-core chips. Our storage manager uses a unique form of log structuring that \n            \tblurs the distinction between a page and a record store and works well with flash storage. This paper describes the architecture \n            \tand algorithms for the Bw-tree, focusing on the main memory aspects. The paper includes results of our experiments that demonstrate that this fresh approach produces outstanding performance.\n            </td></tr><tr><td><b>Speaker Bio</b></td><td>\n            \tDavid Lomet has been a principal researcher managing the Microsoft Research Database Group at Microsoft Research since 1995. Earlier, he spent seven and a half years at Digital Equipment Corporation. He has been at IBM Research in Yorktown and a Professor at Wang Institute. Dr. Lomet spent a sabbatical at University of Newcastle-upon-Tyne working with Brian Randell. He has a Computer Science Ph.D from the University of Pennsylvania.\nDr. Lomet has done research and product development in architecture, programming languages, and distributed systems. His primary interest is database systems, focusing on access methods, concurrency control, and recovery. He is one of the inventors of the transaction concept and is an author of over 100 papers and 45 patents. Two papers won SIGMOD \"best paper\" awards. He received the 2010 SIGMOD Contributions Award for his work as editor-in-chief of the Data Engineering Bulletin since 1992.\nDr. Lomet has served on program committees, including SIGMOD, PODS, VLDB, and ICDE. He was ICDE'2000 PC co-chair and VLDB 2006 PC core chair. He is a member of the ICDE Steering Committee and VLDB Board. He is a past editor of ACM TODS and the VLDB Journal. Dr. Lomet is IEEE Golden Core Member and has received IEEE Outstanding Contribution and Meritorious Service Awards. Dr. Lomet is a Fellow of the ACM, IEEE, and AAAS.\n            </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Oct. 5, 2012</div></td><td><div class=\"eventInfor\">SPEAKER: Thomas Bodner (TU Berlin)</div><div class=\"eventInfor\">A Taxonomy of Platforms for Analytics on Big Data (Stratosphere talk series 5)</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99193\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99193\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Oct. 5, 2012 4:30 pm - 5pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Thomas Bodner (TU Berlin)</td></tr><tr><td><b>Title</b></td><td>A Taxonomy of Platforms for Analytics on Big Data (Stratosphere talk series 5)</td></tr><tr><td><b>Abstract</b></td><td>\nWithin the past few years, industrial and academic organizations designed a wealth of systems for data-intensive analytics including MapReduce, SCOPE/Dryad, ASTERIX, Stratosphere, Spark, and many others. These systems are being applied to new applications from diverse domains other than (traditional) relational OLAP, making it difficult to understand the tradeoffs between them and the workloads for which they were built. We present a taxonomy of existing system stacks based on their architectural components and the design choices made related to data processing and programmability to sort this space. We further demonstrate a web repository for sharing Big Data analytics platform information and use cases. The repository enables researchers and practitioners to store and retrieve data and queries for their use case, and to easily reproduce experiments from others on different platforms, simplifying comparisons.\n             </td></tr><tr><td><b>Speaker Bio</b></td><td>\nThomas Bodner is a second year Master's student in the computer science department at the Technische Universit\u00e4t Berlin working in the Database Systems and Information Management (DIMA) group on the Stratosphere project. He received his B.S. from the University of Cooperative Education at Stuttgart. In the course of his studies, Thomas Bodner studied abroad at University of California, Irvine and Royal Melbourne Institute of Technology. He worked as an intern at the IBM Almaden Research Center and the IBM B\u00f6blingen Laboratory. His research interests include benchmarking of and query optimization for Big Data analytics systems.\n             </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Oct. 5, 2012</div></td><td><div class=\"eventInfor\">SPEAKER: Alexander Alexandrov</div><div class=\"eventInfor\">Generating a Myriad of Atoms in the Blink of an Eye (Stratosphere talk series 4)</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99192\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99192\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Oct. 5, 2012 4 pm - 4:30pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Alexander Alexandrov</td></tr><tr><td><b>Title</b></td><td>Generating a Myriad of Atoms in the Blink of an Eye (Stratosphere talk series 4)</td></tr><tr><td><b>Abstract</b></td><td>\n Data from real-world applications is regarded as the golden standard for database systems evaluation. Unfortunately, finding appropriate real-world datasets is often hard due to various privacy-related constraints. To overcome this problem, we developed the Myriad Parallel Data Generator Toolkit - a generic toolkit for declarative specification of synthetic data generators that provides built-in parallelization support for the specified data generation programs. In this talk, I will motivate and present the main technical challenges solved by the highly-parallel execution model of the Myriad Toolkit. In addition, to demonstrate the usability of the toolkit, I will also give a brief overview of the supported data generator specification syntax and explain how different statistical constraints for the generated data can be implemented using the appropriate combination of specification routines.\n             </td></tr><tr><td><b>Speaker Bio</b></td><td>\nAlexander Alexandrov is a research associate at the Database Systems and Information Management research group at the Technische Universit\u00e4t Berlin. Before moving to Berlin for a Master in Computer Science at TU Berlin, he received his Bachelor of Science in Software and Internet Technologies at the University of Mannheim. Alexander has been working on the Stratosphere project both as student and research assistant since 2009. His research interests include data generation, evaluation, and query optimization for large-scale parallel batch processing systems with partial operator semantics.\n             </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Oct. 5, 2012</div></td><td><div class=\"eventInfor\">SPEAKER: Stephan Ewen (TU Berlin)</div><div class=\"eventInfor\">Spinning Fast Iterative Data Flows (Stratosphere talk series 3)</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99191\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99191\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Oct. 5, 2012 3:30 pm - 4pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Stephan Ewen (TU Berlin)</td></tr><tr><td><b>Title</b></td><td>Spinning Fast Iterative Data Flows (Stratosphere talk series 3)</td></tr><tr><td><b>Abstract</b></td><td>\n Parallel data flow systems are a central part of most analytic pipelines for big data. The iterative nature of many analysis and machine learning algorithms, however, is still a challenge for current systems. While certain types of bulk iterative algorithms are supported by novel data flow frameworks, these systems cannot exploit computational dependencies present in many algorithms, such as graph algorithms. As a result, these algorithms are inefficiently executed and have led to specialized systems based on other paradigms, such as message passing or shared memory. We propose a method to integrate \"incremental iterations\", a form of workset iterations, with parallel data flows. After showing how to integrate bulk iterations into a dataflow system and its optimizer, we present an extension to the programming model for incremental iterations. The extension alleviates for the lack of mutable state in dataflows and allows for exploiting the \"sparse computational dependencies\" inherent in many iterative algorithms. The evaluation of a prototypical implementation shows that those aspects lead to up to two orders of magnitude speedup in algorithm runtime, when exploited. In our experiments, the improved dataflow system is highly competitive with specialized systems while maintaining a transparent and unified data flow abstraction.\n             </td></tr><tr><td><b>Speaker Bio</b></td><td>\nStephan Ewen is a research associate at the department for Database Systems and Information Management (DIMA) at the Technische Universit\u00e4t Berlin. He is working on the Stratosphere Project that aims at creating a versatile and efficient analytics engine for deep analysis of Big Data on cloud platforms. Within the project, Stephan works on the system's data flow programming abstraction, the data flow optimization and the parallel runtime system. Prior to joining the DIMA group, Stephan completed the \"Applied Computer Science\" program at the University of Cooperative Education Stuttgart jointly with IBM Germany and got his Diploma from the University of Stuttgart. In the course of his studies, Stephan Ewen worked, among others, for the IBM Almaden Research Centre and the IBM Development Laboratory B\u00f6blingen.\n             </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Oct. 5, 2012</div></td><td><div class=\"eventInfor\">SPEAKER: Kostas Tzoumas (TU Berlin)</div><div class=\"eventInfor\">Query Optimization with MapReduce Functions (Stratosphere talk series 2)</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99190\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99190\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Oct. 5, 2012 3 pm - 3:30 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Kostas Tzoumas (TU Berlin)</td></tr><tr><td><b>Title</b></td><td>Query Optimization with MapReduce Functions (Stratosphere talk series 2)</td></tr><tr><td><b>Abstract</b></td><td>\nMany systems for big data analytics employ a data flow programming abstraction to define parallel data processing tasks. In this setting, custom operations expressed as user-defined functions are very common. We address the problem of performing data flow optimization at this level of abstraction, where the semantics of operators are not known. Traditionally, query optimization is applied to queries with known algebraic semantics. In this work, we find that a handful of properties, rather than a full algebraic specification, suffice to establish reordering conditions for data processing operators. We show that these properties can be accurately estimated for black box operators using a shallow static code analysis pass based on reverse data and control flow analysis over the general-purpose code of their user-defined functions. We design and implement an optimizer for parallel data flows that does not assume knowledge of semantics or algebraic properties of operators. Our evaluation confirms that the optimizer can apply common rewritings such as selection reordering, bushy join order enumeration, and limited forms of aggregation push-down, hence yielding similar rewriting power as modern relational DBMS optimizers. Moreover, it can optimize the operator order of non-relational data flows, a unique feature among today's systems.\n             </td></tr><tr><td><b>Speaker Bio</b></td><td>\n Kostas Tzoumas is a postdoctoral researcher co-leading the Stratosphere research project at the Technische Universit\u00e4t Berlin. He received his PhD from Aalborg University in 2011 with a thesis on discovering and exploiting correlations for query optimization. He was a visiting researcher at the University of Maryland, College Park, and an intern at Microsoft Research. He received a Diploma in Electrical and Computer Engineering from the National Technical University of Athens in 2007. His research interests are centered around systems for data analytics, including query processing and optimization in massively parallel environments.\n             </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Oct. 5, 2012</div></td><td><div class=\"eventInfor\">SPEAKER: Volker Markl (TU Berlin)</div><div class=\"eventInfor\">The Current State of the Stratosphere (Stratosphere talk series 1)</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99189\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99189\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Oct. 5, 2012 3 pm - 5pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Volker Markl (TU Berlin)</td></tr><tr><td><b>Title</b></td><td>The Current State of the Stratosphere (Stratosphere talk series 1)</td></tr><tr><td><b>Abstract</b></td><td>\n            Introduction to the Stratosphere system.\n\t\t\t</td></tr><tr><td><b>Speaker Bio</b></td><td>\n            Volker Markl is a Full Professor and Chair of the Database Systems and Information Management (DIMA) group at the Technische Universit\u00e4t Berlin (TU-Berlin). Prior to joining TU-Berlin, Dr. Markl lead a research group at FORWISS, the Bavarian Research Center for Knowledge-based Systems in Munich, Germany, and was a Research Staff member and Project Leader at the IBM Almaden Research Center in San Jose, California, USA. His research interests include: information as a service, new hardware architectures for information management, information integration, autonomic computing, query processing, query optimization, data warehousing, electronic commerce, and pervasive computing. Volker has presented over 100 invited talks in numerous industrial settings and at major conferences and research institutions worldwide. He has authored and published more than 50 research papers at world-class scientific venues. Volker regularly serves as member and chair for program committees of major international database conferences. He also is a member of the Board of Trustees of the VLDB Endowment. Volker has 5 patent awards, and he has submitted over 20 invention disclosures to date. Over the course of his career, he has garnered many prestigious awards, including the European Information Society and Technology Prize, an IBM Outstanding Technological Achievement Award, an IBM Shared University Research Grant, an HP Open Innovation Award, and the Pat Goldberg Memorial Best Paper Award.\n            </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Jun. 8, 2012</div></td><td><div class=\"eventInfor\">SPEAKER:  Kerim Yasin Oktay and Bijit Hore (ISG)</div><div class=\"eventInfor\">CloudProtecti and Risk-Aware Workload Distribution in Hybrid Clouds</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99162\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99162\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Jun. 8, 2012 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td> Kerim Yasin Oktay and Bijit Hore (ISG)</td></tr><tr><td><b>Title</b></td><td>CloudProtecti and Risk-Aware Workload Distribution in Hybrid Clouds</td></tr><tr><td><b>Abstract</b></td><td>\n            In this talk, we describe the CloudProtect system from the recently accepted paper in IEEE Cloud 2012. The CloudProtect middleware empowers users to encrypt sensitive data stored within various cloud applications. However, most web applications require data in plaintext for implementing the various functionalities and in general, do not support encrypted data management. Therefore, CloudProtect strives to carry out the data transformations (encryption/decryption) in a manner that is transparent to the application, i.e., preserves all functionalities of the application, including those that require data to be in plaintext. Additionally, CloudProtect allows users flexibility in trading off performance for security in order to let them optimally balance their privacy needs and usage-experience.\n            This paper explores an efficient and secure mechanism\n            to partition computations across public and private\n            machines in a hybrid cloud setting. We propose a principled\n            framework for distributing data and processing in a hybrid\n            cloud that meets the conflicting goals of performance, sensitive\n            data disclosure risk and resource allocation costs. The proposed\n            solution is implemented as an add-on tool for a Hadoop and\n            Hive based cloud computing infrastructure. Our experiments\n            demonstrate that the developed mechanism can lead to a\n            major performance gain by exploiting both the hybrid cloud\n            components without violating any pre-determined public cloud\n            usage constraints.\n            </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Jun. 1, 2012</div></td><td><div class=\"eventInfor\">SPEAKER: Ken Slocum (UCSD)</div><div class=\"eventInfor\">Scalable Lineage Capture for DISC</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99161\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99161\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Jun. 1, 2012 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Ken Slocum (UCSD)</td></tr><tr><td><b>Title</b></td><td>Scalable Lineage Capture for DISC</td></tr><tr><td><b>Abstract</b></td><td>\n            \tScale-out data processing architectures enable sophisticated ``big data''\nanalytics, but understanding and debugging multi-step dataflows that ingest\nlarge volumes of data remains a fundamental challenge.  We are building a\nsystem called Newt, a scalable architecture for capturing fine-grain,\nrecord-level provenance from these data-intensive scalable compute (DISC)\nsystems in a generic manner.  Developers leverage a unique API to\ninstrument these systems, actively capturing fine-grain lineage across\nmulti-step, perhaps non-relational, transformations.   We report on our \nexperiences instrumenting Hyracks and Hadoop, and find that Newt's capture \nincurs 16-26% time overheads for the PigMix benchmark and a 14% overhead \non a complex 145-stage de novo genomic assembler.\n            </td></tr><tr><td><b>Speaker Bio</b></td><td>\n            \tKen Yocum is an associate research scientist in the Department of Computer\nScience at UC San Diego where he runs the Synoptic Systems Lab.  \nWhile he once worked on high-speed networking (briefly holding the land-speed record for gigabit TCP), he has since become enamored with the myriad systems challenges of \"big data\" processing and software-defined networks.  He received his Ph.D. from Duke University, and\nhis B.S from Stanford.  When he's not working, he enjoys his children,\ncycling, and going to the race track.\n            </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">May. 29, 2012 (Special Time)</div></td><td><div class=\"eventInfor\">SPEAKER: Murali Mani (University of Michigan, Flint)</div><div class=\"eventInfor\"> Algebraic Manipulation of Encrypted Databases</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99160\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99160\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>May. 29, 2012 (Special Time) 12 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Murali Mani (University of Michigan, Flint)</td></tr><tr><td><b>Title</b></td><td> Algebraic Manipulation of Encrypted Databases</td></tr><tr><td><b>Abstract</b></td><td>\n            \tCan we improve on the work that received the 10 year ACM SIGMOD test of time award? In this talk, we will outline our preliminary approach at doing the entire query processing on the server/cloud, while the client is involved only with encryption, and decryption. Our work is based on Craig Gentry's revolutionary recent work on fully homomorphic encryption (first such scheme was published in 2009). We utilize Craig Gentry's scheme for query processing, while maintaining the algebraic framework that is a key aspect of database systems. There are several avenues for future investigation: exploring physical implementations for algebraic operators beyond what we have investigated; exploring query optimization and utilization of indexes; exploring feasibility of Craig Gentry's fully homomorphic encryption in the context of databases as some aspects of his scheme are very time consuming.\n            </td></tr><tr><td><b>Speaker Bio</b></td><td>\n            \tMurali Mani finished his PhD in Computer Science from UCLA in 2003. Since then, he has worked at WPI, and is currently an assistant professor at University of Michigan, Flint. His areas of interest are database systems, and his significant projects have been on event stream processing, processing of XML streaming data, provenance metadata management, and data modeling using XML schemas. His research on XML stream processing and provenance have been supported by NSF.\n            </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">May. 25, 2012</div></td><td><div class=\"eventInfor\">SPEAKER: Jimmy Lin (Twitter)</div><div class=\"eventInfor\">Flexibility without Anarchy: Analytics Infrastructure at Twitter</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99159\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99159\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>May. 25, 2012 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Jimmy Lin (Twitter)</td></tr><tr><td><b>Title</b></td><td>Flexibility without Anarchy: Analytics Infrastructure at Twitter</td></tr><tr><td><b>Abstract</b></td><td>The data analytics infrastructure at Twitter supports a myriad of technologies: Hadoop, Pig (with Python and JRuby), \n            \tCascading/Scalding, HBase, MySQL, Vertica, and ZooKeeper. Our philosophy is to let developers and data scientists use whatever \n            \ttools they are most comfortable with, while allowing individual components to be weaved together into complex analytic tapestries. \n            \tManaging complex workflows that cross language boundaries (e.g. Java vs. Pig vs. Scala) as well as architectures with significant \n            \timpedance mismatches (e.g., Hadoop vs. Vertica) has been and continues to remain a significant challenge. \n            \tIn this talk, I'll detail some of these issues and our present solutions.\n            </td></tr><tr><td><b>Speaker Bio</b></td><td>\n            \t Jimmy Lin is a visiting scientist at Twitter, currently on leave from the University of Maryland. His current research focuses on scalable algorithms for data analytics, particularly on text and graph data. At Twitter, he works on services designed to surface relevant content for users and the distributed infrastructure that supports mining relevance signals from massive amounts of data.\n            </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">May. 18, 2012</div></td><td><div class=\"eventInfor\">SPEAKER: Raman Grover (ISG Ph.D. student)</div><div class=\"eventInfor\">ASTERIX: Scalable Warehouse-Style Web Data Integration</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99151\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99151\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>May. 18, 2012 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Raman Grover (ISG Ph.D. student)</td></tr><tr><td><b>Title</b></td><td>ASTERIX: Scalable Warehouse-Style Web Data Integration</td></tr><tr><td><b>Abstract</b></td><td>\n            \t\tA growing wealth of digital information is being generated on a\ndaily basis in social networks, blogs, online communities, etc. Organizations\nand researchers in a wide variety of domains recognize\nthat there is tremendous value and insight to be gained by\nwarehousing this emerging data and making it available for querying,\nanalysis, and other purposes. This new breed of \u201cBig Data\u201d\napplications poses challenging requirements against data management\nplatforms in terms of scalability, flexibility, manageability,\nand analysis capabilities. At UC Irvine, we are building a nextgeneration\ndatabase system, called ASTERIX, in response to these\ntrends. We present ongoing work that approaches the following\nquestions: How does data get into the system? What primitives\nshould we provide to better cope with dirty/noisy data? How can\nwe support efficient data analysis on spatial data? Using real examples,\nwe show the capabilities of ASTERIX for ingesting data via\nfeeds, supporting set-similarity predicates for fuzzy matching, and\nanswering spatial aggregation queries.\n            </td></tr><tr><td><b>Speaker Bio</b></td><td>\n            </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">May. 11, 2012</div></td><td><div class=\"eventInfor\">SPEAKER: Inci Cetindil (ISG Ph.D. student)</div><div class=\"eventInfor\">Analysis of Instant Search Query Logs</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99150\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99150\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>May. 11, 2012 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Inci Cetindil (ISG Ph.D. student)</td></tr><tr><td><b>Title</b></td><td>Analysis of Instant Search Query Logs</td></tr><tr><td><b>Abstract</b></td><td>Instant search is a new search paradigm that shows results as\na user types in a query. It has become increasingly popular\nin recent years due to its simplicity and power. In an instant-\nsearch system, every keystroke from a user triggers a new\nrequest to the server. Therefore, its log has a richer content\nthan that of a traditional search system, and previous log\nanalysis research is not applicable to this type of log. In\nthis study, we present the problem of analyzing the query\nlog of an instant-search system. We propose a classification\nscheme for user typing behaviors. We also compare the log\nof an instant-search system and that of a traditional search\nsystem on the same data. The results show that on a people\ndirectory search system, instant search can typically save\n2 seconds per search, reduce the typing effort by showing\nthe results with fewer characters entered, and increase the\nsuccess rate.\n            </td></tr><tr><td><b>Speaker Bio</b></td><td>\n            </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">April. 27, 2012</div></td><td><div class=\"eventInfor\">SPEAKER: Afsin Akdogan (University of Southern California)</div><div class=\"eventInfor\">Voronoi-based Geospatial Query Processing with MapReduce</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99144\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99144\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>April. 27, 2012 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Afsin Akdogan (University of Southern California)</td></tr><tr><td><b>Title</b></td><td>Voronoi-based Geospatial Query Processing with MapReduce</td></tr><tr><td><b>Abstract</b></td><td>\n            \t\tGeospatial queries (GQ) have been used in a wide variety of applications such as decision support systems, profile-based marketing, bioinformatics and GIS. Most of the existing query-answering approaches assume non parallel processing on a single machine although GQs are intrinsically parallelizable. There are some approaches that have been designed for parallel databases and cluster systems; however, these only apply to the systems with limited parallel processing capability, far from that of cloud-based platforms. In this study, I present the problem of parallel geospatial query processing with MapReduce programming model.  Our approach creates a spatial index, Voronoi diagram, for given data points in 2D space and enables efficient processing of GQs. We evaluated the performance of our proposed techniques and correspondingly compared them with their closest related work while varying the number of employed nodes.\n        \t\t</td></tr><tr><td><b>Speaker Bio</b></td><td>Afsin Akdogan received his master\u2019s degree in computer science from Cornell University in 2009. He received a best paper award in IEEE Cloud Computing Technology and Science conference in 2010. He has also interned at Yahoo. He is currently working towards his Ph.D. degree in computer science at the University of Southern California and his research focuses on cloud computing, parallel data processing languages and geo-spatial databases.</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">April. 20, 2012</div></td><td><div class=\"eventInfor\">SPEAKER: Leila Jalali (Ph.D. student in ISG)</div><div class=\"eventInfor\">A Reflective Approach to Synchronization for Consistent Multisimulations</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99143\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99143\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>April. 20, 2012 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Leila Jalali (Ph.D. student in ISG)</td></tr><tr><td><b>Title</b></td><td>A Reflective Approach to Synchronization for Consistent Multisimulations</td></tr><tr><td><b>Abstract</b></td><td>In this talk, I consider the challenge of designing a framework that supports the integration of multiple existing autonomous simulation models into an integrated simulation environment (multisimulation). In particular, I focus on solutions for synchronization problem in multisimulation to orchestrate consistent information flow through multiple simulator: (1) a transaction-based approach to modeling the synchronization problem in multisimulations by mapping it to a problem similar to multidatabase concurrency; we express multisimulation synchronization as a scheduling problem where the goal is to generate \u201ccorrect schedules\u201d for time advancement and data exchange across simulators that meets the dependencies without loss of concurrency, (2) a hybrid scheduling strategy which adapts itself to the \u201cright\u201d level of pessimism/optimism based on the state of the execution and underlying dependencies, and (3) relaxation model for dependencies which guarantee bounded violation of consistency to support higher levels of concurrency. We also develop two key optimizations: (a) efficient checkpointing/rollback techniques, and (b) relaxation model for dependencies which guarantee bounded violation of consistency to support higher levels of concurrency. We evaluate our proposed techniques via a detailed case study from the emergency response domain by integrating three disparate simulators \u2013 a fire simulator (CFAST), an evacuation simulator (Drillsim) and a communication simulator (LTEsim).\n\t\t\t\t\t\t</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">April. 13, 2012 (Special Time\\Place)</div></td><td><div class=\"eventInfor\">SPEAKER: Jennifer Widom (Stanford)</div><div class=\"eventInfor\">Data-Centric Human Computation + From 100 Students to 100,000</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99142\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99142\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>April. 13, 2012 (Special Time\\Place) 11 am</td></tr><tr><td><b>Location</b></td><td>DBH 6011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Jennifer Widom (Stanford)</td></tr><tr><td><b>Title</b></td><td>Data-Centric Human Computation + From 100 Students to 100,000</td></tr><tr><td><b>Abstract</b></td><td>This talk will have two completely independent parts -- one related to research and the other to education.\nIn the first part of the talk, I'll describe our ongoing research in leveraging human computation for tasks related to data. Human computation (\"crowdsourcing\") augments traditional computation with the use of human abilities to solve sub-problems that are difficult for computers, e.g., object or image comparisons, information extraction, relevance judgements, and data gathering. We are addressing two different types of data-centric human computation: (1) Fundamental algorithms, such as sorting, clustering, and data cleaning, in which the basic operations (e.g., compare, filter) are performed by humans. (2) A database-system like platform in which declarative queries are posed by users, and the system orchestrates a combination of stored and crowdsourced data to answer them. Common to both areas is the need to formalize and optimize new tradeoffs among latency (humans are much slower than computers), cost (humans require real money to perform tasks), and quality (humans are inaccurate and inconsistent).\nIn the second part of the talk, I'll describe my recent experience teaching introductory databases to 60,000 students. Admittedly only 25,000 of them submitted their homework, and a mere 6500 achieved a strong final score. But even with 6500 students, I more than quadrupled the total number of students I've taught in my entire 18-year academic career. I began by \"flipping\" the way I teach my Stanford course and, as a side-effect, making all components of the course freely available online. But the big inflection point came when I offered the online course in a structured fashion with a schedule, automatically-graded assignments and exams, and most importantly a worldwide community of students. I'll cover a variety of topics related to the massive online course, both logistical and social, while avoiding speculation on the future of higher education.\n</td></tr><tr><td><b>Speaker Bio</b></td><td>Jennifer Widom is the Fletcher Jones Professor and Chair of the Computer Science Department at Stanford University. She received her Bachelor's degree from the Indiana University School of Music in 1982 and her Computer Science Ph.D. from Cornell University in 1987. She was a Research Staff Member at the IBM Almaden Research Center before joining the Stanford faculty in 1993. Her research interests span many aspects of nontraditional data management. She is an ACM Fellow and a member of the National Academy of Engineering and the American Academy of Arts and Sciences; she received the ACM SIGMOD Edgar F. Codd Innovations Award in 2007 and was a Guggenheim Fellow in 2000; she has served on a variety of program committees, advisory boards, and editorial boards.</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">March. 16, 2012 (Special Time\\Place)</div></td><td><div class=\"eventInfor\">SPEAKER: Cyrus Shahabi (USC)</div><div class=\"eventInfor\">TransDec:\nA Data-Driven Framework for Decision-Making in Transportation Systems</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99128\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99128\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>March. 16, 2012 (Special Time\\Place) 11 am</td></tr><tr><td><b>Location</b></td><td>DBH 6011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Cyrus Shahabi (USC)</td></tr><tr><td><b>Title</b></td><td>TransDec:\nA Data-Driven Framework for Decision-Making in Transportation Systems</td></tr><tr><td><b>Abstract</b></td><td>The vast amounts of transportation datasets (traffic flow, incidents, etc.) collected by various federal and\nstate agencies are extremely valuable in 1) real-time decision-making, planning, and management of the\ntransportation systems, and 2) conducting research to develop new policies to enhance the efficacy of the\ntransportation systems. In this talk, I will present our data-driven framework, dubbed TransDec (short\nfor Transportation Decision-Making), which enables real-time integration, visualization, querying, and\nanalysis of dynamic and archived transportation data. I will show that considering the large size of the\ntransportation data, variety of the data (different modalities and resolutions), and frequent changes of the\ndata, implementation of such a scalable system that allows for effective querying and analysis of both\narchived and real-time data is an intrinsically challenging data management task. Subsequently, I will\nfocus on a route-planning problem where the weights on the road-network edges vary as a function of\ntime due to the variability of traffic congestion. I will show that na\u00efve approaches to address this problem\nare either inaccurate or slow, motivating the need for new solutions. Consequently, I will discuss our\ninitial approach to this problem and demonstrate its implementation within the TransDec framework.</td></tr><tr><td><b>Speaker Bio</b></td><td>Cyrus Shahabi is a Professor and the Director of the Information Laboratory (InfoLAB) at the Computer\nScience Department and also the Director of the NSF's Integrated Media\nSystems Center (IMSC) at the University of Southern California. He is also the\nCTO and co-founder of a USC spin-off, Geosemble Technologies. He\nreceived his B.S. in Computer Engineering from Sharif University of\nTechnology in 1989 and then his M.S. and Ph.D. Degrees in Computer\nScience from the University of Southern California in May 1993 and\nAugust 1996, respectively. He authored two books and more than hundred-\nfifty research papers in the areas of databases, GIS and multimedia. Dr. Shahabi has received funding from several agencies such as NIJ, NSF, NASA, NIH, DARPA, AFRL,\nand DHS as well as several industries such as Google, Microsoft, NCR, NGC, and Chevron. He was an\nAssociate Editor of IEEE Transactions on Parallel and Distributed Systems (TPDS) from 2004 to 2009.\nHe is currently on the editorial board of the VLDB Journal, IEEE Transactions on Knowledge and Data\nEngineering (TKDE), ACM Computers in Entertainment and Journal of Spatial Information Science. He\nis the founding chair of IEEE NetDB workshop and also the general co-chair of ACM GIS 2007, 2008\nand 2009. He chaired the nomination committee of ACM SIGSPATIAL for the 2011-2014 terms. He\nregularly serves on the program committee of major conferences such as VLDB, ACM SIGMOD, IEEE\nICDE, ACM SIGKDD, and ACM Multimedia. Dr. Shahabi is a recipient of the ACM Distinguished\nScientist award in 2009, the 2003 U.S. Presidential Early Career Awards for Scientists and Engineers\n(PECASE), the NSF CAREER award in 2002, and the 2001 Okawa Foundation Research Grant for\nInformation and Telecommunications. He was the recipient of US Vietnam Education Foundation (VEF)\nfaculty fellowship award in 2011, an organizer of the 2011 National Academy of Engineering \u201cJapan-\nAmerica Frontiers of Engineering\u201d program, an invited speaker in the 2010 National Research Council\n(of the National Academies) Committee on New Research Directions for the National Geospatial-\nIntelligence Agency, and a participant in the 2005 National Academy of Engineering \u201cFrontiers of\nEngineering\u201d program.</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">March. 9, 2012</div></td><td><div class=\"eventInfor\">SPEAKER: Nga Dang (Ph.D. student in ISG)</div><div class=\"eventInfor\">QuARES: A Quality-Aware Renewable Energy-driven Sensing Framework</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99127\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99127\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>March. 9, 2012 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Nga Dang (Ph.D. student in ISG)</td></tr><tr><td><b>Title</b></td><td>QuARES: A Quality-Aware Renewable Energy-driven Sensing Framework</td></tr><tr><td><b>Abstract</b></td><td> Mobile devices, such as smartphones and tablets, are getting increasingly popular, and continue to generate record-high amount of mobile data traffic. For example a recent Cisco report indicates that mobile data traffic will increase 39 times by 2015, while 66% of such boost is due to video traffic. Network capacity issue may be partially coped by deploying more cellular base stations, installing dedicated broadcast networks, or upgrading the cellular base stations to support 4G. However, these approaches all result in additional costs on new network infrastructure, and might not be fully compatible with existing\nobile devices. Also, according to the report, the network capacity provided by cellular network providers is predicted to be only 10 time increasing by 2015, which implies that the above methods do not still meet the requirement for increasing mobile traffic. A better way is moving data to other networks to reduce heavy traffic in cellular networks. In our research, we study motivations and methods to offload part of mobile traffic from cellular networks to other networks such as WiFi or Ad Hoc, which are available in most modern smartphones. Such these methods are cheap, practical, and easily implemented.</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">March. 1, 2012 (Special Time\\Place)</div></td><td><div class=\"eventInfor\">SPEAKER: Archan Misra (Singapore Management University) </div><div class=\"eventInfor\">Real-time Mobile Sensing/Analytics and the LiveLabs Experimentation Platform</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99126\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99126\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>March. 1, 2012 (Special Time\\Place) 11 am</td></tr><tr><td><b>Location</b></td><td>DBH 4011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Archan Misra (Singapore Management University) </td></tr><tr><td><b>Title</b></td><td>Real-time Mobile Sensing/Analytics and the LiveLabs Experimentation Platform</td></tr><tr><td><b>Abstract</b></td><td>\n            This talk explores the ongoing transformation of the mobile device into a combined \u201csensing and\nanalytics\u201d platform, distinguished by two key features: a) efficient localized processing of sensor data\nstreams and b) localized coordination and distributed computation among a set of proximal mobile\nnodes. I will first introduce the LiveLabs Experimentation Platform, a unique \u201curban behavioral testbed\u201d\nthat combines innovations in wireless networks, mobile sensing and App deployment to enable an\necosystem of industry partners to test next-generation context-based applications on approx. 30,000 real-\nlife users in urban environments, such as the SMU campus, 2 major shopping malls and a resort theme\npark. I will then describe ongoing research on offline and near-real time energy-efficient, continuous\nsmartphone-based human context estimation or \u201cactivity mining\u201d, with a special focus on how such\nanalytics can utilize proximity-driven social interactions. I will then briefly cover two ongoing projects\nthat exploit such context-sensing to: a) optimize the delivery of mobile advertising and b) perform real-\ntime adaptation of femtocellular indoor networks.\n            </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Feb. 17, 2012</div></td><td><div class=\"eventInfor\">SPEAKER: Russell Sears (Yahoo! Research)</div><div class=\"eventInfor\">A general purpose Log Structured Merge Tree</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99124\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99124\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Feb. 17, 2012 3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Russell Sears (Yahoo! Research)</td></tr><tr><td><b>Title</b></td><td>A general purpose Log Structured Merge Tree</td></tr><tr><td><b>Abstract</b></td><td>\n            Data management workloads are increasingly write-intensive and subject\nto strict latency SLAs.  This presents a dilemma: Traditional update\nin place systems have unmatched latency properties but poor write\nthroughput.  In contrast, existing log structured techniques\nsignificantly improve write throughput but generally sacrifice read\nperformance and exhibit unacceptable latency spikes.\n\nWe begin by presenting a new performance metric: read fanout, and\nargue that, along with read amplification and write amplification, it\nbetter characterizes the real-world performance of index algorithms than\nexisting approaches such as asymptotic analysis and price/performance.\n\nWe then present a Log Structured Merge (LSM) tree implementation that\ncombines the best properties of B-Trees and log structured approaches:\n(1) Unlike existing log structured trees, our implementation has\nnear-optimal read and scan performance, and (2) we present merge\nalgorithms that bound write latencies without impacting write\nthroughput or allowing merges to block application writes for extended\nperiods of time.  We do this by introducing a new ``spring and gear''\nscheduler that ensures merges at each level of the tree make steady\nprogress.  This allows us to avoid blocking application writes without\nresorting to techniques that degrade read performance.\n\nWe use Bloom filters to improve index performance, and find that a\nnumber of subtleties arise.  First, it is important to ensure that\nreads can safely stop after finding the first version of a record.\nOtherwise, frequently written items will incur multiple disk\nlookups.  Second, many applications and data management architectures\ncheck for preexisting values at insertion time.  Avoiding the disk\nseek performed by the check is crucial for such applications.\n\nThis work will appear in Sigmod 2012.\n\t\t\t</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Feb. 10, 2012 (Special Time\\Place)</div></td><td><div class=\"eventInfor\">SPEAKER: Anhai Doan (U.  Wisconsin and Walmart Labs - ex Kosmix)</div><div class=\"eventInfor\">Social Media, Data Integration, and Human Computation</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99122\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99122\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Feb. 10, 2012 (Special Time\\Place) 11 am</td></tr><tr><td><b>Location</b></td><td>DBH 6011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Anhai Doan (U.  Wisconsin and Walmart Labs - ex Kosmix)</td></tr><tr><td><b>Title</b></td><td>Social Media, Data Integration, and Human Computation</td></tr><tr><td><b>Abstract</b></td><td>Social media has emerged as a major frontier on the World-Wide Web, with applications ranging from helping teenagers track Justin Bieber to e-commerce to fostering revolutions. In this talk I will discuss our work in this area, as carried out at Wisconsin, Kosmix, and @WalmartLabs. I describe how we integrate data from 'traditional' Web sources to build a global taxonomy, greatly expand it with social-media data, then leverage it to build consumer-facing applications. Example applications include building topic pages, detecting Twitter events, and monitoring these events. I discuss the critical role of data integration and human computation in processing social media. Finally, I discuss how all of these can help the emerging area of social commerce, and why Walmart recently acquired Kosmix to make inroads into this new and exciting area.</td></tr><tr><td><b>Speaker Bio</b></td><td>AnHai Doan is an Associate Professor at the University of Wisconsin-Madison. His interests cover databases, AI, and Web, with a current focus on data integration, large-scale knowledge bases, social media, crowdsourcing, human computation, and information extraction. He received the ACM Doctoral Dissertation Award in 2003, a CAREER Award in 2004, and a Sloan Fellowship in 2007. AnHai was Chief Scientist of Kosmix, a social media startup acquired by Walmart in 2011. Currently he also works as Chief Scientist of @WalmartLabs, a research and development lab devoted to integrating social and mobile data for e-commerce.</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Feb. 3, 2012 (Special Time\\Place)</div></td><td><div class=\"eventInfor\">SPEAKER: Yannis Papakonstantinou (UCSD)</div><div class=\"eventInfor\">Declarative, optimizable data-driven specifications of web and mobile applications</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99121\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99121\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Feb. 3, 2012 (Special Time\\Place) 11 am</td></tr><tr><td><b>Location</b></td><td>DBH 6011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Yannis Papakonstantinou (UCSD)</td></tr><tr><td><b>Title</b></td><td>Declarative, optimizable data-driven specifications of web and mobile applications</td></tr><tr><td><b>Abstract</b></td><td>Developers of web and mobile application development write too much low level \"plumbing\" code to efficiently access, integrate and coordinate application state that resides on multiple sub-systems of the architecture, and is accessed using different languages: SQL at the database server; HTML and Javascript at the browser, which in HTML5 includes its own database state; Java or other programming languages at the application server.\nThe FORWARD project replaces such low level code with declarative specifications. Its cornerstones are \n(i) the unified application state virtual database, which enables modeling and manipulating the entire application state in an extension of SQL, named SQL++ \n(ii) specification of Ajax pages as essentially rendered views over the unified application state.\nConsequently the following three problems are resolved by appropriate reduction to data management problems, where prior database research literature is leveraged and extended.\n1. The partial change of Ajax pages, in response to application state changes, is reduced to an incremental view maintenance problem. Id's that retain the provenance of the page data play an instrumental efficiency role.\n2. Efficient data access is reduced to semistructured query processing over an integrated view that involves large database(s) and small main memory-based sources.\n3. The inherent location transparency of the specifications is exploited in order to perform computation at the appropriate location (browser vs server). More broadly, the talk discusses ongoing and future work in utilizing the increased abilities of HTML5 clients towards achieving low latency mobile web applications applications, while location transparency of the specifications is retained.</td></tr><tr><td><b>Speaker Bio</b></td><td>\nYannis Papakonstantinou is a Professor of Computer Science and Engineering at the University of California, San Diego. His research is in the intersection of data management technologies and the web, where he has published over eighty research articles. He has given multiple tutorials and invited talks, has served on journal editorial boards and has chaired and participated in program committees for many international conferences and workshops.\nYannis was the CEO and Chief Scientist of Enosys Software, which built and commercialized an early XML-based Enterprise Information Integration platform. Enosys Software was acquired in 2003 by BEA Systems. He was the CEO and is the Chief Scientist of app2you, which has commercialized UCSD R and D on rapid development of web applications for data-driven analytics and business process management. He is the Chief Computer Scientist of a pharmaceutical spin-off startup in the area of data analytics for the pharmaceutical industry. He has been in the technical advisory board of multiple startups, currently including Brightscope Inc.\nYannis holds a Diploma of Electrical Engineering from the National Technical University of Athens, MS and Ph.D. in Computer Science from Stanford University (1997) and an NSF CAREER award for his work on data integration.</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Jan. 27, 2012 </div></td><td><div class=\"eventInfor\">SPEAKER: Kurt Brown (EMC/Greenplum)</div><div class=\"eventInfor\">The Future of Big Data Analytics</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99120\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99120\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Jan. 27, 2012  3 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Kurt Brown (EMC/Greenplum)</td></tr><tr><td><b>Title</b></td><td>The Future of Big Data Analytics</td></tr><tr><td><b>Abstract</b></td><td>\"Big Data\" and analytics have both existed in some form for as long as computing itself, but only now has technology advanced to the point that, together, they are starting to qualitatively change the way organizations and individuals perceive, understand, and predict the world around them.  In this talk, I'll set Big Data Analytics in a historical context to help sort out what aspects of current technologies (hardware, software, and programming models) are simply transient artifacts or long-term trends, and to project where Big Data Analytics is possibly headed (from the perspective of Greenplum and EMC).</td></tr><tr><td><b>Speaker Bio</b></td><td>Kurt Brown is currently Director of Advanced R and D at Greenplum/EMC.  \n            \tPrior to EMC, he co-directed Intel's Berkeley Research Lab, spent 13 years with IBM in operating systems \n            \tand database R and D on the East and West coasts, and co-founded three startups in database middleware, \n            \tsmall business marketing services, and residential energy management.  \n            \tHe received his PhD in 1995 from the University of Wisconsin for work in automated database performance  tuning.\n            </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Jan. 13, 2011</div></td><td><div class=\"eventInfor\">SPEAKER: Thomas Bodner</div><div class=\"eventInfor\">The Stratosphere Parallel Analysis Framework, Present and Future</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99115\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99115\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Jan. 13, 2011 3:00 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Thomas Bodner</td></tr><tr><td><b>Title</b></td><td>The Stratosphere Parallel Analysis Framework, Present and Future</td></tr><tr><td><b>Abstract</b></td><td>Data-intensive computing is a much investigated topic in current research. \n            \tNext to parallel databases, new flavors of data processors have established themselves - most prominently the MapReduce programming and execution model. \n            \tThe new systems provide key features that current parallel databases lack, such as flexibility in the data models, the ability to \n            \tparallelize custom functions, and fault tolerance that enables them to scale out to thousands of machines. \n            \tThis talk presents the current state of Stratosphere system, a cloud data and query processor that has been released as open-source in spring 2011. \n            \tThe system consists of the parallel data programming model PACT, an extension of the MapReduce programming model for the specification of complex data-intensive tasks in the cloud, \n            \tand the elastic, massively parallel execution engine Nephele, a Dryad-like parallel data processor. Furthermore, I give a demo of the most recent Stratosphere release. \n            \tAnd finally, I report on future enhancements for Stratosphere, particularly, for the compilation, optimization and parallel execution of data-intensive operations in the system.\n</td></tr><tr><td><b>Speaker Bio</b></td><td>  Since October 2010, Thomas Bodner is a Master's student at the department for Database Systems and Information Management (DIMA) at the Technical University of Berlin. \n        \tBetween 2007 and 2010, Thomas Bodner completed the Applied Computer Science program at the University of Cooperative Education, Stuttgart, jointly with IBM Germany as partner. \n        \tIn the course of his undergraduate studies, he studied abroad for one semester at the Royal Melbourne Institute of Technology, Australia and worked as an intern at the IBM Almaden Research Center, \n        \tCalifornia, USA and the IBM B\u00f6blingen Laboratory in Germany, exploring query optimization and in-memory technologies for database management systems. His research interests include architectures \n        \tfor information management, query processing and optimization, benchmarking and machine learning.\n        </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Dec. 9, 2011 (Special Time\\Place)</div></td><td><div class=\"eventInfor\">SPEAKER: Pat Helland (Microsoft)</div><div class=\"eventInfor\">If You Have Too Much Data, then \"Good Enough\" Is Good Enough</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99114\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99114\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Dec. 9, 2011 (Special Time\\Place) 11 am</td></tr><tr><td><b>Location</b></td><td>DBH 6011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Pat Helland (Microsoft)</td></tr><tr><td><b>Title</b></td><td>If You Have Too Much Data, then \"Good Enough\" Is Good Enough</td></tr><tr><td><b>Abstract</b></td><td>Classic database systems offer crisp answers for a relatively small amount of data. These systems hold their data in one or a relatively small number of computers. With a tightly defined schema and transactional consistency, the results returned from queries are crisp and accurate.\nNew systems have humongous amounts of data content, change rates, and querying rates and take lots of computers to hold and process. The data quality and meaning are fuzzy. The schema, if present, is likely to vary across the data. The origin of the data may be suspect, and its staleness may vary.\nToday's data systems coalesce data from many sources. The Internet, B2B, and enterprise application integration (EAI) combine data from different places. No computer is an island. This large amount of interconnectivity and interdependency has led to a relaxation of many database principles. \nIn this talk, consider the some of the ways in which today's answers differ from what we used to expect.\n\t\t\t\t\t</td></tr><tr><td><b>Speaker Bio</b></td><td>\n\t\t\t\t\t\tPat Helland has been working in distributed systems, transaction processing, databases, and similar areas since 1978. \n\t\t\t\t\t\tFor most of the 1980s, he was the chief architect of Tandem Computers' TMF (Transaction Monitoring Facility), which provided distributed transactions for the NonStop System. \n\t\t\t\t\t\tWith the exception of a two-year stint at Amazon, Helland has worked at Microsoft Corporation since 1994 where he was the architect for Microsoft Transaction Server and SQL Service Broker. \n\t\t\t\t\t\tUntil September, 2011, he was working on Cosmos, a distributed computation and storage system that provides back-end support for Bing.  \n\t\t\t\t\t\tPat recently relocated to San Francisco with his wife to be close to the grandchildren and to explore new opportunities in \"Big Data\" and/or \"Cloud Computing\".\n\t\t\t\t\t</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Nov. 18, 2011</div></td><td><div class=\"eventInfor\">SPEAKER: Yi Pan and Masood Mortazavi (Yahoo!)</div><div class=\"eventInfor\">Scalability and Programming Model in Serving Storage Systems</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99111\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99111\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Nov. 18, 2011 3pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Yi Pan and Masood Mortazavi (Yahoo!)</td></tr><tr><td><b>Title</b></td><td>Scalability and Programming Model in Serving Storage Systems</td></tr><tr><td><b>Abstract</b></td><td>We will review some of the storage technologies Yahoo applications use in Yahoo's cloud platform. These serving storage systems can scale to extremely large numbers of records. After discussing overall architecture of these scalable storage systems, we will focus on Sherpa (PNUTS). Sherpa is a multi-tenant, distributed, highly elastic key-value store with a well-defined transaction semantics that serves data for 100s of Yahoo applications. To exemplify the type of scalability challenges we face, we will describe how we're evolving Sherpa along various dimensions. We will then focus on the programmability dimension and explain how we have implemented a highly scalable, eventually consistent indexing system for Sherpa. Design decisions we have made to balance concerns related to consistency and availability will be discussed, \n            \tand we hope to elucidate the basic questions that come up, repeatedly, when evolving such massively scalable systems while they are in operation.</td></tr><tr><td><b>Speaker Bio</b></td><td>Dr. Masood Mortazavi works as a senior principal architect at Yahoo's serving storage systems group. His interests include distributed systems, scalability, multi-tenancy and cloud serving systems. Masood has also worked for Huawei Technologies, Sun Microsystems, Tecknowledge and Hughes Aircrafts.  Masood's LinkedIn profile can be found here: http://www.linkedin.com/in/mortazavi . . . At Yahoo, he helps advance cloud platform and storage technologies.\n\t\t\t\t\t\tDr. Yi Pan graduated with a Ph.D. degree in computer science from University of California at Irvine. He got his B.S. and M.S. Degree from Fudan University in Shanghai, China. His main interests expand across many areas in large scale distributed computer networks and applications.  Currently, he works as a principal software engineer in Yahoo!\u2019s Cloud Platform Group. His main goal is to push forward Yahoo!\u2019s state-of-art cloud storage systems with innovative features.</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Nov. 4, 2011</div></td><td><div class=\"eventInfor\">SPEAKER: Thomas Bodner</div><div class=\"eventInfor\">Myriad - Parallel Data Generation on Shared-Nothing Architectures</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99110\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99110\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Nov. 4, 2011 3:30 pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Thomas Bodner</td></tr><tr><td><b>Title</b></td><td>Myriad - Parallel Data Generation on Shared-Nothing Architectures</td></tr><tr><td><b>Abstract</b></td><td>\nThe need for efficient data generation for the purposes of testing and benchmarking newly developed data-intensive computing systems has increased with the emergence of\nbig data problems. As synthetic data model specifications evolve over time the data generator programs implementing these models have to be continuously adapted \u2013\n a task that might become complex as the set of model constraints grows. This talk presents Myriad - a new parallel data generation toolkit. Data generators created\n  with the toolkit can produce very large datasets by exploiting a completely parallel execution model, while at the same time maintain cross-partition dependencies, correlations and distributions in the generated data. \nIn addition, I report on our efforts towards a benchmark suite for large-scale parallel analysis systems that uses Myriad for the generation of large social network graphs and OLAP-style relational datasets.\n\t\t\t\t\t\t</td></tr><tr><td><b>Speaker Bio</b></td><td>  Since October 2010, Thomas Bodner is a Master's student at the department for Database Systems and Information Management (DIMA) at the Technical University of Berlin. \n        \tBetween 2007 and 2010, Thomas Bodner completed the Applied Computer Science program at the University of Cooperative Education, Stuttgart, jointly with IBM Germany as partner. \n        \tIn the course of his undergraduate studies, he studied abroad for one semester at the Royal Melbourne Institute of Technology, Australia and worked as an intern at the IBM Almaden Research Center, \n        \tCalifornia, USA and the IBM B\u00f6blingen Laboratory in Germany, exploring query optimization and in-memory technologies for database management systems. His research interests include architectures \n        \tfor information management, query processing and optimization, benchmarking and machine learning.\n        </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Oct. 21, 2011</div></td><td><div class=\"eventInfor\">SPEAKER: David Lomet (Microsoft Research)</div><div class=\"eventInfor\">Deuteronomy: Transaction Support for Cloud Data</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99109\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99109\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Oct. 21, 2011 3pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>David Lomet (Microsoft Research)</td></tr><tr><td><b>Title</b></td><td>Deuteronomy: Transaction Support for Cloud Data</td></tr><tr><td><b>Abstract</b></td><td>The Deuteronomy system supports efficient and scalable ACID transactions in the cloud by decomposing the storage engine\n            \t into: (a) a transactional component (TC) that manages transactions and their ``logical\" concurrency control and undo/redo recovery, \n            \t and (b) a data component (DC) that knows about the access methods and supports a record-oriented interface with atomic operations, \n            \t but knows nothing about transactions.  The Deuteronomy TC can be applied to data anywhere, in the cloud, local, etc. with a variety \n            \t of deployments for both the TC and DC components.  In this talk, we first describe the architecture of our TC, and the considerations \n            \t that led to it.  We next describe the contract between TC and DC, how we changed the operation protocol to simplify it and make it more efficient.   \n            \t We have implemented both TC and multiple DCs, and will describe our TC implementation in detail.  \n            \t We will end a few words about observed performance and scalability.</td></tr><tr><td><b>Speaker Bio</b></td><td>\n            \tDavid Lomet is a principal researcher managing the Microsoft Research Database Group.  Earlier, he worked at Digital, IBM Research, and Wang Institute.  \n            \tHe has a CS Ph.D from the University of Pennsylvania.  He is author of over 100 papers (two SIGMOD \"best papers\") and has 45 patents.  \n            \tHe has served on program committees (SIGMOD, PODS, VLDB, ICDE...), was ICDE'2000 PC co-chair, VLDB'2006 PC core chair, and is on the ICDE Steering Committee, \n            \tthe VLDB Board, is TCDE Chair and has been an editor for TODS, VLDBJ, and JDPD. He is the Data Engineering Bulletin EIC, for which he received the SIGMOD Contributions Award.  \n            \tHe received IEEE Golden Core, Outstanding, and Meritorious Service Awards and is a Fellow of IEEE, ACM, and AAAS.\n            </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Oct. 21, 2011 (Special Time\\Place)</div></td><td><div class=\"eventInfor\">SPEAKER: Danny Sullivan (Editor In Chief, Search Engine Land)</div><div class=\"eventInfor\">From Search 1.0 to Search 4.0</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99108\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99108\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Oct. 21, 2011 (Special Time\\Place) 11am</td></tr><tr><td><b>Location</b></td><td>DBH 6011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Danny Sullivan (Editor In Chief, Search Engine Land)</td></tr><tr><td><b>Title</b></td><td>From Search 1.0 to Search 4.0</td></tr><tr><td><b>Abstract</b></td><td>When search engines first began, they focused on crawling web pages\nand \"words on the page\" ranking analysis. That system quickly failed,\nbeing far too easy to game. Search 2.0 gave us ranking where links\nwere used as votes; Search 3.0, a third generational system,\nintroduced blending vertical search results with web matches.\nCurrently underway, the fourth generational trend of Search 4.0 taps\ninto human signals, from social networks and personalization, to\nrefine search results. The \"how and why\" of this evolution has\nunfolded.</td></tr><tr><td><b>Speaker Bio</b></td><td>Widely considered a leading \"search engine guru,\" Danny Sullivan has\nbeen helping webmasters, marketers and everyday web users understand\nhow search engines work for over a decade. Danny's expertise about\nsearch engines is often sought by the media, and he has been quoted in\nplaces like The Wall St. Journal, USA Today, The Los Angeles Times,\nForbes, The New Yorker and Newsweek and ABC's Nightline. Danny began\ncovering search engines in late 1995, when he undertook a study of how\nthey indexed web pages. The results were published online as \"A\nWebmaster's Guide To Search Engines,\" a pioneering effort to answer\nthe many questions site designers and Internet publicists had about\nsearch engines. Danny currently heads up Search Engine Land as\neditor-in-chief, which covers all aspects of search marketing and\nsearch engine news. Danny also serves as Third Door Media's chief\ncontent officer, which owns Search Engine Land and the SMX: Search\nMarketing Expo conference series. Danny also maintains a personal blog\ncalled Daggle and microblogs on Twitter: @dannysullivan.</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Oct. 14, 2011</div></td><td><div class=\"eventInfor\">SPEAKER: Tyson Condie (Yahoo! Research)</div><div class=\"eventInfor\">Scal(a)ing up Machine Learning and Graph-based Analytics</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99107\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99107\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Oct. 14, 2011 3pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Tyson Condie (Yahoo! Research)</td></tr><tr><td><b>Title</b></td><td>Scal(a)ing up Machine Learning and Graph-based Analytics</td></tr><tr><td><b>Abstract</b></td><td>\nMachine learning practitioners are increasingly interested in applying their algorithms to Big Data. Unfortunately, current high-level \nlanguages for data analytics (e.g., Hive, Pig, Sawzall, Scope) do not fully cover this domain. One key missing ingredient is the means to \nefficiently support iteration over the data. Zaharia et al., were the first to answer this call from a systems perspective with Spark. \nSpark adds the notion of a working set to data-parallel workflows and has published speed-ups of 30x over Hadoop MapReduce for many machine learning and graph algorithms.\n\nUnfortunately, Spark does cover the whole pipeline of Big Data analytics; at Yahoo!, it is common to compose Pig, MPI and direct MapReduce program modules into workflows. \nThis fractioning of individual processing steps can be a major pain e.g., for optimization, debugging, and code readability. Our prescription to this dilemma is a new DSL \nfor data analytics called ScalOps. Like Pig, ScalOps combines the declarative style of SQL and the low-level procedural style of MapReduce. Like Spark, ScalOps can optimize \nits runtime\u2014the Hyracks parallel-database engine\u2014for repeated access to data collections. ScalOps is part of a broader research agenda to explore new abstractions\n for machine learning and graph-based analytics. In this talk, I will present example workflows from the machine learning domain expressed in ScalOps and their translation to Hyracks recursive query plans. </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Sept. 30, 2011</div></td><td><div class=\"eventInfor\">SPEAKER: Grad. students</div><div class=\"eventInfor\">System Demo</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99106\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99106\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Sept. 30, 2011 3pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Grad. students</td></tr><tr><td><b>Title</b></td><td>System Demo</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Sept. 23, 2011</div></td><td><div class=\"eventInfor\">SPEAKER: ISG memebers</div><div class=\"eventInfor\">ISG Gathering</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99105\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99105\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Sept. 23, 2011 3pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>ISG memebers</td></tr><tr><td><b>Title</b></td><td>ISG Gathering</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">June 3, 2011</div></td><td><div class=\"eventInfor\">SPEAKER: Donald Kossman</div><div class=\"eventInfor\">Predictable Performance for Unpredictable Workloads</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99104\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99104\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>June 3, 2011 2pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Donald Kossman</td></tr><tr><td><b>Title</b></td><td>Predictable Performance for Unpredictable Workloads</td></tr><tr><td><b>Abstract</b></td><td>This talk presents the design of SwissBox. \n            \tSwissBox is a database appliance designed to process thousands of concurrent queries and updates with bounded \n            \tquery response times and strict data freshness guarantees. The system was designed to aggressively share operations \n            \tbetween concurrent queries and updates. This talk shows the design of the storage manager (called Crescando)\n            \t and the design of the query processor (called SharedDB). Furthermore, the talk presents the results of \n            \t performance experiments with workloads from an airline reservation system.</td></tr><tr><td><b>Speaker Bio</b></td><td>Donald Kossmann is a professor for Computer Science at ETH Zurich (Switzerland). He received his MS from the University of Karlsruhe and completed his PhD at the University of Aachen. After that, he held positions at the University of Maryland, the IBM Almaden Research Center, the University of Passau, the University of Munich, and the University of Heidelberg. He is an ACM fellow, member of the board of trustees of the VLDB endowment, and was the program committee chair of the ACM SIGMOD Conf., 2009. He is a co-founder of i-TV-T (1998), XQRL Inc. \n            \t(acquired by BEA in 2002), and 28msec Inc. (2007). \n            \tHis research interests lie in the area of databases and information systems.</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">May 20, 2011</div></td><td><div class=\"eventInfor\">SPEAKER: Ronen Vaisenberg</div><div class=\"eventInfor\">Scheduling and Actuating Camera Networks to Maximize Event Detection</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99103\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99103\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>May 20, 2011 2pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Ronen Vaisenberg</td></tr><tr><td><b>Title</b></td><td>Scheduling and Actuating Camera Networks to Maximize Event Detection</td></tr><tr><td><b>Abstract</b></td><td>A distributed camera network allows for many compelling applications, such as large-scale tracking, face recognition, occupancy monitoring or event detection. \n\t\t\t\t\tIn most practical systems, resources are either constrained or mutually exclusive. Constraints arise from network bandwidth restrictions, I/O and disk usage from writing images, \n\t\t\t\t\tand CPU usage needed to extract features from the images. Detecting events in real time requires dynamically choosing a subset of the available sensors for processing at any given time. \nFurthermore, certain camera configurations are not feasible. For example, a camera cannot zoom into two different regions in its field of view.\nZooming into a specific area in the field of view of a camera would generate a high resolution image of the region in the expense of a wider field of view. \nThus, the field of view needs to be changed dynamically to get a higher resolution images of certain regions of the space at the expanse other regions. \nIn order to illustrate the complexity of this problem, consider a face recognition application, which is only interested in high resolution (by means of optical zoom) \nfacial images. If we always zoom into a region to look for a high res face, we might miss presence of a person in different region and hence opportunity for zooming later to get the face in next time step.\nIn this talk we examine the problem of scheduling sensors for data collection and actuating them on real time to maximize some user-specified objective - e.g., \ndetecting as much motion as possible or collect as many high resolution facial images. \nThe main idea behind our approach is the use of sensor semantics to guide the scheduling process. We learn a dynamic probabilistic model of motion correlations \nbetween cameras, and use the model to guide resource allocation for our sensor network.\nAlthough previous work has leveraged probabilistic models for sensor-scheduling, our work is distinct in its focus on real-time building-monitoring using a camera network.  \nWe validate our approach using a sensor network of a dozen cameras spread throughout a university building, recording measurements of unscripted human activity over a two week period. \nWe automatically learn a semantic model of typical behaviors, and show that one can significantly improve efficiency of resource allocation and actuation by exploiting this model.\n</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">May 13, 2011 (Special)</div></td><td><div class=\"eventInfor\">SPEAKER: Prof. John Ousterhout (Stanford)</div><div class=\"eventInfor\">RAMCloud: Scalable High-Performance Storage Entirely in DRAM</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99102\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99102\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>May 13, 2011 (Special) 11am</td></tr><tr><td><b>Location</b></td><td>DBH 6011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Prof. John Ousterhout (Stanford)</td></tr><tr><td><b>Title</b></td><td>RAMCloud: Scalable High-Performance Storage Entirely in DRAM</td></tr><tr><td><b>Abstract</b></td><td>Disk-oriented approaches to online storage are becoming increasingly problematic: they do not scale gracefully to meet the needs of new large-scale Web applications, and improvements in disk capacity have out-stripped improvements in access speed.  In this talk I will describe a new approach to datacenter storage called RAMCloud, where information is kept entirely in DRAM and large-scale systems are created by aggregating the main memories of thousands of commodity servers.  A RAMCloud can provide durable and available storage with 100-1000x the throughput of disk-based systems and 100-1000x lower access latency.  By combining low latency and large scale, RAMClouds will enable a new class of applications that manipulate large datasets more intensively than has ever been possible.\n</td></tr><tr><td><b>Speaker Bio</b></td><td>John Ousterhout is Professor (Research) of Computer Science at Stanford University.  His current research focuses on infrastructure\nfor Web applications and cloud computing.  Ousterhout's prior positions include 14 years in industry where he founded two companies (Scriptics and Electric Cloud), preceded by 14 years as Professor of Computer Science at U.C. Berkeley.  He is the creator of the Tcl scripting language and is also well known for his work in distributed operating systems and file systems.  Ousterhout received a BS degree in Physics from Yale University and a PhD in Computer Science from Carnegie Mellon University.  He is a member of the National Academy of Engineering and has received numerous awards, including the ACM Software System Award, the ACM Grace Murray Hopper Award, the National Science Foundation Presidential Young Investigator Award, and the U.C. Berkeley Distinguished Teaching Award.\n</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">May 9, 2011 (Special)</div></td><td><div class=\"eventInfor\">SPEAKER: <a xmlns=\"\" href=\"http://pages.cs.wisc.edu/~bart/\">Prof. Barton P. Miller</a></div><div class=\"eventInfor\">Scaling Up to Large (Really Large) Systems</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99101\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99101\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>May 9, 2011 (Special) 11am</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td><a xmlns=\"\" href=\"http://pages.cs.wisc.edu/~bart/\">Prof. Barton P. Miller</a></td></tr><tr><td><b>Title</b></td><td>Scaling Up to Large (Really Large) Systems</td></tr><tr><td><b>Abstract</b></td><td>I will discuss the problem of developing tools and middleware for large scale\nparallel environments.  We are especially interested in systems, both leadership\nclass parallel computers and clusters that have 100,000's or even millions\nof processors.  The infrastructure that we have developed to address this\nproblem is called MRNet, the Multicast/Reduction Network. MRNet's approach\nto scale is to structure control and data flow in a tree-based overlay\nnetwork (TBON) that allows for efficient request distribution and flexible\ndata reductions.\n\nI will then present an overview of the MRNet design, architecture, and\ncomputational model and then discuss several of the applications of MRNet.\nThe applications include scalable automated performance analysis, a vision\nclustering application and, most recently, an effort to develop our first\npetascale debugging tool, STAT, a scalable stack trace analyzer running\ncurrently on 100,000's of processors on both the Cray XT and IBM BlueGene.</td></tr><tr><td><b>Speaker Bio</b></td><td>Prof. Barton Miller is a Professor of Computer Sciences at the University of Wisconsin.\nBart is a product of the UC System: he received his BA degree from UC San Diego in 1977\nand his MS and PhD in Computer Science from UC Berkeley in 1980 and 1984, respectively.\nHis research interests include distributed and parallel program performance and tools,\nbinary code analysis and instrumentation, computer security, scalable systems, operating\nsystems, and software testing. Bart is a Fellow of the ACM.</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">May 6, 2011</div></td><td><div class=\"eventInfor\">SPEAKER: Matthias Nicola, IBM</div><div class=\"eventInfor\"> A Matter of Time: Temporal Data Management in DB2 for z/OS </div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99100\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99100\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>May 6, 2011 2pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Matthias Nicola, IBM</td></tr><tr><td><b>Title</b></td><td> A Matter of Time: Temporal Data Management in DB2 for z/OS </td></tr><tr><td><b>Abstract</b></td><td>Time is a critical dimension in data management. For many enterprises\n\t\t it is useful or even required to have the ability to go back in time and look at a \n\t\t past state of the database. Many applications also need to manage time in their \n\t\t business records, such as contract start and end dates, expiration dates, or \n\t\t \"effective dates\" to indicate that information is valid for a certain period in the past, presence, or future. This presentation\n\t\t describes typical use cases for temporal data management and describes \n\t\t  the temporal capabilities in DB2, including system time, business time, and bitemporal support. \n</td></tr><tr><td><b>Speaker Bio</b></td><td>Matthias Nicola is a senior software engineer at IBM's Silicon Valley Lab, in \n\tSan Jose, CA, USA. He focuses on DB2 performance and benchmarking, XML, temporal data \n\tmanagement, in-database analytics, and other emerging technologies. Matthias also works \n\tclosely with customers and business partners to help them design, optimize and implement \n\tDB2 solutions. Previously Matthias worked on data warehouse performance at Informix Software. \n\tMatthias received his PhD in computer science from the Technical University of Aachen, Germany. \n</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">April 25, 2011 (Special)</div></td><td><div class=\"eventInfor\">SPEAKER: <a xmlns=\"\" href=\"http://www.cs.cmu.edu/~christos/\">Prof. Christos Faloutsos</a>, CMU</div><div class=\"eventInfor\">Mining Billion-node Graphs</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99029\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99029\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>April 25, 2011 (Special) 11am</td></tr><tr><td><b>Location</b></td><td>DBH 6011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td><a xmlns=\"\" href=\"http://www.cs.cmu.edu/~christos/\">Prof. Christos Faloutsos</a>, CMU</td></tr><tr><td><b>Title</b></td><td>Mining Billion-node Graphs</td></tr><tr><td><b>Abstract</b></td><td>What do graphs look like? How do they evolve over time? How to handle a \ngraph with a billion nodes? We present a comprehensive list of static \nand temporal laws, and some recent observations on real graphs (like, \ne.g., ``eigenSpokes''). We present tools, and specifically ``oddBall'' \nfor discovering anomalies and patterns, as well as fast algorithms for \nimmunization. Finally, we present an overview of the PEGASUS system \nwhich is designed to handle billion-node graphs, running on top of the \n\"hadoop\" system.</td></tr><tr><td><b>Speaker Bio</b></td><td>Christos Faloutsos is a Professor at Carnegie Mellon University. He has \nreceived the Presidential Young Investigator Award by the National \nScience Foundation (1989), the Research Contributions Award in ICDM \n2006, the SIGKDD Innovations Award (2010), seventeen ``best paper'' \nawards, (including two ``test of time'') and four teaching awards. He \nhas served as a member of the executive committee of SIGKDD; he is an \nACM Fellow; he has published over 200 refereed articles, 11 book \nchapters and one monograph.  He holds five patents and he has given over \n30 tutorials and over 10 invited distinguished lectures. His research \ninterests include data mining for graphs and streams, fractals, database \nperformance, and indexing for multimedia and bio-informatics data.\n</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">April 22, 2011</div></td><td><div class=\"eventInfor\">SPEAKER: <a xmlns=\"\" href=\"https://researcher.ibm.com/researcher/view.php?person=us-simeon\">Jerome Simeon</a>, IBM Research T.J. Watson</div><div class=\"eventInfor\">Algebraic Comprehensions (Database Optimization for Web 2.0 Queries)</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99028\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99028\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>April 22, 2011 2pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td><a xmlns=\"\" href=\"https://researcher.ibm.com/researcher/view.php?person=us-simeon\">Jerome Simeon</a>, IBM Research T.J. Watson</td></tr><tr><td><b>Title</b></td><td>Algebraic Comprehensions (Database Optimization for Web 2.0 Queries)</td></tr><tr><td><b>Abstract</b></td><td>Direct support for querying is becoming a \"must have\" for programming languages targeting Web 2.0 and Cloud development. Most of those languages (Microsoft's Linq, University of Edinburgh's Links, EPFL's Scala, Yahoo!'s Pig Latin, IBM's Thorn, etc) rely on the classic notion of comprehensions over collections. At the language level, comprehensions are a perfect choice, being well understood programming constructs, and capturing the expressive power of SQL iterators. At the compiler level, however, they are at odds with database optimizers which mostly rely on relational (or nested-relational) algebras. That mismatch was clearly on display during the design of XQuery, whose semantics is based on comprehensions, and for which most implementations target relational backends. We propose a alternative functional semantic formulation of XQuery to the one proposed by W3C, which is also based on comprehensions but has the benefit of corresponding precisely to compilation into a typed algebra that supports traditional database optimizations. First, this provides a formal foundation for XQuery implementations that want to ensure semantics integrity with the standard, along with modern database optimization techniques. Also, it provides key insights into the nature of database compilers that we believe is essential for the integration of database and programming languages technology. We notably discover that type systems for database algebras require an original solution to the old problem of subtyping with record concatenation, and that such a type system can eliminate the need for complex side conditions used in query language optimization.\n\t</td></tr><tr><td><b>Speaker Bio</b></td><td>Jerome Simeon is a Researcher for the Scalable XML Infrastructure Group at IBM T.J. Watson. He holds a degree in Engineering from EcolePolytechnique, and a Ph.D. from Universite d'Orsay. Previously, Jerome worked at INRIA from 1995 to 1999, and Bell Laboratories from 1999 to 2004. His research interests include databases, programming languages, compilers, and semantics, with a focus on Web development. He has put his work into practice in areas ranging from telecommunication infrastructure, to music. He is a co-editor for five of the W3C XML Query specifications, and has published more than 50 papers in scientific journals and international conferences. He is also a project lead for the Galax open-source XQuery implementation, and a co-author of \"XQuery from the Experts\" (Addison Wesley, 2004).\n        </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">April 15, 2011 </div></td><td><div class=\"eventInfor\">SPEAKER: Tyson Condie, Yahoo! Research</div><div class=\"eventInfor\">RubySky: Exploring Big Data with Transparency and Adjustability</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99027\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99027\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>April 15, 2011  2pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Tyson Condie, Yahoo! Research</td></tr><tr><td><b>Title</b></td><td>RubySky: Exploring Big Data with Transparency and Adjustability</td></tr><tr><td><b>Abstract</b></td><td>In this talk, I will introduce a new scripting language for ad-hoc exploration of large data sets, called RubySky.  \n            \tAs with several prior efforts, RubySky scripts execute either in a local environment or in the cloud (Hadoop). \n            \tTypically, cloud-based execution is highly opaque and hands-off, rendering debugging and iterative code development \n            \tvery difficult. RubySky, on the other hand, aims for a more transparent and adjustable paradigm.  \n            \tIt includes the ability to ``peek into'' intermediate cloud execution pathways, integrated as a first-class language construct.  \n            \tAlso integrated into the language is a way for the user to make last-minute code revisions, at any point at which troublesome\n            \t data is encountered in the cloud. \n            \t Combined, these features aim to improve usability for users who develop and run single-use scripts that\n            \t  explore new data sets. This is joint work with Christopher Olston at Yahoo! Research.\n            </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">April 1, 2011 </div></td><td><div class=\"eventInfor\">SPEAKER: <a xmlns=\"\" href=\"http://research.microsoft.com/en-us/people/terry/\">Doug Terry</a>, Microsoft Research</div><div class=\"eventInfor\">Replicated Data Consistency Explained through Baseball</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99026\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99026\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>April 1, 2011  2pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td><a xmlns=\"\" href=\"http://research.microsoft.com/en-us/people/terry/\">Doug Terry</a>, Microsoft Research</td></tr><tr><td><b>Title</b></td><td>Replicated Data Consistency Explained through Baseball</td></tr><tr><td><b>Abstract</b></td><td> A variety of relaxed consistency models for replicated data have\nbeen proposed and studied as an alternative to one-copy serializability, and\nsome of these are being used in cloud storage systems.  The designers of\nsuch systems particularly avoid two-phase commit for updates to\ngeo-replicated data that spans multiple data centers on different\ncontinents.  Instead, many cloud services, including systems from Amazon,\nYahoo, and Microsoft, have adopted techniques that provide eventual\nconsistency.  This talk explores the hows and whys of different consistency\nmodels.  The discussion will be driven by a simple example: maintaining the\nscore of a baseball game. We'll see that people with various roles in the\ngame can tolerate and benefit from different types of consistency when\naccessing the score.\n</td></tr><tr><td><b>Speaker Bio</b></td><td>Doug Terry is a Principal Researcher in the Microsoft Research Silicon\nValley lab.  His research focuses on the design and implementation of novel\ndistributed systems including mobile and cloud services.  He currently is\nserving as Chair of ACM's Special Interest Group on Operating Systems\n(SIGOPS) and as a member of the ACM Council.  Prior to joining Microsoft,\nDoug was the co-founder and CTO of a start-up company named Cogenia, Chief\nScientist of the Computer Science Laboratory at Xerox PARC, and an Adjunct\nProfessor in the Computer Science Division at U. C. Berkeley, where he still\noccasionally teaches a graduate course on distributed systems.  Doug has a\nPh.D. in Computer Science from U.C. Berkeley and is an ACM Fellow.</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Mar 31, 2011 </div></td><td><div class=\"eventInfor\">SPEAKER: <a xmlns=\"\" href=\"http://research.microsoft.com/en-us/people/terry/\">Doug Terry</a>, Microsoft Research</div><div class=\"eventInfor\">Cimbiosys: Content-based Replication for Mobile Devices and the Cloud</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99025\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99025\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Mar 31, 2011  11am</td></tr><tr><td><b>Location</b></td><td>DBH 6011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td><a xmlns=\"\" href=\"http://research.microsoft.com/en-us/people/terry/\">Doug Terry</a>, Microsoft Research</td></tr><tr><td><b>Title</b></td><td>Cimbiosys: Content-based Replication for Mobile Devices and the Cloud</td></tr><tr><td><b>Abstract</b></td><td> As people increasingly use mobile devices and cloud services to\nshare large data collections, exploiting communication proximity and\nselectively replicating content is essential.  Cimbiosys is a replicated\nstorage platform that permits each device to define its own content-based\nfiltering criteria and to exchange data directly with other devices.  This\ntalk focuses on the key challenge of ensuring eventual consistency in the\nface of fluid network connectivity, redefinable content filters, and\narbitrary updates.  Notably, Cimbiosys guarantees that each device\neventually stores precisely those items whose latest version matches its\ncustom filter and represents its replication-specific metadata in a compact\nform, resulting in low data synchronization overhead.  This permits ad hoc\nreplication between newly encountered devices and frequent synchronization\nbetween established partners, even over low bandwidth wireless networks or\nacross geo-distributed data centers.  (This talk will be a Ted and Janice Smith\nDistinguished lecture, and not at the normal time or place for ISG Seminars.)\n</td></tr><tr><td><b>Speaker Bio</b></td><td>Doug Terry is a Principal Researcher in the Microsoft Research Silicon\nValley lab.  His research focuses on the design and implementation of novel\ndistributed systems including mobile and cloud services.  He currently is\nserving as Chair of ACM's Special Interest Group on Operating Systems\n(SIGOPS) and as a member of the ACM Council.  Prior to joining Microsoft,\nDoug was the co-founder and CTO of a start-up company named Cogenia, Chief\nScientist of the Computer Science Laboratory at Xerox PARC, and an Adjunct\nProfessor in the Computer Science Division at U. C. Berkeley, where he still\noccasionally teaches a graduate course on distributed systems.  Doug has a\nPh.D. in Computer Science from U.C. Berkeley and is an ACM Fellow.\n</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Mar 25, 2011 </div></td><td><div class=\"eventInfor\">SPEAKER: <a xmlns=\"\" href=\"http://www.ics.uci.edu/~abehm/\">Alexander Behm</a>, UCI PhD student</div><div class=\"eventInfor\">Answering Approximate String Queries on Large Data Sets Using External Memory</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99023\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99023\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Mar 25, 2011  2pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td><a xmlns=\"\" href=\"http://www.ics.uci.edu/~abehm/\">Alexander Behm</a>, UCI PhD student</td></tr><tr><td><b>Title</b></td><td>Answering Approximate String Queries on Large Data Sets Using External Memory</td></tr><tr><td><b>Abstract</b></td><td>An approximate string query is to find from a\ncollection of strings those that are similar to a given query string.\nAnswering such queries is important in many applications such\nas data cleaning and record linkage, where errors could occur\nin queries as well as the data. Many existing algorithms have\nfocused on in-memory indexes. In this paper we investigate how\nto efficiently answer such queries in a disk-based setting, by\nsystematically studying the effects of storing data and indexes\non disk. We devise a novel physical layout for an inverted\nindex to answer queries and we study how to construct it with\nlimited buffer space. To answer queries, we develop a cost-based,\nadaptive algorithm that balances the I/O costs of retrieving\ncandidate matches and accessing inverted lists. Experiments\non large, real datasets verify that simply adapting existing\nalgorithms to a disk-based setting does not work well and that our\nnew techniques answer queries efficiently. Further, our solutions\nsignificantly outperform a recent tree-based index, BED-tree.\nThis talk is a ICDE practice talk.\n            </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Mar 18, 2011 </div></td><td><div class=\"eventInfor\">SPEAKER: Pinaki Sinha</div><div class=\"eventInfor\">Summarization of  Personal Photo Collections</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99022\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99022\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Mar 18, 2011  2pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Pinaki Sinha</td></tr><tr><td><b>Title</b></td><td>Summarization of  Personal Photo Collections</td></tr><tr><td><b>Abstract</b></td><td>The volume of personal photos hosted on photo archives and social sharing platforms \n            \thas been increasing exponentially. According to recent estimates, 6 Billion photos are uploaded\n            \t on Facebook per month. It is difficult to get an overview of a large collection of personal \n            \t photos without browsing though the entire database manually. In this talk, I will discuss a \n            \t framework to generate representative subset summaries from photo collections present on personal \n            \t archives or social networks. I will define salient properties of an effective photo summary \n            \t and model summarization as an optimization of these properties, given the size constraints. \n            \t Computer vision, and IR  based techniques will be used to generate summaries that \"look good\" as well as \n            \t are informative. I will also introduce information theory based metrics for evaluating photo \n            \t summaries based on their information content and the ability to satisfy user's information needs. \n            \t I will also discuss the manual evaluation experiments that were done to evaluate summaries.\n            </td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Mar 11, 2011 </div></td><td><div class=\"eventInfor\">SPEAKER: <a xmlns=\"\" href=\"http://www.ics.uci.edu/~dvk\"> Dmitri V. Kalashniknov </a></div><div class=\"eventInfor\">Entity resolution</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99021\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99021\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Mar 11, 2011  2pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td><a xmlns=\"\" href=\"http://www.ics.uci.edu/~dvk\"> Dmitri V. Kalashniknov </a></td></tr><tr><td><b>Title</b></td><td>Entity resolution</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Mar 4, 2011 </div></td><td><div class=\"eventInfor\">SPEAKER: Rares Vernica</div><div class=\"eventInfor\"> Efficient Processing of Set-Similarity Joins on Large Clusters</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99019\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99019\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Mar 4, 2011  2pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td>Rares Vernica</td></tr><tr><td><b>Title</b></td><td> Efficient Processing of Set-Similarity Joins on Large Clusters</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Feb 23, 2011 </div></td><td><div class=\"eventInfor\">SPEAKER:  Dr. Terence Sim</div><div class=\"eventInfor\">Getting More From Fisher</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99018\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99018\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Feb 23, 2011  3pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td> Dr. Terence Sim</td></tr><tr><td><b>Title</b></td><td>Getting More From Fisher</td></tr><tr><td><b>Abstract</b></td><td>The Fisher Linear Discriminant (FLD) is commonly used\nin classification to find a subspace that maximally separates\nclass patterns according to the Fisher Criterion.   It was\npreviously proven that a pre-whitening step can be used to\ntruly optimize the Fisher Criterion. In this talk, we show that\nmore insight and more applications may be derived from this\nclassical technique.\n\nFirst, we explore the subspaces induced by this whitened FLD.\nIn particular, we show how the Identity Space and Variation\nSpace are useful for decomposing and representing data.\nWe give sufficient conditions for these spaces to exist.  Through\nexperiments we also show how these spaces may\nbe used for classification and image synthesis.\n\nSecond, we further extend classical Fisher to handle data exhibiting\nmultiple factors (modes), e.g. face images that exhibit personal\nidentity, illumination, and pose.  We call our method Multimodal\nDiscriminant Analysis (MMDA), which is useful for decomposing\na dataset into independent modes. For face images, MMDA\neffectively separates identity, illumination and pose into mutually\northogonal subspaces.  MMDA is based on maximizing the\nFisher Criterion on all modes simultaneously, and is therefore\nwell-suited for multimodal and mode-invariant pattern recognition.\nWe also show that MMDA may be used for dimension reduction,\nand for synthesizing face images under novel illumination, and\neven novel personal identity.</td></tr><tr><td><b>Speaker Bio</b></td><td>Terence Sim is an Asst. Prof. at the School of Computing, National University of Singapore.  He teaches an undergraduate course in computer vision, as well as a graduate course in multimedia fundamentals.  For research, he works primarily in these areas:  face recognition, biometrics, and computational photography.   He is also interested in computer vision problems in general, such as shape-from-shading, photometric stereo, object recognition.  On the side, he dabbles with some aspects of music processing, such as polyphonic music transcription.  Dr. Sim serves as Vice-Chairman of the Biometrics Technical Committee (BTC), Singapore, and Chairman of the Cross-Jurisdictional and Societal Aspects Working Group (WG6) within the BTC.  The interesting issues here are the legal and privacy aspects of using biometrics.   He also serves as Vice-President of the Pattern Recognition and Machine Intelligence Association (PREMIA), a national professional body for pattern recognition.  Dr. Sim obtained his PhD from Carnegie Mellon in 2002, his MSc from Stanford University in 1991, and his SB from MIT in 1990.</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Feb 16, 2011</div></td><td><div class=\"eventInfor\">SPEAKER: <a xmlns=\"\" href=\"https://researcher.ibm.com/researcher/view.php?person=almaden-laura\"> Laura Haas (IBM)</a></div><div class=\"eventInfor\">New Principles for Information Integration </div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99016\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99016\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Feb 16, 2011 11am</td></tr><tr><td><b>Location</b></td><td>DBH 4011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td><a xmlns=\"\" href=\"https://researcher.ibm.com/researcher/view.php?person=almaden-laura\"> Laura Haas (IBM)</a></td></tr><tr><td><b>Title</b></td><td>New Principles for Information Integration </td></tr><tr><td><b>Abstract</b></td><td> Ten years ago, Clio introduced nonprocedural schema mappings to describe the relationship between data in heterogeneous schemas. This enabled powerful tools for mapping discovery and integration code generation, greatly simplifying the integration process.  However, further progress is needed. We see an opportunity to raise the level of abstraction further, and propose two new principles that the next generation of integration systems should embody. Holistic information integration supports iteration across the various integration tasks, leveraging information about both schema and data to improve the integrated result. Integration independence allows applications to be independent of how, when, and where information integration takes place, making materialization and the timing of transformations an optimization decision that is transparent to applications. This talk introduces these principles and describes some promising recent work in these directions. </td></tr><tr><td><b>Speaker Bio</b></td><td> Laura Haas is an IBM Fellow and has been director of computer science at IBM Almaden Research Center since 2005.  Previously, Dr. Haas was responsible for Information Integration Solutions (IIS) architecture in IBM's Software Group after leading the IIS development team through its first two years.  She joined the development team in 2001 as manager of DB2 UDB Query Compiler development.  Before that, Dr. Haas was a research staff member and manager at the Almaden lab for nearly twenty years.   In IBM Research, she worked on and managed a number of exploratory projects in distributed database systems.  Dr. Haas is best known for her work on the Starburst query processor (from which DB2 UDB was developed); on Garlic, a system which allowed federation of heterogeneous data sources; and on Clio, the first semi-automatic tool for heterogeneous schema mapping.  Garlic technology, married with DB2 UDB query processing, is the basis for the IBM WebSphere Information Server's federation capabilities, while Clio capabilities are a core differentiator in IBM\u2019s Rational Data Architect.  Dr. Haas has received several IBM awards for Outstanding Technical Achievement and Outstanding Innovation, and an IBM Corporate Award for her work on federated database technology. In 2010 she was recognized with the Anita Borg Institute Technical Leadership Award. She is a member of the National Academy of Engineering and the IBM Academy of Technology, an ACM Fellow, and Vice Chair of the board of the Computing Research Association.  Dr. Haas received her PhD from the University of Texas at Austin, and her bachelor degree from Harvard University.</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr><tr><td><div class=\"eventDate\">Feb 4, 2011 (POSTPONED)</div></td><td><div class=\"eventInfor\">SPEAKER: <a xmlns=\"\" href=\"http://www.ics.uci.edu/~amyvoida/Site/News_%26_Updates/News_%26_Updates.html\"> Amy Voida</a></div><div class=\"eventInfor\">Homebrew Databases</div></td></tr><tr><td></td><td><a href=\"#\" onclick='var x=getElementById(\"e99015\");if(x.style.display!=\"none\"){x.style.display=\"none\";}else{x.style.display=\"block\";}return false;'>Details</a></td></tr><tr class=\"detr\"><td colspan=\"2\"><div id=\"e99015\" style=\"display:none;border:solid grey;border-width:1px;\"><table><tr><td style=\"width:100px;\"><b>Date and Time</b></td><td>Feb 4, 2011 (POSTPONED) 2pm</td></tr><tr><td><b>Location</b></td><td>DBH 3011</td></tr></table><br></br><table><tr><td style=\"width:100px;\"><b>Speaker</b></td><td><a xmlns=\"\" href=\"http://www.ics.uci.edu/~amyvoida/Site/News_%26_Updates/News_%26_Updates.html\"> Amy Voida</a></td></tr><tr><td><b>Title</b></td><td>Homebrew Databases</td></tr></table></div><div style=\"height: 5px;\"></div></td></tr></table></div><div class=\"content\"><p></p><p> For more information on CS distinguished lectures, please visit <a href=\"http://www.ics.uci.edu/computerscience/research/seminarseries/\">Computer Science Department Seminar Series</a>.</p><p></p><div class=\"gotop\"><a href=\"#header\">^ top</a></div></div><div id=\"footer\"><p>Last Updated on January 07, 2011</p></div></div></body></html>\n", "id": 4604.0}