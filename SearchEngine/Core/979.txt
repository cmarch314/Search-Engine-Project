{"text": "Reference Material on Unsupervised Learning Clustering Topic Modeling CS 175 Winter 2 15 Clustering Algorithms and Methodsscikit learn overview of clustering methods Clustering algorithms and document clustering from Introduction to Information Retrieval by Manning Raghavan and Schutzeflat clustering chapter 16 hierarchical clustering chapter 17Embedding of Text using Neural NetworksResearch tutorial slides on embedding methods for textResearch paper from Miklov Yih and Zweig 2 13Research paper on representing sentences and documents Le and Mikolov 2 14Useful blog post on deep learning and textTopic Modeling AlgorithmsDavid Blei s topic modeling page papers tutorials code in Python and other languages Topic modeling tutorial from ICML 2 12 by David BleiProbabilistic topic models Steyvers and Griffiths 2 6Matrix Decomposition and Latent Semantic AnalysisScholarpedia article on latent semantic analysis by Landauer and DumaisMatrix decompositions and latent semantic indexing Chapter 18 from Intro to Information Retrieval Manning et al ", "_id": "http://www.ics.uci.edu/~smyth/courses/cs175/reading/references_on_clustering.html", "title": "references on clustering, cs 175", "html": "<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n<html xmlns=\"http://www.w3.org/1999/xhtml\"><head>\r\n<meta content=\"text/html; charset=UTF-8\" http-equiv=\"Content-Type\" />\r\n<title>References on Clustering, CS 175</title></head>\r\n<body style=\"color: rgb(0, 0, 0); background-color: white; margin-left: 104px; width: 872px;\" alink=\"#000099\" link=\"#000099\" vlink=\"#990099\"><center style=\"font-family: Calibri;\"><h2 style=\"text-align: left; width: 979px;\"><small><span style=\"font-family: Calibri;\"><big><span style=\"font-weight: bold;\">Reference Material on Unsupervised Learning (Clustering, Topic Modeling,...)</span></big></span></small><font color=\"#330033\"><small>&nbsp;</small></font></h2><h2 style=\"text-align: left; width: 979px;\"><big><font><small><font color=\"#330033\"><small>CS 175, Winter 2015</small></font></small></font></big></h2><hr style=\"width: 100%; height: 2px;\" />&nbsp;</center><span style=\"font-family: Calibri;\"></span><span style=\"font-family: Calibri;\"><span style=\"font-weight: bold;\"><big>Clustering Algorithms and Methods</big><br /></span></span><ul><li style=\"font-family: Calibri;\">scikit-learn<a href=\"http://scikit-learn.org/stable/modules/clustering.html#clustering\"> overview of clustering methods&nbsp;</a></li><li style=\"font-family: Calibri;\">Clustering algorithms and document clustering,<span class=\"Apple-converted-space\">&nbsp;</span>from <a href=\"http://www-nlp.stanford.edu/IR-book/\">Introduction to Information Retrieval by Manning, Raghavan, and Schutze</a></li><ul style=\"font-family: Calibri;\"><li><a href=\"http://nlp.stanford.edu/IR-book/pdf/16flat.pdf\">flat clustering: chapter 16</a>&nbsp;<span style=\"text-decoration: underline;\">&nbsp;</span><a href=\"http://www-nlp.stanford.edu/IR-book/\"></a></li><li><a href=\"http://nlp.stanford.edu/IR-book/pdf/17hier.pdf\">hierarchical clustering, chapter 17</a></li></ul></ul><span style=\"font-family: Calibri;\"><br /><big><span style=\"font-weight: bold;\">Embedding of Text using Neural Networks</span></big><br /></span><ul><li><span style=\"font-family: Calibri;\">Research <a href=\"http://emnlp2014.org/tutorials/8_notes.pdf\">tutorial slides on embedding methods for text</a></span></li><li><span style=\"font-family: Calibri;\">Research paper from <a href=\"http://www.aclweb.org/anthology/N13-1090.pdf\">Miklov, Yih, and Zweig, 2013</a></span></li><li><span style=\"font-family: Calibri;\">Research paper on <a href=\"http://www-cs.stanford.edu/%7Equocle/paragraph_vector.pdf\">representing sentences and documents</a>, Le and Mikolov, 2014</span></li><li><span style=\"font-family: Calibri;\">Useful blog post on<a href=\"http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/\"> deep learning and text</a><br /></span></li></ul><span style=\"font-family: Calibri;\"><br /><big><span style=\"font-weight: bold;\">Topic Modeling Algorithms</span></big><br /></span><ul style=\"font-family: Calibri;\"><li><a href=\"http://www.cs.columbia.edu/%7Eblei/topicmodeling.html\">David Blei's topic modeling page</a> (papers, tutorials, code in Python and other languages).</li><li><a href=\"http://www.cs.princeton.edu/%7Eblei/papers/icml-2012-tutorial.pdf\">Topic modeling tutorial from ICML 2012</a>, by David Blei</li><li><a href=\"http://psiexp.ss.uci.edu/research/papers/SteyversGriffithsLSABookFormatted.pdf\">Probabilistic topic models</a>, Steyvers and Griffiths, 2006</li></ul><span style=\"font-family: Calibri;\"><br /></span><span style=\"font-family: Calibri;\"><big><span style=\"font-weight: bold;\">Matrix Decomposition and Latent Semantic Analysis</span></big><br /></span><ul style=\"font-family: Calibri;\"><li><a href=\"http://www.scholarpedia.org/article/Latent_semantic_analysis\">Scholarpedia article on latent semantic analysis</a>, by Landauer and Dumais</li><li><a href=\"http://nlp.stanford.edu/IR-book/pdf/18lsi.pdf\">Matrix decompositions and latent semantic indexing</a>, Chapter 18 from Intro to Information Retrieval, Manning et al.&nbsp;</li></ul><br /><span style=\"font-family: Calibri;\"><br /></span><span style=\"font-family: Calibri;\"><span style=\"font-weight: bold;\">&nbsp;</span></span><span style=\"font-family: Calibri;\"><br /><br /></span><span style=\"font-family: Calibri;\"><br />&nbsp;</span><br /><span style=\"font-family: Calibri;\"><span style=\"font-weight: bold;\">&nbsp;</span></span><br /><span style=\"font-weight: normal; font-family: Calibri;\">&nbsp; </span><span style=\"font-family: Verdana,Arial,Helvetica,sans-serif;\"></span><ul><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"></font></font></font></font></ul></body></html>", "id": 979.0}