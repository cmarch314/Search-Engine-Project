{"text": "CS 274A Background Notes and Reading Notation GuideNotes to Accompany Lectures Note Sets 1 to 3 are particularly relevant for the 1st and 2nd week Note Set 1 Review of Probability PDF Note Set 2 Multivariate Probability Models PDF Note Set 3 Models Parameters and Likelihood PDF Note Set 4 The EM Algorithm for Gaussian Mixtures PDF Overview Articles on Probabilistic LearningModel based machine learning Chris Bishop Phil Trans R Soc A 2 12 A well written overview article that reviews some of the key ideas behind probabilistic model based learningGeneral Background Review Material on ProbabilityMaterial random variables conditional and joint probabilities Bayes rule law of total probability chain rule and factorization Frequentist and Bayesian views of probability Sets of random variables the multivariate Gaussian model Conditional independence and graphical models Note Sets 1 and 2 above Barber text pages 1 to 14 basic probability pages 29 to 4 graphical models sections 8 1 to 8 4 univariate and multivariate distributions Murphy text Chapter 1 introduction and Chapter 2 1 through 2 5 probability and distributions Excellent 15 minute video on multivariate Gaussian distributions from Alex IhlerProbability The Analysis of Data vol 1 by Guy Lebanon html version freely available online useful as a reference Learning from Data using Maximum LikelihoodMaterial Concepts of models and parameters Definition of the likelihood function and the principle of maximum likelihood parameter estimation Using maximum likelihood methods to learn the parameters of Gaussian models binomial multivariate and other parametric models Note Set 3 aboveBarber pages 174 177 Tutorial paper on maximum likelihood estimation Bayesian LearningMaterial General principles of Bayesian estimation prior densities posterior densities MAP fully Bayesian approaches Beta binomial and Gaussian examples Predictive densities model selection model averaging Note Sets 1 and 2 above Barber text pages 191 194 in Chapter 9 Learning as Inference pPages 177 179 in Chapter 8 and Chapter 12 on Bayesian Model SelectionMurphy text Chapter 3 1 to 3 4 and Chapter 5 1 5 2 5 3Chapter on Model Comparison and Occam s Razor from David MacKay s book on Information Theory and Inference and video lecture of David lecturing on Bayesian inference Regression ModelsMaterial Linear models Normal equations Systematic and stochastic components Parameter estimation methods for regression Maximum likelihood and Bayesian interpretations Barber text pages 345 35 and Pages 367 374 in Chapter 17 on Linear Models Murphy text Chapter 7 1 7 2 7 3 and 7 6 pages 1 to 33 of a classic paper on the bias variance tradeoff Mike Tipping s review paper on Bayesian regression Slides from Stephen Wright on optimization techniques for machine learning algorithmsProbabilistic ClassificationMaterial Bayes rule classification boundaries discriminant functions Optimal decisions Bayes error rate Gaussian classifiers Likelihood based approaches and properties of objective functions Logistic regression and neural network models Barber text pages 229 234 in Chapter 1 on Naive Bayes pages 353 358 on logistic regression in Chapter 17 on Linear Models Murphy text pages 1 1 1 7 on Gaussian classifiers in Chapter 4 Chapter 8 1 8 2 8 3 Notes on logistic regression from Charles ElkanGenkin et al Logistic regression for high dimensional text data Probabilistic ClusteringMaterial Mixtures of Gaussians and the associated EM algorithm K means clustering Mixtures of conditional indepedence models Applications to text data Underlying theory of the EM algorithm Note Set 4 above EM for Gaussian mixture models General derivation of the EM Algorithm pages 4 4 4 6 in Barber pages 363 369 in MurphyBarber text pages 4 3 416 Murphy text pages 337 356 Chapter 11 Jeff Bilmes tutorial notes on EM Frank Dellaert s tutorial notes on EMLiang and Klein s Online EM with applications to textFraley and Raftery paper on model based clustering State Space ModelsMaterial discrete and continuous latent state space models Hidden Markov models Kalman filters Basic principles of smoothing and filtering Parameter estimation methods using EM Barber text pages 451 471 in Chapter 23 on Dynamical Models Murphy text Chapter 17 1 to 17 5Sampling MethodsMaterial Importance sampling Gibbs sampling and related ideas Barber text pages 543 553 in Chapter 27 on Sampling ", "_id": "http://www.ics.uci.edu/~smyth/courses/cs274/background_notes.html", "title": "cs 274a: background notes", "html": "<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n<html xmlns=\"http://www.w3.org/1999/xhtml\"><head>\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=ISO-8859-1\" />\n<title>CS 274A: Background Notes</title></head>\n<body style=\"color: rgb(0, 0, 0); background-color: white;\" alink=\"#000099\" link=\"#000099\" vlink=\"#990099\"><div style=\"text-align: center;\">\n</div><center style=\"font-family: Calibri;\">\n\n  <h2><big><font color=\"#330033\"><small> CS 274A: Background Notes and Reading</small></font></big><br /></h2>\n</center>\n<a style=\"font-family: Calibri; font-weight: bold;\" href=\"notes/notation.pdf\">Notation Guide</a><br /><br /><span style=\"font-weight: bold; font-family: Calibri;\"><br /></span><span style=\"font-weight: bold; font-family: Calibri;\">Notes to Accompany Lectures</span><span style=\"font-family: Calibri;\"> (Note Sets 1 to 3 are particularly relevant for the 1st and 2nd week)</span><span style=\"font-weight: bold; font-family: Calibri;\"><br /></span><ul style=\"font-family: Calibri;\"><li><a href=\"notes/notes1.pdf\">Note Set 1: Review of Probability (PDF)<br /></a></li><li><a href=\"notes/notes2.pdf\">Note Set 2: Multivariate Probability Models (PDF)</a><br /></li><li><a href=\"notes/notes3.pdf\">Note Set 3: Models, Parameters, and Likelihood (PDF) <br /></a></li><li style=\"font-weight: normal;\"><big><a href=\"notes/EMnotes.pdf\"><small>Note Set 4: The EM Algorithm for Gaussian\n      Mixtures (PDF)</small></a></big></li></ul><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><span style=\"font-weight: normal;\"><big><span style=\"font-family: Calibri;\"><span style=\"font-weight: bold;\"><br />Overview Articles on Probabilistic Learning</span></span></big></span></small></font></font></font></font></font><span style=\"font-family: Calibri;\"><br /></span><ul><li style=\"font-family: Calibri;\"><a href=\"readings/Bishop-MBML-2012.pdf\">Model-based machine learning</a>, Chris Bishop, <span style=\"font-style: italic;\">Phil Trans R. Soc. A</span>, 2012. A well-written overview article that reviews some of the key ideas behind probabilistic model-based learning</li></ul><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><span style=\"font-weight: normal;\"><big><span style=\"font-family: Calibri;\"><span style=\"font-weight: bold;\"></span></span></big></span></small></font></font></font></font></font><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><span style=\"font-weight: normal;\"><big><span style=\"font-family: Calibri;\"><span style=\"font-weight: bold;\"><br /></span></span></big></span></small></font></font></font></font></font><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><span style=\"font-weight: normal;\"><big><span style=\"font-family: Calibri;\"><span style=\"font-weight: bold;\">General Background/Review Material on Probability</span></span></big></span></small></font></font></font></font></font><span style=\"font-family: Calibri;\"><br /></span><ul><li style=\"font-family: Calibri;\">Material: <font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><small><big><span style=\"font-weight: normal;\">random variables, conditional and joint\nprobabilities, Bayes rule, law of total probability, chain&nbsp;rule\nand factorization. Frequentist and Bayesian views of probability. Sets of random variables, the\nmultivariate Gaussian model. Conditional independence and graphical\nmodels.&nbsp;</span></big></small><span style=\"font-weight: normal;\"></span></small></font></font></font></font></font></font></li><li style=\"font-family: Calibri;\">Note Sets 1 and 2 above&nbsp;</li><li style=\"font-family: Calibri;\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small>Barber\ntext: pages 1 to 14 (basic probability), pages 29 to 40 (graphical\nmodels), sections 8.1 to 8.4 (univariate and multivariate\ndistributions)&nbsp;</small></font></font></font></font></font></font></li><li style=\"font-family: Calibri;\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small>Murphy text: Chapter 1 (introduction) and Chapter 2.1 through 2.5 &nbsp;(probability and distributions)</small></font></font></font></font></font></font></li><li style=\"font-family: Calibri;\">Excellent 15 minute <a href=\"http://www.youtube.com/watch?v=eho8xH3E6mE&amp;feature=youtu.be\">video on multivariate Gaussian distributions</a> from Alex Ihler</li><li style=\"font-family: Calibri;\"><a href=\"http://www.theanalysisofdata.com/probability/0_2.html\">Probability: The Analysis of Data,</a> vol 1, by Guy Lebanon (html version freely available online - useful as a reference)</li></ul><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><span style=\"font-weight: normal;\"></span></small></font></font></font></font></font><br /><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><span style=\"font-weight: normal;\"><big><span style=\"font-family: Calibri;\"><span style=\"font-weight: bold;\"><br />Learning from Data using Maximum Likelihood</span></span></big></span></small></font></font></font></font></font><span style=\"font-family: Calibri;\"><br /></span><ul><li style=\"font-family: Calibri;\">Material: <font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><span style=\"font-weight: normal;\"> Concepts of models and\n          parameters. Definition of the likelihood\n          function&nbsp;and the principle of maximum likelihood parameter\n          estimation.</span></small><b>&nbsp;</b></font></font></font></font></font></font><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><span style=\"font-weight: normal;\">Using maximum likelihood methods to learn the parameters of Gaussian models, binomial, multivariate and other\n          parametric models.</span></small></font></font></font></li><li style=\"font-family: Calibri;\">Note Set 3 above</li><li style=\"font-family: Calibri;\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small>Barber: pages 174-177&nbsp;</small></font></font></font></font></font></font></li><li style=\"font-family: Calibri;\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><a href=\"papers/MLtutorial.pdf\" style=\"font-weight: normal;\">Tutorial          paper on maximum likelihood estimation</a></small></font></font></font><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small>&nbsp;</small></font></font></font></font></font></font></li></ul><span style=\"font-family: Verdana,Arial,Helvetica,sans-serif;\"></span><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><a href=\"papers/MLtutorial.pdf\" style=\"font-weight: normal;\"></a></small></font></font></font><br /><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><span style=\"font-weight: normal;\"><big><span style=\"font-family: Calibri;\"><span style=\"font-weight: bold;\">Bayesian Learning</span></span></big></span></small></font></font></font></font></font><span style=\"font-family: Calibri;\"><br /></span><ul><li style=\"font-family: Calibri;\">Material:<font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><span style=\"font-weight: normal;\"> General\n          principles of Bayesian\n          estimation: prior densities, posterior densities, MAP, fully Bayesian approaches. </span></small></font></font></font><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><span style=\"font-weight: normal;\"></span></small></font></font></font><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><span style=\"font-weight: normal;\">Beta/binomial and Gaussian examples.</span></small></font></font></font><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><small><big><span style=\"font-weight: normal;\"></span></big></small><span style=\"font-weight: normal;\">&nbsp;</span></small></font></font></font></font></font></font><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><span style=\"font-weight: normal;\">Predictive densities, model selection, model averaging<span style=\"font-weight: bold;\">&nbsp;</span></span></small></font></font></font><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><small><big><span style=\"font-weight: normal;\"></span></big></small><span style=\"font-weight: normal;\"></span></small></font></font></font></font></font></font></li><li style=\"font-family: Calibri;\">Note Sets 1 and 2 above&nbsp;</li><li style=\"font-family: Calibri;\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small>Barber text: pages 191-194 (in Chapter 9, Learning as Inference), p</small></font></font></font></font></font></font><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small>Pages 177-179 in Chapter 8, and Chapter 12 on Bayesian Model Selection</small></font></font></font></font></font></font></li><li style=\"font-family: Calibri;\">Murphy text:<font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small> Chapter 3.1 to 3.4 and </small></font></font></font></font></font></font><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small>Chapter 5.1, 5.2, 5.3</small></font></font></font></font></font></font></li><li style=\"font-family: Calibri;\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small>Chapter on <a href=\"http://www.cs.toronto.edu/%7Emackay/itprnn/ps/345.357.pdf\">Model Comparison and Occam's Razor</a> from David MacKay's book on <a href=\"http://www.inference.phy.cam.ac.uk/mackay/itila/book.html\">Information Theory and Inference</a>,&nbsp;</small></font></font></font></font></font></font><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small>and <a href=\"http://videolectures.net/mackay_course_10/\">video lecture</a> of David lecturing on Bayesian inference.</small></font></font></font></font></font></font><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small>&nbsp; &nbsp;</small></font></font></font></font></font></font><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small></small></font></font></font></font></font></font></li></ul><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><span style=\"font-weight: normal;\"><big><span style=\"font-family: Calibri;\"><span style=\"font-weight: bold;\"></span></span></big></span></small></font></font></font></font></font><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><span style=\"font-weight: normal;\"><big><span style=\"font-family: Calibri;\"><span style=\"font-weight: bold;\"><br /></span></span></big></span></small></font></font></font></font></font><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><span style=\"font-weight: normal;\"><big><span style=\"font-family: Calibri;\"><span style=\"font-weight: bold;\">Regression Models</span></span></big></span></small></font></font></font></font></font><span style=\"font-family: Calibri;\"><br /></span><ul><li style=\"font-family: Calibri;\">Material:<big><small><span style=\"font-weight: normal;\"> Linear models.\n          Normal equations. Systematic and stochastic components.&nbsp;</span></small></big><span style=\"font-weight: normal;\">\n Parameter estimation methods for\n          regression. Maximum likelihood and Bayesian interpretations.&nbsp;</span></li><li style=\"font-family: Calibri;\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small>Barber text:&nbsp;</small></font></font></font></font></font></font>pages 345-350 and&nbsp;Pages 367-374 (in Chapter 17 on Linear Models)</li><li style=\"font-family: Calibri;\">Murphy text:<font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small>&nbsp;</small></font></font></font></font></font></font>Chapter 7.1, 7.2, 7.3 and 7.6<font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small> </small></font></font></font></font></font></font><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small>&nbsp;</small></font></font></font></font></font></font></li><li style=\"font-family: Calibri;\">pages 1 to 33 of <a href=\"readings/bias_variance.pdf\">a classic paper on the bias/variance tradeoff</a><big>&nbsp;&nbsp;</big></li><li style=\"font-family: Calibri;\"><a href=\"readings/bayesian_regression_overview.pdf\">Mike Tipping's review paper on\n          Bayesian regression</a><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small>&nbsp;</small></font></font></font></font></font></font></li><li style=\"font-family: Calibri;\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small>Slides from Stephen Wright on <a href=\"http://www.ipam.ucla.edu/publications/gss2012/gss2012_10763.pdf\">optimization techniques for machine learning algorithms</a><br /></small></font></font></font></font></font></font></li></ul><br /><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><span style=\"font-weight: normal;\"><big><span style=\"font-family: Calibri;\"><span style=\"font-weight: bold;\">Probabilistic Classification</span></span></big></span></small></font></font></font></font></font><span style=\"font-family: Calibri;\"><br /></span><ul><li style=\"font-family: Calibri;\">Material:&nbsp;<font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><font style=\"font-weight: normal;\">\n          Bayes rule, classification boundaries, discriminant\n          functions</font></small></font></font></font><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><span style=\"font-weight: normal;\">, </span></small></font></font></font></font></font></font><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><big><small><span style=\"font-weight: normal;\">\n        Optimal decisions, Bayes error\n            rate<span style=\"font-weight: bold;\">, </span></span></small></big></small></font></font></font><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><span style=\"font-weight: normal;\">Gaussian classifiers. </span></small></font></font></font></font></font></font><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><big><small><span style=\"font-weight: normal;\"><span style=\"font-weight: bold;\"></span></span></small></big></small></font></font></font><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><span style=\"font-weight: normal;\"> Likelihood-based approaches and properties of objective functions.&nbsp;</span></small><small><font style=\"font-weight: normal;\">Logistic regression and\n      neural network models.</font></small></font></font></font><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><big><small><span style=\"font-weight: normal;\"><span style=\"font-weight: bold;\">&nbsp;</span></span></small></big></small></font></font></font><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><span style=\"font-weight: normal;\"> &nbsp;</span></small></font></font></font></font></font></font></li><li style=\"font-family: Calibri;\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small>Barber text:&nbsp;</small></font></font></font></font></font></font><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small>pages 229-234 (in Chapter 10 on Naive Bayes),&nbsp;</small></font></font></font></font></font></font>pages 353-358 on logistic regression (in Chapter 17 on Linear Models)<font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small></small></font></font></font></font></font></font></li><li style=\"font-family: Calibri;\">Murphy text:<font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small>&nbsp;</small></font></font></font></font></font></font><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small>pages 101-107 on Gaussian classifiers in Chapter 4, </small></font></font></font></font></font></font>Chapter 8.1. 8.2, 8.3<font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small>&nbsp;</small></font></font></font></font></font></font><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small>&nbsp;</small></font></font></font></font></font></font></li><li style=\"font-family: Calibri;\"><big><font style=\"font-family: Calibri;\"><small><a href=\"readings/elkan_logisticregression_notes.pdf\">Notes on logistic regression</a> from Charles Elkan</small></font></big></li><li style=\"font-family: Calibri;\"><big><font style=\"font-family: Calibri;\"><small>Genkin et al,<span style=\"font-family: Calibri;\"> </span></small></font></big><a href=\"http://www.stat.columbia.edu/%7Emadigan/PAPERS/techno.pdf\" style=\"font-family: Calibri;\">Logistic regression for high-dimensional text data</a><span style=\"font-family: Calibri;\"> &nbsp;</span></li></ul><br /><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><span style=\"font-weight: normal;\"><big><span style=\"font-family: Calibri;\"><span style=\"font-weight: bold;\">Probabilistic Clustering</span></span></big></span></small></font></font></font></font></font><span style=\"font-family: Calibri;\"><br /></span><ul><li style=\"font-family: Calibri;\">Material: <span style=\"font-weight: normal;\">Mixtures of\n      Gaussians and the associated EM algorithm.&nbsp;</span><span style=\"font-weight: normal;\"> K-means\n        clustering.</span><span style=\"font-weight: normal;\"> Mixtures of\n        conditional indepedence models.&nbsp;</span><font style=\"font-weight: normal;\"> Applications to text\n      data. Underlying theory of the EM algorithm.</font></li><li style=\"font-family: Calibri;\">Note Set 4 above (EM for Gaussian mixture models)</li><li style=\"font-family: Calibri;\">General derivation of the EM Algorithm: pages 404-406 in Barber, pages 363-369 in Murphy</li><li style=\"font-family: Calibri;\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><big><small><span style=\"font-weight: normal;\"><span style=\"font-weight: bold;\"></span></span></small></big></small></font></font></font><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><span style=\"font-weight: normal;\"></span></small></font></font></font></font></font></font><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small>Barber text: p</small></font></font></font></font></font></font>ages 403-416<font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small>&nbsp;</small></font></font></font></font></font></font></li><li style=\"font-family: Calibri;\">Murphy text:<font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small>&nbsp;</small></font></font></font></font></font></font>pages 337-356 (Chapter 11)<font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small></small></font></font></font></font></font></font><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small>&nbsp;</small></font></font></font></font></font></font></li><li style=\"font-family: Calibri;\"><small> </small><big><font style=\"font-family: Calibri;\"><small><span style=\"font-weight: normal;\"></span>Jeff Bilmes <a href=\"http://ssli.ee.washington.edu/people/bilmes/mypapers/em.pdf\">tutorial\n        notes on EM</a>, Frank Dellaert's <a href=\"http://www.cc.gatech.edu/%7Edellaert/em-paper.pdf\">tutorial\n      notes on EM</a></small></font></big></li><li style=\"font-family: Calibri;\"><big><font style=\"font-family: Calibri;\"><small>Liang and Klein's<a href=\"http://dl.acm.org/citation.cfm?id=1620843\"> Online EM with applications to text</a></small></font></big></li><li style=\"font-family: Calibri;\"><big><big><small><font style=\"font-family: Calibri;\"><small><span style=\"font-weight: normal;\">Fraley and Raftery </span><a href=\"readings/fraley_raftery.pdf\" style=\"font-weight: normal;\">paper on\n          model-based clustering&nbsp;</a></small></font></small></big></big></li></ul><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><span style=\"font-weight: normal;\"><big><span style=\"font-family: Calibri;\"><span style=\"font-weight: bold;\"></span></span></big></span></small></font></font></font></font></font><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><span style=\"font-weight: normal;\"><big><span style=\"font-family: Calibri;\"><span style=\"font-weight: bold;\"></span></span></big></span></small></font></font></font></font></font><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><span style=\"font-weight: normal;\"><big><span style=\"font-family: Calibri;\"><span style=\"font-weight: bold;\"><br /></span></span></big></span></small></font></font></font></font></font><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><span style=\"font-weight: normal;\"><big><span style=\"font-family: Calibri;\"><span style=\"font-weight: bold;\"><br /></span></span></big></span></small></font></font></font></font></font><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><span style=\"font-weight: normal;\"><big><span style=\"font-family: Calibri;\"><span style=\"font-weight: bold;\">State-Space Models</span></span></big></span></small></font></font></font></font></font><span style=\"font-family: Calibri;\"><br /></span><ul><li style=\"font-family: Calibri;\">Material:<big><small><span style=\"font-weight: normal;\">\ndiscrete and continuous latent-state space models. Hidden Markov\nmodels, Kalman filters. Basic principles of smoothing and filtering.\nParameter estimation methods using EM.</span></small></big><span style=\"font-weight: normal;\">&nbsp;</span></li><li style=\"font-family: Calibri;\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small>Barber text: p</small></font></font></font></font></font></font><big><font style=\"font-family: Calibri;\"><small>ages 451-471 (in Chapter 23 on Dynamical Models)</small></font></big></li><li style=\"font-family: Calibri;\">Murphy text:<font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small>&nbsp;</small></font></font></font></font></font></font><big><font style=\"font-family: Calibri;\"><small>Chapter 17.1 to 17.5</small></font></big></li></ul><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><span style=\"font-weight: normal;\"><big><span style=\"font-family: Calibri;\"></span></big></span></small></font></font></font></font></font><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><span style=\"font-weight: normal;\"><big><span style=\"font-family: Calibri;\"><span style=\"font-weight: bold;\"><br /></span></span></big></span></small></font></font></font></font></font><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><span style=\"font-weight: normal;\"><big><span style=\"font-family: Calibri;\"><span style=\"font-weight: bold;\"><br /></span></span></big></span></small></font></font></font></font></font><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><span style=\"font-weight: normal;\"><big><span style=\"font-family: Calibri;\"><span style=\"font-weight: bold;\">Sampling Methods</span></span></big></span></small></font></font></font></font></font><span style=\"font-family: Calibri;\"><br /></span><ul><li style=\"font-family: Calibri;\">Material:<big><small><span style=\"font-weight: normal;\">&nbsp;</span></small></big><span style=\"font-weight: normal;\">Importance sampling, Gibbs sampling, and related ideas<span style=\"font-weight: bold;\">&nbsp;</span></span><span style=\"font-weight: normal;\"></span></li><li style=\"font-family: Calibri;\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small>Barber text: p</small></font></font></font></font></font></font>ages 543-553&nbsp;(in Chapter 27 on Sampling) &nbsp;</li></ul><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><span style=\"font-weight: normal;\"><big><span style=\"font-family: Calibri;\"><span style=\"font-weight: bold;\"></span></span></big></span></small></font></font></font></font></font><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><font face=\"Verdana, Arial, Helvetica, sans-serif\"><small><span style=\"font-weight: normal;\"><big><span style=\"font-family: Calibri;\"><span style=\"font-weight: bold;\"><br /></span></span></big></span></small></font></font></font></font></font><br /><span style=\"font-family: Verdana,Arial,Helvetica,sans-serif;\"><br />&nbsp;</span></body></html>", "id": 230.0}