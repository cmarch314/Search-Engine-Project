{"text": "Google Servers Home Research Software Publications Industry Resume Flashback Introduction This is my attemp to tackle the greatest question of modern times how many blade PCs does Google run The initial guess in 2 3 was 1 and then recently the consensus seems to be in the order of 1 But these have remained guesses at best Here I ll try and see if this number can be deduced from various requirements network BW storage CPU etc Bandwidth Requirement First let s see how much bandwidth Google might need Then we ll divide this by how much BW a PC can handle to get the number of PCs needed I ll constrain the analysis to North America Similar analysis can be done for other geographies Again since search is the main Bread Butter of Google this analysis is restricted to search OK first some numbers that ll help us U S pop 3 million Internet penetration in US 7 Google market share 3 So assuming that on an average a person using google does 2 searches a day and clicks through 1 5 pages of results for each search supposedly 9 of users find the results they want on the first page so I think an average of 1 5 might be reasonable Each web page served up by Google is approximately 25KB in size you can check by saving the web page So an average person needs 2 x1 5x25 75 KB of data from Google in a day The bandwidth served per day out of Google is therefore 3 mkt share x 7 internet pop x 3 million x 75 KB which is around 48 million MB The bandwidth persecond is then 4 375 Mbits sec note conversion to bits which is basically around 4Gbps If Google has just one data center for whole of US highly unlikely they ll need a OC96 pipe You can calculate how much Google would need to pay for leasing at OC96 link Now finally how many PC s are needed to throw out 4 375Gbps Most PCs today come standard with 1Gbps network interfaces so Google would need only 5 PCs This of course assumes that a PC can sustain peak throughput of 1 Gbps and that all bits put out reach the target A more feasible number I think without getting into the details for this assumption would be more in the range of 1Mbps In this case Google would need around 5 PCs Well analyzing the bandwidth requirement showed a surprising statictic but not something that can be used to accurately guess the number of PCs Google has anywhere between 5 5 Too vague So time to look at another metric Storage In bandwidth requirements I have completely left out another part of the equation the bandwidth needed by Google s crawlers I ll get back to this later Other things that make the bandwidth estimate conservative is that this only looked at search results web pages If you had image search news pages maps Gmail etc the bandwidth requirement will be much much higher Storage Requirement Again lets restrict the discussion to just web pages The analysis here will assume that Google is audacious enough to store all web pages in memory in RAM Search queries follow the usual 8 2 rule i e 8 of queries are for 2 of pages so maintaning a cache of the 2 of most requested pages should work quite well but lets assume Google stores all web pages in RAM The current estimate of the total number of web pages is around 4 billion Lets assume on an average each web page is 1 KB This is pure conjecture but it is something to start working with Also lets assume that each blade uses 2GB of RAM to store web pages So simple math suggests Google should have 4 Billion 1 KB 2GB blades which is approximately 2 blades Why have only 2GB on each blade to store the web pages Well assuming each blade has a maximum of 4GB storage 32 bit machines the remaining 2GB is to do the rest of the stuff like maintaining indexes of their data running page rank algorithm etc And what about redundancy to these in RAM web pages Well that is what the hard drives on each of the blades are for If each balde comes with a 6 GB hard drive then Google has close to 11 Petabytes note not terabytes of slow memory that can be used for backup Gmail etc Links HTML CSS 5 8", "_id": "http://www.ics.uci.edu/~mayur/google_servers.html", "title": "analyzing how many servers google has", "html": "<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"DTD/xhtml1-transitional.dtd\">\r\n<html lang=\"en\">\r\n<head>\r\n\r\n<title>Analyzing how many servers Google has</title>\r\n\r\n<!-- BEGIN META TAG INFO -->\r\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=iso-8859-1\">\r\n<meta name=\"author\" content=\"Mayur Deshpande\">\r\n<link rel=\"index\" href=\"http://www.ics.uci.edu/~mayur/index.html\">\r\n<link rel=\"stylesheet\" type=\"text/css\" href=\"css/fonts.css\" media=\"screen\">\r\n<link rel=\"stylesheet\" type=\"text/css\" href=\"css/print.css\" media=\"print\">\r\n<link rel=\"shortcut icon\" type=\"image/x-icon\" href=\"./images/favicon.ico\">\r\n<link rel=\"stylesheet\" type=\"text/css\" href=\"css/3col.css\" title=\"style\">\r\n<style type=\"text/css\" media=\"all\"></style>\r\n<!-- END META TAG INFO -->\r\n</head>\r\n\r\n\r\n<body>\r\n\r\n<div id=\"banner\">\r\n<h4> Google Servers &nbsp;\r\n</h4>\r\n</div>\r\n\r\n<div id=\"leftcontent\">\r\n<h1>\r\n<a href=\"index.html\"> Home </a>\r\n</h1>\r\n<h1>\r\n<a href=\"Research.html\"> Research </a>\r\n</h1>\r\n<h1>\r\n<a href=\"Software.html\"> Software </a>\r\n</h1>\r\n<h1>\r\n<a href=\"Publications.html\"> Publications </a>\r\n</h1>\r\n<h1>\r\n<a href=\"Industry.html\"> Industry </a>\r\n</h1>\r\n<h1>\r\n<a href=\"Mayur_Resume.pdf\"> Resume </a>\r\n</h1>\r\n<h1>\r\n<a href=\"http://flashback.calit2.uci.edu\"> Flashback! </a>\r\n</h1>\r\n</div>\r\n\r\n\r\n<div id=\"centercontent\">\r\n<h2>::Introduction</h2>\r\n<p>\r\nThis is my attemp to tackle the greatest question of modern times: how many blade PCs does\r\nGoogle run?  The initial guess in 2003 was 10,000 and then recently the consensus seems\r\nto be in the order of 100,000.  But these have remained guesses at best.  Here, I'll try and\r\nsee if this number can be deduced, from various requirements (network BW, storage, CPU, etc..)\r\n</p>\r\n\r\n<h2>::Bandwidth Requirement</h2>\r\n<p>\r\nFirst, let's see how much bandwidth Google might need. Then, we'll divide this by how much BW a PC can\r\nhandle, to get the number of PCs needed.\r\nI'll constrain the analysis to North-America.\r\nSimilar analysis can be done for other geographies.\r\nAgain, since search is the main Bread&Butter of Google, this analysis is restricted to search.\r\n<br>\r\nOK, first some numbers that'll help us.  U.S. pop: 300 million. Internet penetration in US: 70%.\r\nGoogle market share: 30%.\r\n<br>\r\nSo assuming that, on an average, a person using google does 20 searches a day and clicks through 1.5 pages\r\nof results for each search (supposedly 90% of users find the results they want on the first page, so\r\nI think an average of 1.5 might be reasonable).\r\nEach web-page served up by Google is approximately 25KB in size (you can check by saving the web-page).\r\nSo, an average person needs: 20x1.5x25 = 750KB of data from Google in a day.\r\n<br>\r\nThe bandwidth served per day out of Google is therefore, 0.3 (mkt-share) x 0.7 (internet-pop) x\r\n300 million x 750KB\r\n<br>\r\nwhich is around 48 million MB. The bandwidth persecond is then: 4,375 Mbits/sec (note conversion to bits)\r\n<br>\r\nwhich is basically around 4Gbps! If Google has just one data-center for whole of US (highly unlikely),\r\nthey'll need a OC96 pipe. You can calculate how much Google would need\r\nto pay for leasing at OC96 link :)\r\n<br>\r\n<br>\r\nNow, finally, how many PC's are needed to throw out 4.375Gbps?  Most PCs today come standard with 1Gbps\r\nnetwork interfaces, so Google would need only 5 PCs! :)  This, of course assumes that a PC can\r\nsustain peak throughput of 1 Gbps and that all bits put out reach the target. A more feasible\r\nnumber, I think, (without getting into the details for this assumption) would be more in the\r\nrange of 1Mbps. In this case, Google would need around 5,000 PCs.\r\n<br>\r\nWell, analyzing the bandwidth requirement showed a surprising statictic but not something that can be\r\nused to accurately guess (!) the number of PCs Google has: anywhere between 5-5,000? Too vague.\r\nSo time to look at another metric: Storage.\r\n<br>\r\nIn bandwidth requirements, I have completely left out another part of the equation, the bandwidth\r\nneeded by Google's crawlers. I'll get back to this later. Other things that make the bandwidth estimate\r\nconservative is that this only looked at search results web-pages. If you had image-search, news pages,\r\nmaps, Gmail, etc. the bandwidth requirement will be much much higher.\r\n<br>\r\n</p>\r\n\r\n\r\n<h2>::Storage Requirement</h2>\r\n<p>\r\nAgain, lets restrict the discussion to just web-pages. The analysis here will assume that Google is\r\naudacious enough to store all web-pages in-memory (in RAM). Search queries follow the usual 80:20 rule,\r\ni.e. 80% of queries are for 20% of pages, so maintaning a cache of the 20% of most requested pages should\r\nwork quite well, but lets assume Google stores all web-pages in RAM.\r\n<br>\r\nThe current estimate of the total number of web-pages is around 4 billion. Lets assume, on an average, each\r\nweb-page is 100KB. This is pure conjecture but it is something to start working with. Also, lets assume that\r\neach blade uses 2GB of RAM to store web-pages. So simple math suggests Google should have: (4 Billion * 100KB) / 2GB blades\r\nwhich is approximately 200,000 blades.\r\n<br>\r\nWhy have only 2GB on each blade to store the web-pages?  Well, assuming each\r\nblade has a maximum of 4GB storage (32 bit machines), the remaining 2GB is to do the \"rest of the stuff\", like\r\nmaintaining indexes of their data, running page-rank algorithm, etc. And what about redundancy to these in-RAM web-pages.\r\nWell that is what the hard-drives on each of the blades are for. If each balde comes with a 60GB hard-drive, then Google\r\nhas close to 11 Petabytes (note, not terabytes) of 'slow memory' that can be used for backup, Gmail :), etc.\r\n</p>\r\n\r\n\r\n</div>\r\n\r\n\r\n\r\n<div id=\"rightcontent\">\r\n<h2> Links</h2>\r\n<p>\r\n</p>\r\n\r\n</div>\r\n\r\n<script src=\"http://www.google-analytics.com/urchin.js\" type=\"text/javascript\">\r\n</script>\r\n<script type=\"text/javascript\">\r\n_uacct = \"UA-556186-1\";\r\nurchinTracker();\r\n</script>\r\n\r\n\r\n<!-- START INCLUDED FOOTER -->\r\n<center>\r\n<br>\r\n<br>\r\n<br>\r\n<span class=\"G9G\"><a href=\"http://validator.w3.org/check?uri=referer\" title=\"W3C HTML Validation\" target=\"_blank\">HTML</a> &#8226; <a href=\"http://jigsaw.w3.org/css-validator/check/referer/\" title=\"W3C CSS Validation\" target=\"_blank\">CSS</a> &#8226; <a href=\"http://bobby.watchfire.com/\" title=\"U.S. Section 508 Accessibility\" target=\"_blank\">508</a></span>\r\n\r\n<br>\r\n<!-- END INCLUDED FOOTER -->\r\n</body>\r\n</html>\r\n</center>", "id": 24791.0}