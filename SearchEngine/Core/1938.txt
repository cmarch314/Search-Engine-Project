{"text": "ICS 161 Design and Analysis of Algorithms Lecture notes for February 6 1996 Minimum Spanning Trees Spanning trees A spanning tree of a graph is just a subgraph that contains all the vertices and is a tree A graph may have many spanning trees for instance the complete graph on four vertices o o X o o has sixteen spanning trees o o o o o o o o o o o o o o o o o o o o o o o o X X X X o o o o o o o o o o o o o o o o o o o o o o o o o o o o o o o o o o o o o o o o Minimum spanning trees Now suppose the edges of the graph have weights or lengths The weight of a tree is just the sum of weights of its edges Obviously different trees have different lengths The problem how to find the minimum length spanning tree This problem can be solved by many different algorithms It is the topic of some very recent research There are several best algorithms depending on the assumptions you make A randomized algorithm can solve it in linear expected time Karger Klein and Tarjan A randomized linear time algorithm to find minimum spanning trees J ACM vol 42 1995 pp 321 328 It can be solved in linear worst case time if the weights are small integers Fredman and Willard Trans dichotomous algorithms for minimum spanning trees and shortest paths 31st IEEE Symp Foundations of Comp Sci 199 pp 719 725 Otherwise the best solution is very close to linear but not exactly linear The exact bound is O m log beta m n where the beta function has a complicated definition the smallest i such that log log log log n is less than m n where the logs are nested i times Gabow Galil Spencer and Tarjan Efficient algorithms for finding minimum spanning trees in undirected and directed graphs Combinatorica vol 6 1986 pp 1 9 122 These algorithms are all quite complicated and probably not that great in practice unless you re looking at really huge graphs The book tries to keep things simpler so it only describes one algorithm but in my opinion doesn t do a very good job of it I ll go through three simple classical algorithms spending not so much time on each one Why minimum spanning trees The standard application is to a problem like phone network design You have a business with several offices you want to lease phone lines to connect them up with each other and the phone company charges different amounts of money to connect different pairs of cities You want a set of lines that connects all your offices with a minimum total cost It should be a spanning tree since if a network isn t a tree you can always remove some edges and save money A less obvious application is that the minimum spanning tree can be used to approximately solve the traveling salesman problem A convenient formal way of defining this problem is to find the shortest path that visits each point at least once Note that if you have a path visiting all points exactly once it s a special kind of tree For instance in the example above twelve of sixteen spanning trees are actually paths If you have a path visiting some vertices more than once you can always drop some edges to get a tree So in general the MST weight is less than the TSP weight because it s a minimization over a strictly larger set On the other hand if you draw a path tracing around the minimum spanning tree you trace each edge twice and visit all points so the TSP weight is less than twice the MST weight Therefore this tour is within a factor of two of optimal There is a more complicated way Christofides heuristic of using minimum spanning trees to find a tour within a factor of 1 5 of optimal I won t describe this here but it might be covered in ICS 163 graph algorithms next year How to find minimum spanning tree The stupid method is to list all spanning trees and find minimum of list We already know how to find minima But there are far too many trees for this to be efficient It s also not really an algorithm because you d still need to know how to list all the trees A better idea is to find some key property of the MST that lets us be sure that some edge is part of it and use this property to build up the MST one edge at a time For simplicity we assume that there is a unique minimum spanning tree Problem 4 3 of Baase is related to this assumption You can get ideas like this to work without this assumption but it becomes harder to state your theorems or write your algorithms precisely Lemma Let X be any subset of the vertices of G and let edge e be the smallest edge connecting X to G X Then e is part of the minimum spanning tree Proof Suppose you have a tree T not containing e then I want to show that T is not the MST Let e u v with u in X and v not in X Then because T is a spanning tree it contains a unique path from u to v which together with e forms a cycle in G This path has to include another edge f connecting X to G X T e f is another spanning tree it has the same number of edges and remains connected since you can replace any path containing f by one going the other way around the cycle It has smaller weight than t since e has smaller weight than f So T was not minimum which is what we wanted to prove Kruskal s algorithm We ll start with Kruskal s algorithm which is easiest to understand and probably the best one for solving problems by hand Kruskal s algorithm sort the edges of G in increasing order by length keep a subgraph S of G initially empty for each edge e in sorted order if the endpoints of e are disconnected in S add e to S return S Note that whenever you add an edge u v it s always the smallest connecting the part of S reachable from u with the rest of G so by the lemma it must be part of the MST This algorithm is known as a greedy algorithm because it chooses at each step the cheapest edge to add to S You should be very careful when trying to use greedy algorithms to solve other problems since it usually doesn t work E g if you want to find a shortest path from a to b it might be a bad idea to keep taking the shortest edges The greedy idea only works in Kruskal s algorithm because of the key property we proved Analysis The line testing whether two endpoints are disconnected looks like it should be slow linear time per iteration or O mn total But actually there are some complicated data structures that let us perform each test in close to constant time this is known as the union find problem and is discussed in Baase section 8 5 I won t get to it in this class though The slowest part turns out to be the sorting step which takes O m log n time Prim s algorithm Rather than build a subgraph one edge at a time Prim s algorithm builds a tree one vertex at a time Prim s algorithm let T be a single vertex x while T has fewer than n vertices find the smallest edge connecting T to G T add it to T Since each edge added is the smallest connecting T to G T the lemma we proved shows that we only add edges that should be part of the MST Again it looks like the loop has a slow step in it But again some data structures can be used to speed this up The idea is to use a heap to remember for each vertex the smallest edge connecting T with that vertex Prim with heaps make a heap of values vertex edge weight edge initially v infinity for each vertex let tree T be empty while T has fewer than n vertices let v e weight e have the smallest weight in the heap remove v e weight e from the heap add v and e to T for each edge f u v if u is not already in T find value u g weight g in heap if weight f weight g replace u g weight g with u f weight f Analysis We perform n steps in which we remove the smallest element in the heap and at most 2m steps in which we examine an edge f u v For each of those steps we might replace a value on the heap reducing it s weight You also have to find the right value on the heap but that can be done easily enough by keeping a pointer from the vertices to the corresponding values I haven t described how to reduce the weight of an element of a binary heap but it s easy to do in O log n time Alternately by using a more complicated data structure known as a Fibonacci heap you can reduce the weight of an element in constant time The result is a total time bound of O m n log n Boruvka s algorithm Actually Boruvka should be spelled with a small raised circle accent over the u Although this seems a little complicated to explain it s probably the easiest one for computer implementation since it doesn t require any complicated data structures The idea is to do steps like Prim s algorithm in parallel all over the graph at the same time Boruvka s algorithm make a list L of n trees each a single vertex while L has more than one tree for each T in L find the smallest edge connecting T to G T add all those edges to the MST causing pairs of trees in L to merge As we saw in Prim s algorithm each edge you add must be part of the MST so it must be ok to add them all at once Analysis This is similar to merge sort Each pass reduces the number of trees by a factor of two so there are O log n passes Each pass takes time O m first figure out which tree each vertex is in then for each edge test whether it connects two trees and is better than the ones seen before for the trees on either endpoint so the total is O m log n A hybrid algorithm This isn t really a separate algorithm but you can combine two of the classical algorithms and do better than either one alone The idea is to do O log log n passes of Boruvka s algorithm then switch to Prim s algorithm Prim s algorithm then builds one large tree by connecting it with the small trees in the list L built by Boruvka s algorithm keeping a heap which stores for each tree in L the best edge that can be used to connect it to the large tree Alternately you can think of collapsing the trees found by Boruvka s algorithm into supervertices and running Prim s algorithm on the resulting smaller graph The point is that this reduces the number of remove min operations in the heap used by Prim s algorithm to equal the number of trees left in L after Boruvka s algorithm which is O n log n Analysis O m log log n for the first part O m n log n log n O m n for the second so O m log log n total ICS 161 Dept Information Computer Science UC Irvine Last update ", "_id": "http://www.ics.uci.edu/~eppstein/161/960206.html", "title": "minimum spanning trees", "html": "<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 3.2//EN\">\n<html>\n<head>\n<title>Minimum spanning trees</title>\n<meta name=\"Owner\" value=\"eppstein\">\n<meta name=\"Reply-To\" value=\"eppstein@ics.uci.edu\">\n</head>\n<body>\n<h1>ICS 161: Design and Analysis of Algorithms<br>\nLecture notes for February 6, 1996</h1>\n\n<!--#config timefmt=\"%d %h %Y, %T %Z\" -->\n<hr>\n<p></p>\n\n<h1>Minimum Spanning Trees</h1>\n\n<h2>Spanning trees</h2>\n\nA <i>spanning tree</i> of a graph is just a subgraph that contains\nall the vertices and is a tree. A graph may have many spanning\ntrees; for instance the complete graph on four vertices \n\n<pre>\n    o---o\n    |\\ /|\n    | X |\n    |/ \\|\n    o---o\n</pre>\n\nhas sixteen spanning trees: \n\n<pre>\n    o---o    o---o    o   o    o---o\n    |   |    |        |   |        |\n    |   |    |        |   |        |\n    |   |    |        |   |        |\n    o   o    o---o    o---o    o---o\n\n    o---o    o   o    o   o    o   o\n     \\ /     |\\ /      \\ /      \\ /|\n      X      | X        X        X |\n     / \\     |/ \\      / \\      / \\|\n    o   o    o   o    o---o    o   o\n\n    o   o    o---o    o   o    o---o\n    |\\  |       /     |  /|     \\\n    | \\ |      /      | / |      \\\n    |  \\|     /       |/  |       \\\n    o   o    o---o    o   o    o---o\n\n    o---o    o   o    o   o    o---o\n    |\\       |  /      \\  |       /|\n    | \\      | /        \\ |      / |\n    |  \\     |/          \\|     /  |\n    o   o    o---o    o---o    o   o\n</pre>\n\n<h2>Minimum spanning trees</h2>\n\nNow suppose the edges of the graph have weights or lengths. The\nweight of a tree is just the sum of weights of its edges.\nObviously, different trees have different lengths. The problem: how\nto find the minimum length spanning tree? \n\n<p>This problem can be solved by many different algorithms. It is\nthe topic of some very recent research. There are several \"best\"\nalgorithms, depending on the assumptions you make:</p>\n\n<ul>\n<li>A randomized algorithm can solve it in linear expected time.\n[Karger, Klein, and Tarjan, \"A randomized linear-time algorithm to\nfind minimum spanning trees\", J. ACM, vol. 42, 1995, pp.\n321-328.]</li>\n\n<li>It can be solved in linear worst case time if the weights are\nsmall integers. [Fredman and Willard, \"Trans-dichotomous algorithms\nfor minimum spanning trees and shortest paths\", 31st IEEE Symp.\nFoundations of Comp. Sci., 1990, pp. 719--725.] <a name=\"beta\">\n</a></li>\n\n<li>Otherwise, the best solution is very close to linear but not\nexactly linear. The exact bound is O(m log beta(m,n)) where the\nbeta function has a complicated definition: the smallest i such\nthat log(log(log(...log(n)...))) is less than m/n, where the logs\nare nested i times. [Gabow, Galil, Spencer, and Tarjan, Efficient\nalgorithms for finding minimum spanning trees in undirected and\ndirected graphs. Combinatorica, vol. 6, 1986, pp. 109--122.]</li>\n</ul>\n\nThese algorithms are all quite complicated, and probably not that\ngreat in practice unless you're looking at really huge graphs. The\nbook tries to keep things simpler, so it only describes one\nalgorithm but (in my opinion) doesn't do a very good job of it.\nI'll go through three simple classical algorithms (spending not so\nmuch time on each one). \n\n<h2>Why minimum spanning trees?</h2>\n\n<a name=\"phone\">The standard application is to a problem like phone\nnetwork design. You have a business with several offices; you want\nto lease phone lines to connect them up with each other; and the\nphone company charges different amounts of money to connect\ndifferent pairs of cities. You want a set of lines that connects\nall your offices with a minimum total cost. It should be a spanning\ntree, since if a network isn't a tree you can always remove some\nedges and save money.</a> \n\n<p><a name=\"tsp\">A less obvious application is that the minimum\nspanning tree can be used to approximately solve the traveling\nsalesman problem. A convenient formal way of defining this problem\nis to find the shortest path that visits each point at least\nonce.</a></p>\n\n<p>Note that if you have a path visiting all points exactly once,\nit's a special kind of tree. For instance in the example above,\ntwelve of sixteen spanning trees are actually paths. If you have a\npath visiting some vertices more than once, you can always drop\nsome edges to get a tree. So in general the MST weight is less than\nthe TSP weight, because it's a minimization over a strictly larger\nset.</p>\n\n<p><a name=\"chris\">On the other hand, if you draw a path tracing\naround the minimum spanning tree, you trace each edge twice and\nvisit all points, so the TSP weight is less than twice the MST\nweight. Therefore this tour is within a factor of two of optimal.\nThere is a more complicated way (<i><a href= \n\"people.html#christofides\">Christofides</a>' heuristic</i>) of\nusing minimum spanning trees to find a tour within a factor of 1.5\nof optimal; I won't describe this here but it might be covered in\nICS 163 (graph algorithms) next year.</a></p>\n\n<h2>How to find minimum spanning tree?</h2>\n\nThe stupid method is to list all spanning trees, and find minimum\nof list. We already know how to find minima... But there are far\ntoo many trees for this to be efficient. It's also not really an\nalgorithm, because you'd still need to know how to list all the\ntrees. \n\n<p>A better idea is to find some key property of the MST that lets\nus be sure that some edge is part of it, and use this property to\nbuild up the MST one edge at a time.</p>\n\n<p>For simplicity, we assume that there is a unique minimum\nspanning tree. (Problem 4.3 of Baase is related to this\nassumption). You can get ideas like this to work without this\nassumption but it becomes harder to state your theorems or write\nyour algorithms precisely.</p>\n\n<blockquote>Lemma: Let X be any subset of the vertices of G, and\nlet edge e be the smallest edge connecting X to G-X. Then e is part\nof the minimum spanning tree. \n\n<p>Proof: Suppose you have a tree T not containing e; then I want\nto show that T is not the MST. Let e=(u,v), with u in X and v not\nin X. Then because T is a spanning tree it contains a unique path\nfrom u to v, which together with e forms a cycle in G. This path\nhas to include another edge f connecting X to G-X. T+e-f is another\nspanning tree (it has the same number of edges, and remains\nconnected since you can replace any path containing f by one going\nthe other way around the cycle). It has smaller weight than t since\ne has smaller weight than f. So T was not minimum, which is what we\nwanted to prove.</p>\n</blockquote>\n\n<h2>Kruskal's algorithm</h2>\n\nWe'll start with <a href=\"people.html#kruskal\">Kruskal</a>'s\nalgorithm, which is easiest to understand and probably the best one\nfor solving problems by hand. \n\n<pre>\n    Kruskal's algorithm:\n    sort the edges of G in increasing order by length\n    keep a subgraph S of G, initially empty\n    for each edge e in sorted order\n        if the endpoints of e are disconnected in S\n        add e to S\n    return S\n</pre>\n\nNote that, whenever you add an edge (u,v), it's always the smallest\nconnecting the part of S reachable from u with the rest of G, so by\nthe lemma it must be part of the MST. \n\n<p>This algorithm is known as a <i>greedy algorithm</i>, because it\nchooses at each step the cheapest edge to add to S. You should be\nvery careful when trying to use greedy algorithms to solve other\nproblems, since it usually doesn't work. E.g. if you want to find a\nshortest path from a to b, it might be a bad idea to keep taking\nthe shortest edges. The greedy idea only works in Kruskal's\nalgorithm because of the key property we proved.</p>\n\n<p><a name=\"uf\">Analysis: The line testing whether two endpoints\nare disconnected looks like it should be slow (linear time per\niteration, or O(mn) total). But actually there are some complicated\ndata structures that let us perform each test in close to constant\ntime; this is known as the <i>union-find</i> problem and is\ndiscussed in Baase section 8.5 (I won't get to it in this class,\nthough). The slowest part turns out to be the sorting step, which\ntakes O(m log n) time.</a></p>\n\n<h2>Prim's algorithm</h2>\n\nRather than build a subgraph one edge at a time, <a href= \n\"people.html#prim\">Prim</a>'s algorithm builds a tree one vertex at\na time. \n\n<pre>\n    Prim's algorithm:\n    let T be a single vertex x\n    while (T has fewer than n vertices)\n    {\n        find the smallest edge connecting T to G-T\n        add it to T\n    }\n</pre>\n\nSince each edge added is the smallest connecting T to G-T, the\nlemma we proved shows that we only add edges that should be part of\nthe MST. \n\n<p>Again, it looks like the loop has a slow step in it. But again,\nsome data structures can be used to speed this up. The idea is to\nuse a <a href=\"960116.html#binheap\">heap</a> to remember, for each\nvertex, the smallest edge connecting T with that vertex.</p>\n\n<pre>\n    Prim with heaps:\n    make a heap of values (vertex,edge,weight(edge))\n        initially (v,-,infinity) for each vertex\n        let tree T be empty\n    while (T has fewer than n vertices)\n    {\n        let (v,e,weight(e)) have the smallest weight in the heap\n        remove (v,e,weight(e)) from the heap\n        add v and e to T\n        for each edge f=(u,v)\n        if u is not already in T\n            find value (u,g,weight(g)) in heap\n            if weight(f) &lt; weight(g)\n            replace (u,g,weight(g)) with (u,f,weight(f))\n    }\n</pre>\n\n<a name=\"fib\">Analysis: We perform n steps in which we remove the\nsmallest element in the heap, and at most 2m steps in which we\nexamine an edge f=(u,v). For each of those steps, we might replace\na value on the heap, reducing it's weight. (You also have to find\nthe right value on the heap, but that can be done easily enough by\nkeeping a pointer from the vertices to the corresponding values.) I\nhaven't described how to reduce the weight of an element of a\nbinary heap, but it's easy to do in O(log n) time. Alternately by\nusing a more complicated data structure known as a Fibonacci heap,\nyou can reduce the weight of an element in constant time. The\nresult is a total time bound of O(m + n log n).</a>\n<h2>Boruvka's algorithm</h2>\n\n(Actually <a href=\"people.html#boruvka\">Boruvka</a> should be\nspelled with a small raised circle accent over the \"u\".) Although\nthis seems a little complicated to explain, it's probably the\neasiest one for computer implementation since it doesn't require\nany complicated data structures. The idea is to do steps like\nPrim's algorithm, in parallel all over the graph at the same time. \n\n<pre>\n    Boruvka's algorithm:\n    make a list L of n trees, each a single vertex\n    while (L has more than one tree)\n        for each T in L, find the smallest edge connecting T to G-T\n        add all those edges to the MST\n        (causing pairs of trees in L to merge)\n</pre>\n\nAs we saw in Prim's algorithm, each edge you add must be part of\nthe MST, so it must be ok to add them all at once. \n\n<p>Analysis: This is similar to merge sort. Each pass reduces the\nnumber of trees by a factor of two, so there are O(log n) passes.\nEach pass takes time O(m) (first figure out which tree each vertex\nis in, then for each edge test whether it connects two trees and is\nbetter than the ones seen before for the trees on either endpoint)\nso the total is O(m log n).</p>\n\n<h2>A hybrid algorithm</h2>\n\nThis isn't really a separate algorithm, but you can combine two of\nthe classical algorithms and do better than either one alone. The\nidea is to do O(log log n) passes of Boruvka's algorithm, then\nswitch to Prim's algorithm. Prim's algorithm then builds one large\ntree by connecting it with the small trees in the list L built by\nBoruvka's algorithm, keeping a heap which stores, for each tree in\nL, the best edge that can be used to connect it to the large tree.\nAlternately, you can think of collapsing the trees found by\nBoruvka's algorithm into \"supervertices\" and running Prim's\nalgorithm on the resulting smaller graph. The point is that this\nreduces the number of remove min operations in the heap used by\nPrim's algorithm, to equal the number of trees left in L after\nBoruvka's algorithm, which is O(n / log n). \n\n<p>Analysis: O(m log log n) for the first part, O(m + (n/log n) log\nn) = O(m + n) for the second, so O(m log log n) total.</p>\n\n<hr>\n<p><a href=\"/~eppstein/161/\">ICS 161</a> -- <a href=\"/\">Dept.\nInformation &amp; Computer Science</a> -- <a href= \n\"http://www.uci.edu/\">UC Irvine</a><br>\n<small>Last update: \n<!--#flastmod file=\"960206.html\" --></small></p>\n</body>\n</html>\n\n", "id": 1938.0}