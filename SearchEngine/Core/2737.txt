{"text": "Code Packages KDE Toolbox Event Detection Adaptive Inference Gaussian Process Regression with Time shifts Kernel Density Estimation Toolbox for MATLAB R13 MATLAB KDE Class Description The KDE class is a general matlab class for k dimensional kernel density estimation It is written in a mix of matlab m files and MEX C code Thus to use it you will need to be able to compile C code for Matlab Note that the default compiler for Windows does not support C so you will need GCC under Linux or GCC or Visual C for Windows Bloodshed supplies a nice development environment along with the MinGW compiler See this page for help setting up MEX with MinGW NOTE Since several compiled mexglx and dll files are included you may not need to re compile the toolbox at all however I recommend it if possible for compatibility reasons Kernels supported are GaussianEpanetchnikov truncated quadratic Laplacian Double exponential For multivariate density estimates the code supports product kernels kernels which are products of the kernel function in each dimension For example for Gaussian kernels this is equivalent to requiring a diagonal covariance It can also support non uniform kernel bandwidths i e bandwidths which vary over kernel centers The implementation uses kd trees a heirarchical representation for point sets which caches sufficient statistics about point locations etc in order to achieve potential speedups in computation For the Epanetchnikov kernel this can translate into speedups with no loss of precision but for kernels with infinite support it provides an approximation tolerance level which allows tradeoffs between evaluation quality and computation speed In particular we implement Alex Gray s Dual Tree evaluation algorithm see Gray and Moore Very Fast Multivariate Kernel Density Estimation using via Computational Geometry in Proceedings Joint Stat Meeting 2 3 for more details This gives a tolerance parameter which is a percent error from the exact N 2 computation on the value at any evaluated point In general tolerance parameters in the matlab code notes refers to this percent tolerance This percentage error translates to an absolute additive error on the mean log likelihood for example An exception to this is the gradient calcuation functions which calculate using an absolute tolerance value This is due to the difficulty of finding a percentage bound when the function calculated is not strictly positive We have also recently implemented the so called Improved Fast Gauss Transform described in Yang Duraiswami and Gumerov Improved Fast Gauss Transform submitted to the Siam Journal of Scientific Computing This often performs MUCH faster than the dual tree algorithm mentioned above but the error bounds which control the computation are often quite loose and somewhat unwieldy for example it is difficult to obtain the fractional error bounds provided used by the dual tree methods and other functions in the KDE toolbox Thus for the moment we have left the IFGT separate with alternate controls for computational complexity see below and the file evalIFGT m Getting Started Download and unzip the KDE class to a directory called kde If desired Compile the MEX functions This can be done by going to the kde mex directory in Matlab and copying and pasting the code from the makemex m file into the Matlab window If this fails make sure that MEX C compilation works The KDE toolbox is tested in Matlab R13 and later it may work in ealier versions as well Re compiling may not be required depending on your platform and version mexglx Linux 32 bit mexa64 Linux 64 bit and dll Windows 32 bit files are included If you have trouble recompile Thanks to Ankur Datta for compiling Mac versions of the MEX files and making them available I do not even own a Mac and cannot vouch for their operation etc use at your own risk NOTE MS Visual C has a bug in dealing with static const variables I think there is a patch available or you can change these to defines Operate from the class parent directory or add it to your MATLAB path e g if you unzip to myhome kde cd in matlab to the myhome dir or add it to the path Objects of type KDE may be created by e g p kde rand 2 1 5 3 Gaussian kernel 2D BW 5 in dim 1 3 in dim 2 p kde rand 2 1 5 ones 1 1 Same as above but uniform BW and specifying weights p kde rand 2 1 5 ones 1 1 Epanetchnikov Quadratic kernel just E or e also works p kde rand 2 1 rot Gaussian kernel 2D BW chosen by rule of thumb below To see the kernel shape types you can use plot 3 1 3 evaluate kde 1 1 T 3 1 3 where T G E or L Kernel sizes may be selected automatically using e g p ksize p lcv 1D Likelihood based search for BW p ksize p rot Rule of Thumb Silverman 86 Scott 92 p ksize p hall Plug in type estimator estimates each dim separately Density estimates may be visualized using e g plot p or mesh hist p See help kde plot and help kde hist for more information Also the demonstration programs kde examples demo kde m may be helpful Usage Examples The demonstration programs in kde examples demo kde m where is one of 1 2 3 may be helpful KDE Matlab class definition The following is a simple list of all accessible functions for the KDE class Use help functionname in Matlab for more information Constructors kde empty kde kde kde re construct kde from points weights bw etc kde points bw construct Gauss kde with weights 1 N kde points bw weights construct Gaussian kde kde points bw weights type potentially non Gaussian marginal kde dim marginalize to the given dimensions condition kde dim A marginalize to dim and weight by K x i dim a dim resample kde kstype draw N samples from kde use to construct a new kdereduce kde construct a reduced density estimate fewer points joinTrees t1 t2 make a new tree with t1 and t2 as the children of a new root node Accessors data access extremely limited or no processing req d getType kde return the kernel type of the KDE Gaussian etc getDimget the dimension of the data getNpts get the of kernel locationsgetNeff effective of kernels accounts for non uniform weights getPoints kde Ndim x Npoints array of kernel locations adjustPoints p delta shift points of P by delta by reference rescale kde alpha rescale a KDE by the vector alpha getBW kde index return the bandwidth assoc with x i Ndim x length index adjustBW kde newBW set the bandwidth s of the KDE by reference Note cannot change from a uniform non uniform bandwidth ksizeautomatic bandwidth selection via a number of methods LCV1D search using max leave one out likelihood criterion HALL HJSMPlug in estimator with good asymptotics MISE criterion ROT MSPFast standard deviaion based methods AMISE criterion LOCALLike LCV but makes BW propto k th NN distance k sqrt N getWeights 1 x Npts array of kernel weights adjustWeightsset kernel weights by reference sample P Np KSType draw Np new samples from P and set BW according to KSType Display visualization description plot kde plot the specified dimensions of the KDE locationshist kde discretize the kde at uniform bin lengths display text output describing the KDEdoubleboolean evaluation of the KDE non empty Statistics useful stats operations on a kde meanfind the weighted mean of the kernel centers covarfind the weighted covariance of the kernel centers knn kde points k find the k nearest neighbors of each of points in kde entropyestimate the entropy of the KDE kldestimate divergence between two KDEs evaluate kde x tol evaluate KDE at a set of points x evaluate p p2 tol same as above x p2 pts if we ve already built a tree evalIFGT kde x N evaluate using the N term IFGT requires uniform BW Gaussian kernels evalIFGT p p2 N evalAvgLogL kde x compute Mean log evaluate kde x evalAvgLogL kde kde2 same as above but use the weights of kde2 evalAvgLogL kde self eval leave one out option llGrad kde kde2 estimate the gradient of log likelihood for kde evaluated at the points of kde2 entropyGrad p estimate gradient of entropy uses llGrad miGrad p dim estimate gradient for mutual information between p dim p dim klGrad p1 p2 estimate gradient direction of KL divergence Mixture products NBP stuff GAUSSIAN KERNELS ONLY productExactexact computation N d kernel centers productApproxaccessor for other product sampling methods prodSampleExactsample N points exactly N d computation prodSampleEpsilonkd tree epsilon exact sampler prodSampleGibbs1seq index gibbs sampler prodSampleGibbs2product of experts gibbs sampler prodSampleGibbsMS1multiresolution version of GS1 prodSampleGibbsMS2multiresolution version of GS2 prodSampleImportance mixture importance sampling prodSampleImportGaussgaussian importance sampling COPYRIGHT LICENSE The kde package and all code were written by Alex Ihler and Mike Mandel and are copyrighted under the lesser GPL Copyright C 2 3 Alexander Ihler This program is free software you can redistribute it and or modify it under the terms of the GNU Lesser General Public License as published by the Free Software Foundation version 2 1 or later This program is distributed in the hope that it will be useful but WITHOUT ANY WARRANTY without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE See the GNU Lesser General Public License for more details You should have received a copy of the GNU Lesser General Public License along with this program if not write to the Free Software Foundation Inc 59 Temple Place Suite 33 Boston MA 2111 13 7 USA The authors may be contacted via email at ihler at alum mit edu CHANGELOG CHANGE LOG FOR KERNEL DENSITY ESTIMATION CLASS 8 14 7 ATI Fixed 64 bit support for productApprox functions bugfix 7 16 7 ATI Fixed 64 bit support for most functions 1 8 4 ATI Added support for LOO estimate in llGrad fixed computation of norm constant for LOO version of evaluate 11 22 4 ATI Added original Fast Gauss Transform Greengard Strain 91 using newer correct error bound of Baxter Roussos 2 11 9 4 ATI Fixed bug in IFGT eval incorrect scale factor 1 2 4 ATI Added support for Yang Duraiswami and Gumerov s Improved Fast Gauss Transform Extremely fast loose bounds on absolute error 9 17 4 ATI Fixed permutation bug in adjustBW and bug in llGrad for evals between two distributions Added explicit discrete resampling 8 4 4 ATI Updated productApprox import reduceKD added ISE type to reduceKD 7 9 4 ATI Fixed small bugs condition m jointrees m productExact m Improved speed of sample m 2 19 4 ATI Added llHess Hessian and modes mode finding functions 1 29 4 ATI fixed vs 1 base err in index ret n values of productApprox 1 22 4 ATI Added ise method and epsilon exact MEX implementation Fixed bug in epsilon and exact products of variable BW densities Improved implementation of condition for fixed BW densities 12 28 3 ATI Removed abs KL method replaced with ise estimate method abs was not a good est of KL but served as an est of ISE 12 13 3 ATI Fixed bug in KNN function and some bugs with the reduce f n kld Added some example demonstration functions 12 5 3 ATI Added reduce function Fixed bug in productExact thanks Chunhua Shen Fixed bug in adjustBW caused crashing or termination 11 18 3 ATI Added support for additional KL divergence estimates 1 28 3 ATI Added support for kde pts kstype constructor 1 24 3 ATI Fixed an error in adjustWeights added mex dll files to tarfile", "_id": "http://www.ics.uci.edu/~ihler/code/kde.html", "title": "", "html": "<html>\n<head>\n<link rel=\"stylesheet\" type=\"text/css\" href=\"../ihler.css\">\n</head>\n\n<body>\n<div id=\"navleft\">\r\n<CENTER>\r\n   <H2>Code Packages</H2>\r\n</CENTER>\r\n<HR noShade>\r\n<p style=\"text-indent:-1em; margin-left:1em\">\r\n<a href=\"kde.html\">KDE Toolbox</a>\r\n<p style=\"text-indent:-1em; margin-left:1em\">\r\n<a href=\"event.html\">Event Detection</a>\r\n<p style=\"text-indent:-1em; margin-left:1em\">\r\n<a href=\"adaptive.html\">Adaptive Inference</a>\r\n<p style=\"text-indent:-1em; margin-left:1em\">\r\n<a href=\"http://sli.ics.uci.edu/Code/GPRTimeshift/\">Gaussian Process Regression with Time-shifts</a>\r\n</p>\r\n<hr noShade>\r\n</div>\r\n<div class=\"content\">\n\n<head>\n<LINK rel=\"stylesheet\" type=\"text/css\" href=\"../ihler.css\">\n</head>\n\n<font face=\"Arial, Helvetica, sans-serif\" size=5 color=\"#000000\"> \nKernel Density Estimation Toolbox for MATLAB (R13) </font><br><br>\n<h1>MATLAB KDE Class Description</h1>\n<p>The KDE class is a general matlab class for k-dimensional kernel density estimation. \n  It is written in a mix of matlab \".m\" files and MEX/C++ code. Thus, to use it \n  you will need to be able to compile C++ code for Matlab. Note that the default \n  compiler for Windows does <b>not</b> support C++, so you will need GCC under \n  Linux, or GCC or Visual C++ for Windows. <a href=http://www.bloodshed.net>Bloodshed</a> \n  supplies a nice development environment along with the <a href=\"http://www.mingw.org\">MinGW</a> \n  compiler. See <a target=\"_top\" href=\"http://gnumex.sourceforge.net/\">this page</a> for help setting up\n  MEX with MinGW.</p>\n<p>[NOTE: Since several compiled mexglx and dll files are included, you may not need to re-compile the toolbox at all; however, I recommend it if possible for compatibility reasons.]</p>\n<p>Kernels supported are: </p>\n<ul>\n  <li><p>Gaussian</p></li>\n  <li><p>Epanetchnikov (truncated quadratic)</p></li>\n  <li><p>Laplacian (Double-exponential)</p></li>\n</ul>\n<p>For multivariate density estimates, the code supports product kernels -- kernels \n  which are products of the kernel function in each dimension. For example, for \n  Gaussian kernels this is equivalent to requiring a diagonal covariance. It can \n  also support non-uniform kernel bandwidths -- i.e. bandwidths which vary over \n  kernel centers. </p>\n<p>The implementation uses \"kd-trees\", a heirarchical representation for point \n  sets which caches sufficient statistics about point locations etc. in order \n  to achieve potential speedups in computation. For the Epanetchnikov kernel this \n  can translate into speedups with no loss of precision; but for kernels with \n  infinite support it provides an approximation tolerance level, which allows \n  tradeoffs between evaluation quality and computation speed. In particular, we \n  implement Alex Gray's \"Dual Tree\" evaluation algorithm; see <it><i>Gray and \n  Moore, \"Very Fast Multivariate Kernel Density Estimation using via Computational \n  Geometry\", in Proceedings, Joint Stat. Meeting 2003</i></it> for more details. \n  This gives a tolerance parameter which is a percent error (from the exact, N^2 \n  computation) on the value at any evaluated point. In general, \"tolerance\" parameters \n  in the matlab code / notes refers to this percent tolerance. This percentage \n  error translates to an absolute additive error on the mean log-likelihood, for \n  example. An exception to this is the gradient calcuation functions, which calculate \n  using an absolute tolerance value. This is due to the difficulty of finding \n  a percentage bound when the function calculated is not strictly positive. </p>\n<p> We have also recently implemented the so-called Improved Fast Gauss Transform,\n  described in [Yang, Duraiswami, and Gumerov, \"Improved Fast Gauss Transform\",\n  submitted to the Siam Journal of Scientific Computing].  This often performs\n  MUCH faster than the dual tree algorithm mentioned above, but the error bounds\n  which control the computation are often quite loose, and somewhat unwieldy\n  (for example, it is difficult to obtain the fractional error bounds provided & \n  used by the dual tree methods and other functions in the KDE toolbox).  Thus \n  for the moment we have left the IFGT separate, with alternate controls for \n  computational complexity (see below, and the file \"evalIFGT.m\").  </p>\n<p></p>\n<p></p>\n<p></p>\n<p></p>\n<p></p>\n\n\n<h1>Getting Started </h1>\n\n<p> <a href=\"kde.tar.gz\">Download</a> and unzip the KDE class to a directory called <tt>@kde</tt>. </p>\n\n<p> (If desired) Compile the MEX functions. This can be done by going to the\n  \"@kde/mex\" directory in Matlab, and <b>copying and pasting</b> the code from \n  the \"<tt>makemex.m</tt>\" file into the Matlab window.  If this fails, make \n  sure that MEX / C++ compilation works. The KDE toolbox is tested in Matlab R13 \n  and later; it may work in ealier versions as well. \n  Re-compiling may not be required, depending on your platform and version;\n  \"mexglx\" (Linux 32-bit), \"mexa64\" (Linux 64-bit), and \"dll\" (Windows 32-bit)\n  files are included.  If you have trouble, recompile.</p>\n\n<p> Thanks to Ankur Datta for compiling <a href=\"kde.mac.zip\">Mac versions of the MEX files</a> and making them\navailable.  (I do not even own a Mac and cannot vouch for their operation, etc.; use at your own risk.)\n\n<p> NOTE: MS Visual C++ has a bug in dealing with \"static const\" variables; I\n      think there is a patch available, or you can change these to #defines.</p>\n\n<p>  Operate from the class' parent directory, or add it to your MATLAB path\n    (e.g. if you unzip to \"myhome/@kde\", cd in matlab to the \"myhome\" dir,\n     or add it to the path.) </p>\n\n<p> Objects of type KDE may be created by e.g. </p>\n<blockquote> \n  <p><tt>p = kde( rand(2,1000), [.05;.03] );</tt> % Gaussian kernel, 2D % BW = \n    .05 in dim 1, .03 in dim 2. </p>\n  <p><tt>p = kde( rand(2,1000), .05, ones(1,1000) );</tt> % Same as above, but \n    uniform BW and % specifying weights </p>\n  <p><tt>p = kde( rand(2,1000), .05, ones(1,1000), 'Epanetchnikov');</tt> % Quadratic \n    kernel; just 'E' or 'e' also works </p>\n  <p><tt>p = kde( rand(2,1000), 'rot' );</tt> % Gaussian kernel, 2D, BW chosen \n    by \"rule of thumb\" (below) </p>\n</blockquote>\n<p> To see the kernel shape types, you can use: </p>\n<blockquote> \n  <p><tt>plot(-3:.01:3, evaluate(kde(0,1,1,T),-3:.01:3) );</tt> % where T = 'G', \n    'E', or 'L' </p>\n</blockquote>\n<p> Kernel sizes may be selected automatically using e.g. </p>\n<blockquote> \n  <p><tt>p = ksize(p, 'lcv');</tt> % 1D Likelihood-based search for BW </p>\n  <p><tt>p = ksize(p, 'rot');</tt> % \"Rule of Thumb\"; Silverman '86 / Scott '92 \n  </p>\n  <p><tt>p = ksize(p, 'hall');</tt> % Plug-in type estimator (estimates each dim. \n    separately) </p>\n</blockquote>\n<p> Density estimates may be visualized using e.g. </p>\n<blockquote> \n  <p><tt>plot(p); </tt> </p>\n</blockquote>\n<p> or </p>\n<blockquote>\n  <p><tt>mesh(hist(p));</tt> </p>\n</blockquote>\n<p> See &quot;<tt>help kde/plot</tt>&quot; and &quot;<tt>help kde/hist</tt>&quot; \n  for more information. </p>\n<p> Also, the demonstration programs<tt> @kde/examples/demo_kde_#.m</tt> may be \n  helpful. </p>\n<p></p>\n<p></p>\n<p></p>\n<p></p>\n<p></p>\n\n\n\n<h1>Usage Examples </h1>\n<p>The demonstration programs in <code>@kde/examples/demo_kde_#.m</code> (where <code>#</code> \nis one of <code>1,2,3</code>) may be helpful. </p>\n<p></p>\n<p></p>\n<p></p>\n<p></p>\n<p></p>\n\n\n\n<h1> KDE Matlab class definition </h1>\n<p>The following is a simple list of all accessible functions for the KDE class. \nUse &quot;<tt>help functionname</tt>&quot; in Matlab for more information. </p>\n<p></p>\n<p><b><font size=\"+1\">Constructors:</font></b> </p>\n<table width=\"90%\" border=\"1\" cellspacing=\"0\" cellpadding=\"2\">\n  <tr> \n    <td width=\"23%\"><p>kde( )</td>\n    <td width=\"77%\"><p>empty kde </td>\n  </tr>\n  <tr> \n    <td width=\"23%\"><p>kde( kde )</td>\n    <td width=\"77%\"><p>re-construct kde from points, weights, bw, etc.</td>\n  </tr>\n  <tr> \n    <td width=\"23%\"><code>kde( points, bw )</code></td>\n    <td width=\"77%\"><p>construct Gauss kde with weights 1/N</p> </td>\n  </tr>\n  <tr> \n    <td width=\"23%\"><code>kde( points, bw, weights)</code></td>\n    <td width=\"77%\"><p> construct Gaussian kde</p> </td>\n  </tr>\n  <tr> \n    <td width=\"23%\"><code>kde( points, bw, weights,type)</code></td>\n    <td width=\"77%\"><p>potentially non-Gaussian</p> </td>\n  </tr>\n  <tr> \n    <td width=\"23%\"><code>marginal( kde, dim)</code></td>\n    <td width=\"77%\"><p>marginalize to the given dimensions</p> </td>\n  </tr>\n  <tr> \n    <td width=\"23%\"><code>condition( kde, dim, A)</code></td>\n    <td width=\"77%\"><p>marginalize to ~dim and weight by K(x_i(dim),a(dim))</p> </td>\n  </tr>\n  <tr> \n    <td width=\"23%\"><code>resample( kde, [kstype] )</code></td>\n    <td width=\"77%\"><p>draw N samples from kde & use to construct a new kde</p></td>\n  </tr>\n  <tr> \n    <td width=\"23%\"><code>reduce( kde, ...)</code></td>\n    <td width=\"77%\"><p>construct a \"reduced\" density estimate (fewer points)</p></td>\n  </tr>\n  <tr>\n    <td width=\"23%\"><code>joinTrees( t1, t2 )</code></td>\n    <td width=\"77%\"><p>make a new tree with t1 and t2 as the children of a new root \n      node</p></td>\n  </tr>\n</table>\n<p> </p>\n<p></p>\n<p><b><font size=\"+1\">Accessors: (data access, extremely limited or no processing \n  req'd)</font></b> </p>\n<table width=\"90%\" border=\"1\" cellspacing=\"0\" cellpadding=\"2\">\n  <tr> \n    <td height=\"24\" colspan=\"2\"><code>getType(kde)</code></td>\n    <td width=\"79%\" height=\"24\"><p>return the kernel type of the KDE ('Gaussian', \n      etc)</p> </td>\n  </tr>\n  <tr> \n    <td colspan=\"2\">&nbsp;</td>\n    <td width=\"79%\">&nbsp;</td>\n  </tr>\n  <tr> \n    <td colspan=\"2\"><code>getDim</code></td>\n    <td width=\"79%\"><p>get the dimension of the data</p> </td>\n  </tr>\n  <tr> \n    <td colspan=\"2\"><code>getNpts</code></td>\n    <td width=\"79%\"><p> get the # of kernel locations</p></td>\n  </tr>\n  <tr> \n    <td colspan=\"2\"><code>getNeff</code></td>\n    <td width=\"79%\"><p>\"effective\" # of kernels (accounts for non-uniform weights)</p> \n    </td>\n  </tr>\n  <tr> \n    <td colspan=\"2\">&nbsp;</td>\n    <td width=\"79%\">&nbsp;</td>\n  </tr>\n  <tr> \n    <td colspan=\"2\"><code>getPoints(kde)</code></td>\n    <td width=\"79%\"><p>Ndim x Npoints array of kernel locations</p> </td>\n  </tr>\n  <tr> \n    <td colspan=\"2\"><code>adjustPoints(p,delta)</code></td>\n    <td width=\"79%\"><p>shift points of P by delta (by reference!)</p> </td>\n  </tr>\n  <tr> \n    <td colspan=\"2\"><code>rescale(kde,alpha)</code></td>\n    <td width=\"79%\"><p>rescale a KDE by the (vector) alpha</p> </td>\n  </tr>\n  <tr> \n    <td colspan=\"2\">&nbsp;</td>\n    <td width=\"79%\">&nbsp;</td>\n  </tr>\n  <tr> \n    <td colspan=\"2\"><code>getBW(kde,index)</code></td>\n    <td width=\"79%\"><p>return the bandwidth assoc. with x_i (Ndim x length(index))</p></td>\n  </tr>\n  <tr> \n    <td colspan=\"2\"><code>adjustBW(kde,newBW)</code></td>\n    <td width=\"79%\"><p>set the bandwidth(s) of the KDE (by reference!) <i>Note: cannot \n      change from a uniform -> non-uniform bandwidth</i></p> </td>\n  </tr>\n  <tr> \n    <td colspan=\"2\"><code>ksize</code></td>\n    <td width=\"79%\"><p>automatic bandwidth selection via a number of methods</p> </td>\n  </tr>\n  <tr> \n    <td width=\"2%\">&nbsp;</td>\n    <td width=\"19%\"><code>LCV</code></td>\n    <td width=\"79%\"><p>1D search using max leave-one-out likelihood criterion</p></td>\n  </tr>\n  <tr> \n    <td width=\"2%\">&nbsp;</td>\n    <td width=\"19%\"><code>HALL, HJSM</code></td>\n    <td width=\"79%\"><p>Plug-in estimator with good asymptotics; MISE criterion </p></td>\n  </tr>\n  <tr> \n    <td width=\"2%\">&nbsp;</td>\n    <td width=\"19%\"><code>ROT, MSP</code></td>\n    <td width=\"79%\"><p>Fast standard-deviaion based methods; AMISE criterion </p></td>\n  </tr>\n  <tr> \n    <td width=\"2%\">&nbsp;</td>\n    <td width=\"19%\"><code>LOCAL</code></td>\n    <td width=\"79%\"><p>Like LCV, but makes BW propto k-th NN distance (k=sqrt(N))</p> \n    </td>\n  </tr>\n  <tr> \n    <td height=\"10\" colspan=\"2\">&nbsp;</td>\n    <td width=\"79%\" height=\"10\">&nbsp;</td>\n  </tr>\n  <tr> \n    <td colspan=\"2\"><code>getWeights</code></td>\n    <td width=\"79%\"><p>[1 x Npts] array of kernel weights </p></td>\n  </tr>\n  <tr> \n    <td colspan=\"2\"><code>adjustWeights</code></td>\n    <td width=\"79%\"><p>set kernel weights (by reference!)</p></td>\n  </tr>\n  <tr> \n    <td colspan=\"2\">&nbsp;</td>\n    <td width=\"79%\">&nbsp;</td>\n  </tr>\n  <tr> \n    <td colspan=\"2\"><code>sample(P,Np,KSType)</code></td>\n    <td width=\"79%\"><p>draw Np new samples from P and set BW according to KSType</p></td>\n  </tr>\n  <tr> \n    <td colspan=\"2\">&nbsp;</td>\n    <td width=\"79%\">&nbsp;</td>\n  </tr>\n</table>\n<p><b><font size=\"+1\">Display: (visualization / description)</font></b> </p>\n<table width=\"90%\" border=\"1\" cellspacing=\"0\" cellpadding=\"2\">\n  <tr> \n    <td width=\"23%\"><code>plot(kde...)</code></td>\n    <td width=\"77%\"><p>plot the specified dimensions of the KDE locations</p></td>\n  </tr>\n  <tr> \n    <td width=\"23%\"><code>hist(kde...)</code></td>\n    <td width=\"77%\"><p>discretize the kde at uniform bin lengths display : text output \n      describing the KDE</p></td>\n  </tr>\n  <tr> \n    <td width=\"23%\"><code>double</code></td>\n    <td width=\"77%\"><p>boolean evaluation of the KDE (non-empty)</p> </td>\n  </tr>\n</table>\n<p></p>\n<p><font size=\"+1\"><b>Statistics: (useful stats & operations on a kde)</b></font> \n</p>\n<table width=\"90%\" border=\"1\" cellspacing=\"0\" cellpadding=\"2\">\n  <tr> \n    <td width=\"23%\"><code>mean</code></td>\n    <td width=\"77%\"><p>find the (weighted) mean of the kernel centers</p> </td>\n  </tr>\n  <tr> \n    <td width=\"23%\"><code>covar</code></td>\n    <td width=\"77%\"><p>find the (weighted) covariance of the kernel centers</p> </td>\n  </tr>\n  <tr> \n    <td width=\"23%\"><code>knn(kde, points, k)</code></td>\n    <td width=\"77%\"><p>find the k nearest neighbors of each of points in kde</p> </td>\n  </tr>\n  <tr> \n    <td width=\"23%\"><code>entropy</code></td>\n    <td width=\"77%\"><p>estimate the entropy of the KDE</p> </td>\n  </tr>\n  <tr> \n    <td width=\"23%\"><code>kld</code></td>\n    <td width=\"77%\"><p>estimate divergence between two KDEs</p> </td>\n  </tr>\n  <tr> \n    <td width=\"23%\"><code>evaluate(kde, x[,tol])</code></td>\n    <td width=\"77%\"><p>evaluate KDE at a set of points x</p> </td>\n  </tr>\n  <tr> \n    <td width=\"23%\"><code>evaluate(p, p2 [,tol])</code></td>\n    <td width=\"77%\"><p>same as above, x = p2.pts (if we've already built a tree)</p> \n    </td>\n  </tr>\n  <tr> \n    <td width=\"23%\"><code>evalIFGT(kde, x, N)</code></td>\n    <td width=\"77%\"><p>evaluate using the N-term IFGT (requires uniform BW Gaussian kernels)</p> </td>\n  </tr>\n  <tr> \n    <td width=\"23%\"><code>evalIFGT(p, p2, N)</code></td>\n    <td width=\"77%\"><p><same as above, x = p2.pts (if we've already built a tree)</p> </td>\n  </tr>\n  <tr> \n    <td width=\"23%\"> <code> evalAvgLogL(kde, x)</code> </td>\n    <td width=\"77%\"><p>compute Mean( log( evaluate(kde, x) ))</p></td>\n  </tr>\n  <tr> \n    <td width=\"23%\"><code>evalAvgLogL(kde, kde2)</code></td>\n    <td width=\"77%\"><p>same as above, but use the weights of kde2</p> </td>\n  </tr>\n  <tr> \n    <td width=\"23%\"><code>evalAvgLogL(kde)</code></td>\n    <td width=\"77%\"><p>self-eval; leave-one-out option</p> </td>\n  </tr>\n  <tr> \n    <td width=\"23%\"><code>llGrad(kde,kde2)</code></td>\n    <td width=\"77%\"><p>estimate the gradient of log-likelihood for kde evaluated \n      at the points of kde2</p> </td>\n  </tr>\n  <tr> \n    <td width=\"23%\"><code>entropyGrad(p)</code></td>\n    <td width=\"77%\"><p>estimate gradient of entropy (uses llGrad)</p> </td>\n  </tr>\n  <tr> \n    <td width=\"23%\"><code>miGrad(p,dim)</code></td>\n    <td width=\"77%\"><p>estimate gradient for mutual information between p(dim), p(~dim)</p> </td>\n  </tr>\n  <tr> \n    <td width=\"23%\"><code>klGrad(p1,p2)</code></td>\n    <td width=\"77%\"><p>estimate gradient direction of KL-divergence</p></td>\n  </tr>\n</table>\n<p> <b><font size=\"+1\">Mixture products: (NBP stuff) </font></b><font size=\"+1\"><i>(GAUSSIAN \n  KERNELS ONLY)</i></font> </p>\n<table width=\"90%\" border=\"1\" cellspacing=\"0\" cellpadding=\"2\">\n  <tr> \n    <td colspan=\"2\"><code>productExact</code></td>\n    <td width=\"678\"><p>exact computation (N^d kernel centers)</p> </td>\n  </tr>\n  <tr> \n    <td colspan=\"2\"><code>productApprox</code></td>\n    <td width=\"678\"><p>accessor for other product sampling methods</p></td>\n  </tr>\n  <tr> \n    <td width=\"20\">&nbsp;</td>\n    <td width=\"170\"><code>prodSampleExact</code></td>\n    <td width=\"678\"><p>sample N points exactly (N^d computation)</p></td>\n  </tr>\n  <tr> \n    <td width=\"20\">&nbsp;</td>\n    <td width=\"170\"><code>prodSampleEpsilon</code></td>\n    <td width=\"678\"><p>kd-tree epsilon-exact sampler</p> </td>\n  </tr>\n  <tr> \n    <td width=\"20\">&nbsp;</td>\n    <td width=\"170\"><code>prodSampleGibbs1</code></td>\n    <td width=\"678\"><p>seq. index gibbs sampler</p></td>\r\n  </tr>\n  <tr> \n    <td width=\"20\">&nbsp;</td>\n    <td width=\"170\"><code>prodSampleGibbs2</code></td>\n    <td width=\"678\"><p>product of experts gibbs sampler</p></td>\n  </tr>\n  <tr> \n    <td width=\"20\">&nbsp;</td>\n    <td width=\"170\"><code>prodSampleGibbsMS1</code></td>\n    <td width=\"678\"><p>multiresolution version of GS1</p> </td>\n  </tr>\n  <tr> \n    <td width=\"20\">&nbsp;</td>\n    <td width=\"170\"><code>prodSampleGibbsMS2</code></td>\n    <td width=\"678\"><p>multiresolution version of GS2</p></td>\n  </tr>\n  <tr> \n    <td width=\"20\">&nbsp;</td>\n    <td width=\"170\"><code>prodSampleImportance</code></td>\n    <td width=\"678\"><p>&quot;mixture&quot; importance sampling</p></td>\n  </tr>\n  <tr>\n    <td width=\"20\">&nbsp;</td>\n    <td width=\"170\"><code>prodSampleImportGauss</code></td>\n    <td width=\"678\"><p>gaussian importance sampling</p> </td>\n  </tr>\n</table>\n<p>&nbsp;</p>\n\n\n\n<h1> COPYRIGHT / LICENSE </h1>\n<p>The kde package and all code were written by Alex Ihler and Mike Mandel, and \n  are copyrighted under the (lesser) GPL: </p>\n<blockquote>\n  <p>Copyright (C) 2003 Alexander Ihler </p>\n</blockquote>\n<p>This program is free software; you can redistribute it and/or modify it under \n  the terms of the GNU Lesser General Public License as published by the Free \r\n  Software Foundation; version 2.1 or later. This program is distributed in the \n  hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied \n  warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU \n  Lesser General Public License for more details. You should have received a copy \n  of the GNU Lesser General Public License along with this program; if not, write \n  to the Free Software Foundation, Inc., 59 Temple Place - Suite 330, Boston, \n  MA 02111-1307, USA. </p>\n<p>The authors may be contacted via email at: <i>ihler (at) alum (.) mit (.) edu</i> </p>\n<p></p>\n<p></p>\n<p></p>\n<p></p>\n<p></p>\n<h1>CHANGELOG </h1>\n<pre>\nCHANGE LOG FOR KERNEL DENSITY ESTIMATION CLASS\n==============================================\n\n08/14/07   ATI   Fixed 64-bit support for productApprox functions + bugfix\n07/16/07   ATI   Fixed 64-bit support for most functions\n01/08/04   ATI   Added support for LOO estimate in llGrad; fixed computation\n                 of norm. constant for LOO version of evaluate\n11/22/04   ATI   Added (original) Fast Gauss Transform (Greengard & Strain '91), \n                 using newer (correct) error bound of Baxter & Roussos '02\n11/09/04   ATI   Fixed bug in IFGT eval (incorrect scale factor)\n10/02/04   ATI   Added support for Yang, Duraiswami, and Gumerov's Improved Fast\n                 Gauss Transform.  Extremely fast; loose bounds on absolute error.\n09/17/04   ATI   Fixed permutation bug in adjustBW, and bug in llGrad for evals\n                 between two distributions.  Added explicit discrete resampling.\n08/04/04   ATI   Updated productApprox:import, reduceKD; added ISE type to reduceKD\n07/09/04   ATI   Fixed small bugs: condition.m, jointrees.m, productExact.m\n                 Improved speed of sample.m \n02/19/04   ATI   Added \"llHess\" (Hessian) and \"modes\" (mode-finding) functions\n01/29/04   ATI   fixed 0 vs 1-base err in \"index\" ret'n values of productApprox\n01/22/04   ATI   Added \"ise\" method and epsilon-exact MEX implementation\n                 Fixed bug in epsilon and exact products of variable-BW densities\n                 Improved implementation of \"condition\" for fixed-BW densities\n12/28/03   ATI   Removed \"abs\" KL method, replaced with \"ise\" estimate method\n                 (\"abs\" was not a good est. of KL but served as an est. of ISE)\n12/13/03   ATI   Fixed bug in KNN function and some bugs with the \"reduce\" f'n & \"kld\"\n                 Added some example demonstration functions\n12/05/03   ATI   Added \"reduce\" function\n                 Fixed bug in \"productExact\" (thanks Chunhua Shen)\n                 Fixed bug in adjustBW (caused crashing or termination)\n11/18/03   ATI   Added support for additional KL-divergence estimates\n10/28/03   ATI   Added support for \"kde(pts,'kstype')\" constructor\n10/24/03   ATI   Fixed an error in \"adjustWeights\"; added mex & dll files to tarfile\n</pre>\n<p></p>\n\n</div>\n\n</body>\n</html>\n", "id": 2737.0}