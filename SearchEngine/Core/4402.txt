{"text": "CS 221 Information Retrieval Homework ProjectsPaper SummariesSyllabus Academic Honesty Students with Disability Synopsis Purpose An introduction to information retrieval including indexing retrieval classifying and clustering text and multimedia documents Book Introduction to Information Retrieval by Christopher D Manning Prabhakar Raghavan and Hinrich Schutze Evaluation Homework lab projects 1 2 Summaries 1 4 Class participation 1 4 Pedagogy Lectures cover the material in the reading materials by placing it in context giving examples and engaging in Q As Homework projects are hands on vehicles for learning the material Collaboration and knowledge exchange are encouraged in the projects but mindless copy of solutions aka cheating is not allowed Papers cover the foundations of the field of Information Retrieval right from the original source Class discussions push students beyond text book materials and into research territory Instructor Prof Cristina Lopes DBH 5 76 lopes at ics dot uci dot edu Reader Nitin Shantharam Lectures Mon Web 3 3 4 5 pm PSCB 12 Office hours Mondays and Wednesdays 1 3 pm 3pm DBH 5 76 Projects Project descriptions Support for this courses s projects kindly provided by Quizzes There will be 4 quizzes throughout the course Quizzes are on Mondays during the lecture They cover material that has been taught the previous weeks since the last quizz No quiz make ups QuizDate11 3 22 1332 2743 12 Paper Summaries Summaries are due Fridays Summaries submitted up to one week late will have a penalty of 35 Please name your paper summary files like this LastName SummaryNumber pdf starting with SummaryNumber 1 for the first summary Files that don t follow this convention may be missed by the instructors Include your full name and student ID in the summary itself Turn in summaries in EEE Dropbox Syllabus WeekDateTopic Weekly materialsDeliverablesNotes11 9Web Search BasicsTextbook Chapter 19 Web Search Basics no need to summarize 1 Wikipedia entry on Vannevar Bush 2 As We May Think The Atlantic Monthly July 1945 reprinted in ACM CHI Interactions March 1996 Summaries Slides Slides Slides 1 11Projects Overview Slides 21 16 Web Search Basics 3 Stuff I ve seen A system for personal information retrieval and re use by S Dumais E Cutell J Cadiz G Jancke R Sarin and D Robbins SIGIR 2 3 Commentary This paper addresses an increasingly important problem how to search and manage personal collections of electronic information it addresses an important user centered problem this paper presents a practical user interface to make the system useful the paper includes large scale user oriented testing that demonstrates the efficacy of the system the evaluation uses both quantitative and qualitative data to make its case I think this paper is destined to be a classic because it may eventually define how people manage their files for a decade Moreover it is well written and can serve as a good model for developers doing system design and evaluation and for students learning about IR systems and evaluation 4 Simple Proven Approaches to Text Retrieval by Robertson and Jones Commentary This paper provides a brief but well informed and technically accurate overview of the state of the art in text retrieval at least up to 1997 It introduces the ideas of terms and matching term weighting strategies relevance weighting a little on data structures and the evidence for their effectiveness In my view it does an exemplary job of introducing the terminology of IR and the main issues in text retrieval for a numerate and technically well informed audience It also has a very well chosen list of references Summaries No class1 18Discussion31 23Web crawling andEvaluation in IRTextbook Chapter 2 Web Crawling and Indices no need to summarize Textbook Chapter 8 Evaluation in information retrieval no need to summarize 5 The Web As a Graph by R Kumar P Raghavan S Rajagopalan D Sivakumar A Tomkins E Upfal PODS 2 Abstract The pages and hyperlinks of the World Wide Web may be viewed as nodes and edges in a directed graph This graph has about a billion nodes today several billion links and appears to grow exponentially with time There are many reasons mathematical sociological and commercial for studying the evolution of this graph We first review a set of algorithms that operate on the Web graph addressing problems from Web search automatic community discovery and classification We then recall a number of measurements and properties of the Web graph Noting that traditional random graph models do not explain these observations we propose a new family of random graph models Summaries Slides Slides More 1 25Evaluation 41 3 Index ConstructionTextbook Chapter 4 Index Construction 6 How Google Code Search Worked by Russ Cox January 2 12 Commentary Google code search has been a great resource for developers but it has just been shut down This blog post explains how it worked SummariesSlides2 1Slides More 52 6Index Construction and Scoring 7 The unreasonable effectiveness of data Commentary Three Google researchers summarize the benefits of data driven problem solving in an essay that borrows the title from another famous paper that proposes the opposite Summaries Slides Slides2 8Slides Slides 62 13Querying Scoring Term Weighting and the Vector Space modelTextbook Chapter 1 Boolean Retrieval Textbook Chapter 6 Scoring term weighting the vector space model 8 A vector space model for automatic indexing by Salton Wong Yang Summaries Slides Slides2 15Slides72 2 Hadoop 1 Map Reduce Simplified Data Processing on Large Clusters by Jeffrey Dean and Sanjay Ghemawat Commentary the paper that revolutionized modern data processing made cloud computing trendy and a great example of how programming language concepts can be applied to the design of real systems Summaries no class2 22 Slides 82 27Link Analysis Textbook Chapter 21 Link Analysis 9 The Anatomy of a Large Scale Hypertextual Web Search Engine by S Brin and L Page this link is to the long version the short version was publishied in WWW1998 Commentary This paper and the work it reports has had more impact on everyday life than any other in the IR area A major contribution of the paper is the recognition that some relevant search results are greatly more valued by searchers than others By reflecting this in their evaluation procedures Brin and Page were able to see the true value of web specific methods like anchor text The paper presents a highly efficient scalable implementation of a ranking method which now delivers very high quality results to a billion people over billions of pages at about 6 queries per second It also hints at the technology which Google users now take for granted spam rejection high speed query based summaries source clustering and context location sensitive search IR and bibliometrics researchers had done it all relevance proximity link analysis efficiency scalability summarization evaluation before 1998 but this paper showed how to make it work on the web For any non IR engineer attempting to build a web based retrieval system from scratch this must be the first port of call Summaries Slides Slides2 29 93 5Matrix decompositions and latent semantic indexingTextbook Chapter 18 Matrix Decompositions and latent semantic indexing Additional tutorial on LSA with code 11 Indexing by latent semantic analysis by Deerwester Dumais et al Commentary IR as a field hasn t directly considered the issue of semantic knowledge representation The above paper is one of the few that does in the following way LSI is latent semantic analysis LSA applied to document retrieval LSA is actually a variant of a growing ensemble of cognitively motivated models referred to by the term semantic space LSA has an encouraging track record of compatibility with human information processing across a variety of information processing tasks LSA seems to capture the meaning of words in a way which accords with the representations we carry around in our heads Finally the above paper is often cited and interest in LSI seems to have increased markedly in recent years The above paper has also made an impact outside our field For example recent work on latent semantic kernels machine learning draws heavily on LSI Summaries Slides3 7 1 3 12Matrix decompositions and latent semantic indexingTextbook Chapter 8 Evaluation in Information Retrieval 12 Unsupervised Named Entity Extraction from the Web An Experimental Study Etzioni et al Commentary This paper represents a new generation of IR work that attempts to do more than build a bag of words for information retrieval but also attempts to make some sense of the information as well Summaries Slides Slides 3 14 Exam no exam Academic Honesty I trust all students are honest and do not cheat Those who break my trust at any point will get an F in the course no excuses or apologies will be accepted Additional penalties may also be imposed by the department and the university Very severe incidents of academic dishonesty can result in suspension or expulsion from the university So don t risk it If for some reason you can t do the homework on time or can t study for the Quiz you re better off skipping it than cheating it Do the math Students with Disability Any student who feels he or she may need an accommodation based on the impact of a disability should contact me privately to discuss his or her specific needs Also contact the Disability Services Center at 949 824 7494 as soon as possible to better ensure that such accommodations are implemented in a timely fashion ", "_id": "http://www.ics.uci.edu/~lopes/teaching/cs221W12/index.html", "title": "cs 221 - information retrieval", "html": "<html>\n<head>\n  <meta http-equiv=\"Content-Language\" content=\"en-us\">\n  <meta http-equiv=\"content-type\" content=\"text/html; charset=windows-1252\">\n  <title>CS 221 - Information Retrieval</title>\n  <style>\n<!--\ntable.MsoTableGrid\n{border:1.0pt solid windowtext;\nfont-size:10.0pt;\nfont-family:Times;\n}\n-->\n\n  </style>\n</head>\n\n<body bgcolor=\"#FFFFFF\">\n<h2><font face=\"Pristina\">CS 221</font>\n<font face=\"Pristina\">Information Retrieval</font></h2>\n\n<table border=\"1\" cellpadding=\"10\" cellspacing=\"0\"\nstyle=\"border-collapse: collapse\" width=\"100%\" id=\"AutoNumber1\">\n  <tbody>\n    <tr>\n      <td width=\"20%\">\n        <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\"\n        style=\"border-collapse: collapse\" width=\"97%\" id=\"AutoNumber2\">\n          <tbody>\n<!--\n\t    <tr>\n              <td width=\"100%\"><p><strong>Groupware</strong></p>\n\n                * <a href=\"http://getsatisfaction.com/uc_irvine\">Discussions</a></br>\n                * <a href=\"http://ir-winter2010.blogspot.com/\">Course\n                Blog</a>\n\n             </td>\n            </tr>\n          <tr>\n              <td width=\"100%\">&nbsp;</td>\n            </tr>\n           <tr>\n              <td width=\"100%\">&nbsp;</td>\n            </tr>\n-->\n           <tr>\n              <td width=\"100%\"></td>\n            </tr>\n            <tr>\n              <td width=\"100%\"><b><font face=\"Arial\" size=\"2\"><a\n                href=\"#homework\">Homework Projects</a></font></b></td>\n            </tr>\n           <tr>\n              <td width=\"100%\"><b><font face=\"Arial\" size=\"2\"><a\n                href=\"#summaries\">Paper Summaries</a></font></b></td>\n            </tr>\n            <tr>\n              <td width=\"100%\"><b><font face=\"Arial\" size=\"2\"><a\n                href=\"#syllabus\">Syllabus</a></font></b></td>\n            </tr>\n            <tr>\n              <td width=\"100%\">&nbsp;</td>\n            </tr>\n            <tr>\n              <td width=\"100%\"><b><font face=\"Arial\" size=\"2\"><a\n                href=\"#honesty\">Academic Honesty</a></font></b></td>\n            </tr>\n            <tr>\n              <td width=\"100%\"><font face=\"Arial\" size=\"2\">&nbsp;</font></td>\n            </tr>\n            <tr>\n              <td width=\"100%\"><b><font face=\"Arial\" size=\"2\"><a\n                href=\"#disability\">Students with Disability</a></font></b></td>\n            </tr>\n          </tbody>\n        </table>\n      </td>\n      <td width=\"80%\" valign=\"top\"><font size=\"4\"\n        face=\"Pristina\"><b>Synopsis</b></font> \n\n        <p><b><font face=\"Pristina\">Purpose</font><font\n        size=\"2\">.</font></b><font size=\"2\"></font> <font face=\"Pristina\">An\n        introduction to information retrieval including indexing, retrieval,\n        classifying, and clustering text and multimedia documents.</font></p>\n\n        <p><font face=\"Pristina\"><b>Book</b></font><font size=\"2\">. <font\n        size=\"-1\"><span style=\"font-size: 12pt\"><span\n        style=\"font-size: 11pt\"><a\n        href=\"http://nlp.stanford.edu/IR-book/information-retrieval-book.html\">Introduction\n        to Information Retrieval</a> by Christopher D. Manning, Prabhakar\n        Raghavan and Hinrich Schutze </span></span></font></font></p>\n\n       <p><b><font face=\"Pristina\">Evaluation. </font></b>\n        Homework/lab projects (1/2) + Summaries (1/4) + Class\n        participation (1/4)</p>\n\n\t<p><font face=\"Pristina\"><b>Pedagogy:</b></font></br>\n        - Lectures cover the material in the reading materials by placing it in\n        context, giving examples, and engaging in Q&amp;As. <br>\n       - Homework projects are hands-on vehicles for learning the material.\n        Collaboration and knowledge exchange are encouraged in the projects, but mindless\n        copy of solutions (aka cheating)</font> is not allowed.<br>\n       - Papers cover the foundations of the field of Information\n\tRetrieval, right from the original source.</br>\n       - Class discussions push students beyond text book materials,\n\tand into research territory.</p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n<p><font face=\"Pristina\"></font>Instructor: <a\nhref=\"http://www.ics.uci.edu/~lopes\">Prof. Cristina Lopes</a>, DBH 5076, lopes\n<i><font size=\"1\">at</font></i> ics <i><font size=\"1\">dot</font></i> uci\n<i><font size=\"1\">dot</font></i> edu <br>\n<font face=\"Pristina\">Reader</font>: <a\nhref=\"http://www.ics.uci.edu/~nshantha/\">Nitin Shantharam</a></p>\n\n<p><font face=\"Pristina\">Lectures</font>: Mon &amp; Web 3:30-4:50pm,\nPSCB 120</br>\nOffice hours: Mondays and Wednesdays, 1:30pm-3pm, DBH 5076\n</p>\n<hr>\n\n<a name=\"homework\"><p><b><font size=\"4\">Projects</font></b></p></a>\n\n<p><a href=\"projects/projects.pdf\">Project descriptions</a></p>\n\n<p>Support for this courses's projects kindly provided by\n<img width=\"100px\" src=\"amazon-web-services-logo-large.png\"></p>\n\n<!--\n<p>There will be 6 projects, including one on the first week. Projects are due\n<font color=\"#FF0000\"><font face=\"Pristina\">by midnight</font></font>\non the due date.\nLate homework will be accepted with penalties.</p>\n\n<p><b>Submission</b></p>\n\n<p>See instructions in each homework.<br>\n</p>\n\n<p><b>Important dates</b></p>\n\n<table border=\"1\">\n  <tr>\n    <td>Assignment</td>\n    <td>Topic</td>\n    <td>Due date</td>\n    <td>Weight</td>\n  </tr>\n  <tr>\n    <td>1</td>\n    <td><a href=\"assignments/Assignment1.html\">R U here?</a></td>\n    <td>1/9</td>\n    <td>10%</td>\n </tr>\n  <tr>\n    <td>2</td>\n    <td><a href=\"assignments/Assignment2.pdf\">Text processing</a></td>\n    <td>1/18</td>\n    <td>20%</td>\n  </tr>\n  <tr>\n    <td>3</td>\n    <td><a href=\"http://www.ics.uci.edu/~sjavanma/IR/Assignments/Assignment3/Assignment3_2011.pdf\">Web crawling</a></td>\n    <td>1/30</td>\n    <td>20%</td>\n  </tr>\n  <tr>\n    <td>4</td>\n    <td><a href=\"assignments/Assignment4.pdf\">Indexing</a></td>\n    <td>2/13</td>\n    <td></td>\n  </tr>\n  <tr>\n    <td>5</td>\n    <td><a href=\"assignments/Assignment5.pdf\">Ranking</a></td>\n    <td>2/27</td>\n    <td></td>\n  </tr>\n  <tr>\n    <td>6</td>\n    <td><a href=\"assignments/Assignment6.pdf\">Map-Reduce</a></td>\n    <td>3/18</td>\n    <td></td>\n  </tr>\n</table>\n-->\n\n<p>&nbsp;</p>\n<hr>\n\n<a name=\"quizzes\"><p><b><font size=\"4\">Quizzes</font></b></p></a>\n\n<p>There will be 4 quizzes throughout the course. <font color=\"#FF0000\"\nface=\"Pristina\">Quizzes are on Mondays</font> during the lecture.\nThey cover material that has been taught the previous weeks since\nthe last quizz. \nNo quiz make-ups.</p>\n\n<table border=\"1\">\n  <tr>\n    <td>Quiz</td>\n    <td>Date</td>\n  </tr>\n  <tr>\n    <td>1</td>\n    <td>1/30</td>\n  </tr>\n  <tr>\n    <td>2</td>\n    <td>2/13</td>\n  </tr>\n  <tr>\n    <td>3</td>\n    <td>2/27</td>\n  </tr>\n  <tr>\n    <td>4</td>\n    <td>3/12</td>\n  </tr>\n</table>\n<p>&nbsp;</p>\n<hr>\n\n<a name=\"summaries\"><h3>Paper Summaries</h3></a>\n\n<p> Summaries are due Fridays. Summaries submitted up to\none week late will have a penalty of 35%.</p>\n<p>Please name your paper summary files like this:</br>\n<i>LastName</i>_<i>SummaryNumber</i>.pdf</br>\nstarting with <i>SummaryNumber</i>=1 for the first summary.</br>\n\nFiles that don't follow this convention may be missed by the\ninstructors.</p>\n\n<p>Include your full name and student ID in the summary itself.</p>\n\n<p>Turn in summaries in EEE Dropbox.</p>\n\n<hr>\n\n<a name=\"syllabus\"><h3>Syllabus:</h3></a>\n\n<p></p>\n\n<table border=\"1\" style=\"width: 100%\">\n  <caption></caption>\n  <col>\n  <col>\n  <col>\n  <col>\n  <col>\n  <col>\n  <tbody>\n    <tr>\n      <td>Week</td>\n      <td>Date</td>\n      <td>Topic </td>\n      <td>Weekly materials</td>\n      <td>Deliverables</td>\n      <td>Notes</td>\n    </tr>\n    <tr>\n      <td rowspan=\"2\">1</td>\n      <td>1/9</td>\n      <td rowspan=\"2\">Web Search Basics</td>\n      <td rowspan=\"2\">Textbook <a\n        href=\"http://nlp.stanford.edu/IR-book/information-retrieval-book.html\">Chapter\n        19</a>: Web Search Basics (no need to summarize)\n\n        <p>1. Wikipedia entry on <a\n        href=\"http://en.wikipedia.org/wiki/Vannevar_Bush\">Vannevar Bush</a></p>\n\n        <p>2. \"<a href=\"http://www.theatlantic.com/doc/194507/bush\">As We May\n        Think</a>\" The Atlantic Monthly, July, 1945. (reprinted in ACM CHI\n        Interactions, March 1996)</p>\n\n     </td>\n      <td rowspan=\"2\">\n\tSummaries \n      </td>\n      <td><a href=\"slides/Lecture01Slides.pdf\">Slides</a> \n        <p><a href=\"slides/Lecture02Slides.pdf\">Slides</a></p>\n\t<p><a href=\"slides/Lecture03Slides.pdf\">Slides</a></p>\n      </td>\n    </tr>\n    <tr>\n      <td>1/11</td>\n      <td><a href=\"slides/CS 221 Information Retrieval Projects.pdf\">Projects Overview</a>\n\t<p><a href=\"slides/Lecture04Slides.pdf\">Slides</a></p>\n      </td>\n    </tr>\n    <tr>\n      <td rowspan=\"2\">2</td>\n      <td>1/16*</td>\n      <td rowspan=\"2\">Web Search Basics</td>\n      <td rowspan=\"2\">\n        <p>3. \"<a href=\"http://doi.acm.org/10.1145/860435.860451\">Stuff I've\n        seen: A system for personal information retrieval and re-use</a> \" by\n        S. Dumais, E. Cutell, J. Cadiz, G. Jancke, R. Sarin, and D. Robbins,\n        SIGIR, 2003</p>\n\n        <p>Commentary: \"This paper addresses an increasingly important problem\n        - how to search and manage personal collections of electronic\n        information. ... it addresses an important user-centered problem.\n        ...this paper presents a practical user interface to make the system\n        useful. ..., the paper includes large scale, user-oriented testing that\n        demonstrates the efficacy of the system. ..., the evaluation uses both\n        quantitative and qualitative data to make its case. I think this paper\n        is destined to be a classic because it may eventually define how people\n        manage their files for a decade. Moreover, it is well-written and can\n        serve as a good model for developers doing system design and\n        evaluation, and for students learning about IR systems and\n        evaluation.\"</p>\n\n\t<p>4. \"<a\n        href=\"http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.53.8337\">Simple,\n        Proven Approaches to Text Retrieval</a>\" by Robertson and Jones </p>\n\n        <p>Commentary: \"This paper provides a brief but well informed and\n        technically accurate overview of the state of the art in text\n        retrieval, at least up to 1997. It introduces the ideas of terms and\n        matching, term weighting strategies, relevance weighting, a little on\n        data structures and the evidence for their effectiveness. In my view it\n        does an exemplary job of introducing the terminology of IR and the main\n        issues in text retrieval for a numerate and technically well informed\n        audience. It also has a very well chosen list of references.\"</p>\n\n        <p></p>\n      </td>\n      <td rowspan=\"2\">\n\t<p>Summaries </p></td>\n      <td>No class</td>\n    </tr>\n    <tr>\n      <td>1/18</td>\n      <td>Discussion</td>\n    </tr>\n    <tr>\n      <td rowspan=\"2\">3</td>\n      <td>1/23</td>\n      <td rowspan=\"2\">Web crawling <br/>and<br/>Evaluation in IR</td>\n      <td rowspan=\"2\">Textbook <a\n        href=\"http://nlp.stanford.edu/IR-book/information-retrieval-book.html\">Chapter\n        20</a> : Web Crawling and Indices (no need to summarize)<br/>\n\n      Textbook <a\n        href=\"http://nlp.stanford.edu/IR-book/information-retrieval-book.html\">Chapter\n        8</a> : Evaluation in information retrieval (no need to summarize)\n\n        <p>5. \"<a\n        href=\"http://portal.acm.org/citation.cfm?id=335168.335170&amp;coll=ACM&amp;dl=ACM&amp;CFID=5772105&amp;CFTOKEN=18886490\">The\n        Web As a Graph</a>\" by R. Kumar, P Raghavan, S. Rajagopalan, D.\n        Sivakumar, A. Tomkins, E. Upfal, PODS 2000</p>\n\n        <p>Abstract: \"The pages and hyperlinks of the World-Wide Web may be\n        viewed as nodes and edges in a directed graph. This graph has about a\n        billion nodes today, several billion links, and appears to grow\n        exponentially with time. There are many reasons -- mathematical,\n        sociological, and commercial -- for studying the evolution of this graph.\n        We first review a set of algorithms that operate on the Web graph,\n        addressing problems from Web search, automatic community discovery, and\n        classification. We then recall a number of measurements and properties\n        of the Web graph. Noting that traditional random graph models do not\n        explain these observations, we propose a new family of random graph\n        models.\"</p>\n\n        <p></p>\n      </td>\n      <td rowspan=\"2\">\n\tSummaries  \n      </td>\n      <td><a href=\"slides/Lecture05.pdf\">Slides</a>\n\t<p><a href=\"slides/Lecture06.pdf\">Slides</a> </p>\n        <p><a\n        href=\"http://dg3rtljvitrle.cloudfront.net/slides/chap3.pdf\">More</a></p>\n      </td>\n    </tr>\n\n    <tr>\n      <td>1/25</td>\n      <td><a href=\"slides/chap8.pptx\">Evaluation</a>\n      </td>\n    </tr>\n    <tr>\n      <td rowspan=\"2\">4</td>\n      <td>1/30</td>\n      <td rowspan=\"2\">Index Construction</td>\n      <td rowspan=\"2\">Textbook <a\n        href=\"http://nlp.stanford.edu/IR-book/information-retrieval-book.html\">Chapter\n        4</a> : Index Construction \n\n        <p>6. \"<a href=\"http://swtch.com/~rsc/regexp/regexp4.html\">How Google Code Search Worked\n        </a> \" by Russ Cox (January 2012)</p>\n\n        <p>Commentary: Google code search has been a great resource for developers, but it\n           has just been shut down. This blog post explains how it worked.</p>\n     </td>\n      <td rowspan=\"2\">\n\tSummaries</td>\n      <td><a href=\"slides/Lecture07.pdf\">Slides</a></td>\n    </tr>\n    <tr>\n      <td>2/1</td>\n      <td><a href=\"slides/Lecture08.pdf\">Slides</a> \n\n        <p><a\n        href=\"http://dg3rtljvitrle.cloudfront.net/slides/chap5.pdf\">More</a></p>\n      </td>\n    </tr>\n    <tr>\n      <td rowspan=\"2\">5</td>\n      <td>2/6</td>\n      <td rowspan=\"2\">Index Construction and Scoring</td>\n     <td rowspan=\"2\">\n      <p>7. <a\n      href=\"http://research.google.com/pubs/archive/35179.pdf\">The\n      unreasonable effectiveness of data</a></p>\n        <p>Commentary: Three Google researchers summarize the benefits of\n      data-driven problem-solving in an essay that borrows the title from\n      <a\n      href=\"http://www.dartmouth.edu/~matc/MathDrama/reading/Wigner.html\">another\n      famous paper that proposes the opposite</a>.</p>\n     </td>\n      <td rowspan=\"2\">\n\tSummaries\n      </td>\n      <td><a href=\"slides/Lecture09.pdf\">Slides</a>\n          <a href=\"http://www.stanford.edu/class/cs276/handouts/lecture4-indexconstruction.ppt\">Slides</a></td>\n    </tr>\n    <tr>\n      <td>2/8</td>\n      <td><a href=\"http://www.stanford.edu/class/cs276/handouts/lecture1-intro.ppt\">Slides</a>\n          <a href=\"http://www.stanford.edu/class/cs276/handouts/lecture6-tfidf.ppt\">Slides</a>\n     </td>\n    </tr>\n    <tr>\n      <td rowspan=\"2\">6</td>\n      <td>2/13</td>\n      <td rowspan=\"2\">Querying, Scoring, Term Weighting and the Vector Space\n        model</td>\n      <td rowspan=\"2\">Textbook <a\n        href=\"http://nlp.stanford.edu/IR-book/information-retrieval-book.html\">Chapter\n        1</a> : Boolean Retrieval \n\n        <p>Textbook <a\n        href=\"http://nlp.stanford.edu/IR-book/information-retrieval-book.html\">Chapter\n        6</a> : Scoring, term weighting &amp; the vector space model</p>\n\n        <p>8.<a href=\"http://dl.acm.org/citation.cfm?id=361220\">A vector space model for automatic indexing</a>\n           by Salton, Wong, Yang \n        </p>\n\n        <p></p>\n      </td>\n      <td rowspan=\"2\">\n\tSummaries\n      </td>\n      <td><a href=\"slides/Lecture12.pdf\">Slides</a><br/>\n          <a href=\"slides/Lecture14.pdf\">Slides</a></td>\n    </tr>\n    <tr>\n      <td>2/15</td>\n      <td><a href=\"http://www.stanford.edu/class/cs276/handouts/lecture7-vectorspace.ppt\">Slides</a></td>\n    </tr>\n    <tr>\n      <td rowspan=\"2\">7</td>\n      <td>2/20*</td>\n      <td rowspan=\"2\">Hadoop</td>\n      <td rowspan=\"2\">\n      <p>10. <a href=\"http://dl.acm.org/citation.cfm?id=1327492\">\"Map Reduce: Simplified Data Processing on\n        Large Clusters\"</a> by Jeffrey Dean and Sanjay Ghemawat</p>\n       <p>Commentary: the paper that revolutionized modern data\n        processing, made \"cloud computing\" trendy, and a great example of how programming language\n        concepts can be applied to the design of real systems.</p>\n        <p>&nbsp;</p>\n      </td>\n      <td rowspan=\"2\">\n       Summaries \n      </td>\n      <td>*no class</td>\n    </tr>\n    <tr>\n      <td>2/22</td>\n      <td>\n        <p><a href=\"slides/Hadoop-AWS.pdf\">Slides</a></p>\n      </td>\n    </tr>\n\n    <tr>\n      <td rowspan=\"2\">8</td>\n      <td>2/27</td>\n      <td rowspan=\"2\">Link Analysis</td>\n      <td rowspan=\"2\"><p> Textbook <a\n        href=\"http://nlp.stanford.edu/IR-book/information-retrieval-book.html\">Chapter\n        21</a> : Link Analysis</p>\n        <p>9. \"<a href=\"http://www-db.stanford.edu/pub/papers/google.pdf\">The\n        Anatomy of a Large-Scale Hypertextual Web Search Engine</a>\" by S.\n        Brin and L. Page (this link is to the long version, the short version\n        was publishied in WWW1998)</p>\n\n        <p>Commentary: \"This paper (and the work it reports) has had more\n        impact on everyday life than any other in the IR area. A major\n        contribution of the paper is the recognition that some relevant search\n        results are greatly more valued by searchers than others. By reflecting\n        this in their evaluation procedures, Brin and Page were able to see the\n        true value of web-specific methods like anchor text. The paper presents\n        a highly efficient, scalable implementation of a ranking method which\n        now delivers very high quality results to a billion people over\n        billions of pages at about 6,000 queries per second. It also hints at\n        the technology which Google users now take for granted: spam rejection,\n        high speed query-based summaries, source clustering, and\n        context(location)-sensitive search. IR and bibliometrics researchers\n        had done it all (relevance, proximity, link analysis, efficiency,\n        scalability, summarization, evaluation) before 1998 but this paper\n        showed how to make it work on the web. For any non-IR engineer\n        attempting to build a web-based retrieval system from scratch, this\n        must be the first port of call.\"</p>\n\n      </td>\n      <td rowspan=\"2\">Summaries\n     </td>\n      <td><a href=\"http://www.stanford.edu/class/cs276/handouts/lecture17-linkanalysis.ppt\">Slides</a></br>\n          <a href=\"slides/Lecture16.pdf\">Slides</a></td>\n    </tr>\n    <tr>\n      <td>2/29</td>\n      <td>&nbsp;</td>\n    </tr>\n    <tr>\n      <td rowspan=\"2\">9</td>\n      <td>3/5</td>\n      <td rowspan=\"2\">Matrix decompositions and latent semantic indexing</td>\n      <td rowspan=\"2\">Textbook <a\n        href=\"http://nlp.stanford.edu/IR-book/information-retrieval-book.html\">Chapter\n        18</a> : Matrix Decompositions and latent semantic indexing \n\n\t<p><a\n\thref=\"http://www.puffinwarellc.com/index.php/news-and-articles/articles/33-latent-semantic-analysis-tutorial.html\">\n\tAdditional tutorial on LSA, with code</a>\n\n        <p>11. \"<a\n        href=\"http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.49.7546\">Indexing\n        by latent semantic analysis</a>\" by (Deerwester, Dumais, et.al)</p>\n\n        <p>Commentary: \" IR, as a field, hasn't directly considered the issue\n        of semantic knowledge representation. The above paper is one of the few\n        that does in the following way. LSI is latent semantic analysis (LSA)\n        applied to document retrieval. LSA is actually a variant of a growing\n        ensemble of cognitively-motivated models referred to by the term\n        \"semantic space\". LSA has an encouraging track record of compatibility\n        with human information processing across a variety of information\n        processing tasks. LSA seems to capture the meaning of words in a way\n        which accords with the representations we carry around in our heads.\n        Finally, the above paper is often cited and interest in LSI seems to\n        have increased markedly in recent years. The above paper has also made\n        an impact outside our field. For example, recent work on latent\n        semantic kernels (machine learning) draws heavily on LSI. \"</p>\n\n        <p></p>\n      </td>\n      <td rowspan=\"2\">\n\t<p>Summaries</p>\n\t\n     </td>\n      <td><a href=\"slides/LSI.pdf\">Slides</a></td>\n    </tr>\n    <tr>\n      <td>3/7</td>\n      <td>\n        &nbsp;\n      </td>\n    </tr>\n    <tr>\n      <td rowspan=\"2\">10</td>\n      <td>3/12</td>\n      <td rowspan=\"2\">Matrix decompositions and latent semantic indexing</td>\n      <td rowspan=\"2\">Textbook <a\n        href=\"http://nlp.stanford.edu/IR-book/information-retrieval-book.html\">Chapter\n        8</a> : Evaluation in Information Retrieval\n\n       <p> 12. \"<a\n        href=\"http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.124.8829\">\n\tUnsupervised\n        Named-Entity Extraction from the Web: An Experimental Study</a> \"\n        (Etzioni, et.al.)</p>\n\n        <p>Commentary: \"This paper represents a new generation of IR work that\n        attempts to do more than build a bag of words for information\n        retrieval, but also attempts to make some sense of the information as\n        well.\"</p>\n\n        <p></p>\n      </td>\n      <td rowspan=\"2\">Summaries</td>\n      <td>\n        <p><a href=\"slides/OOPSLA08.pdf\">Slides</a></p>\n        <a href=\"slides/Lecture19New.pdf\">Slides</a>\n\n     </td>\n    </tr>\n    <tr>\n      <td>3/14</td>\n      <td><a href=\"slides/Lecture20.pdf\"></a></td>\n    </tr>\n  </tbody>\n</table>\n\n<p></p>\n\n<p><span style=\"color:#fd4138\">Exam: no exam</span></p>\n\n<p>&nbsp;</p>\n<hr>\n\n<a name=\"honesty\"><p><b><font size=\"4\">Academic Honesty</font></b></p></a>\n\n<p>I trust all students are honest and do not cheat. Those who break my trust\nat any point will get an F in the course - no excuses or apologies will be\naccepted.<font size=\"2\" face=\"Times New Roman, Times\"></font><font\nface=\"Times New Roman, Times\">Additional penalties may also be imposed by the\ndepartment and the university. Very severe incidents of academic dishonesty can\nresult in suspension or expulsion from the university.</font> </p>\n\n<p>So don't risk it! If, for some reason, you can't do the homework on time or\ncan't study for the Quiz, you're better off skipping it than cheating it. Do\nthe math!</p>\n<hr>\n\n<a name=\"disability\"><p><b><font size=\"4\">Students with Disability</font></b></p></a>\n\n<p>Any student who feels he or she may need an accommodation based on the\nimpact of a disability should contact me privately to discuss his or her\nspecific needs. Also contact the Disability Services Center at (949) 824-7494\nas soon as possible to better ensure that such accommodations are implemented\nin a timely fashion.</p>\n</body>\n</html>\n", "id": 4402.0}