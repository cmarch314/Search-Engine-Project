{"text": "From callahan condor cs jhu edu Paul Callahan Newsgroups comp theory Subject Jordan Sorting with Splay Trees conjecture Date 12 Aug 1995 13 4 8 4 Organization The Johns Hopkins University CS Department Jordan Sorting is the problem of sorting a list of numbers by x coordinate assuming that the numbers represent intersections of a non self intersecting i e Jordan curve with the x axis and that they are given in the order that they appear along this curve It has been known for about a decade as far as I my research has determined that Jordan Sorting can be performed in linear time What I m curious about is the following conjecture given in a paper that presents a linear time algorithm reference given below Our second remark is that there may be a much simpler way to sort Jordan sequences in linear time we merely insert the items in the sequence one at a time into a splay tree and then access them in sorted order On the basis of Sleator and Tarjan s dynamic optimality conjecture we conjecture than this sorts Jordan sequences in O n time This is from Sorting Jordan Sequences in Linear Time Using Level Linked Search Trees Hoffman Mehlhorn Rosensteihl and Tarjan Information and Control 68 1986 pp 17 184 Several later papers claim to present simpler algorithms but the most recent one I ve seen 199 is still not nearly as simple as the approach using splay trees So I m curious if this conjecture has been treated either theoretically or experimentally From a theoretical perspective one would think that if the conjecture is true it would at least be easier to prove than the dynamic optimality conjecture and would still be a pretty interesting result It strikes me as even more attractive as an experimental issue though because there is existing code for splay trees and random Jordan sequences are not hard to generate of course this leaves open the issue of generating hard cases of Jordan Sorting In a sense there s no excuse at all for not performing this experiment My literature search was far from exhaustive so if there are experimental results I d very much appreciate a reference It seems to me that if the conjecture is actually true then one could perhaps make a careful study of the splay tree algorithm for Jordan Sorting and try to infer what it is doing to achieve such good results This would provide a non trivial linear time algorithm that in some sense exists in nature rather than being the consequence of clever design If true that strikes me and some other people I hope as quite remarkable despite the fact that it would do no better than a known optimal algorithm Paul Callahan callahan cs jhu edu The first principle in science is to invent something nice to look at and then decide what it can do Rowland Emett From callahan biffvm cs jhu edu Paul Callahan Newsgroups comp theory Subject A family of Jordan Sequences for which Splay Sort is Omega n log n Date 25 Sep 1995 14 13 9 4 Organization The Johns Hopkins University CS Department About a month and a half ago I posted an inquiry about a conjecture related to sorting Jordan sequences A Jordan sequence is a list of intersections of a non self intersecting plane curve with the x axis The Jordan sequence sorting problem is to sort these intersections by x coordinate The non crossing curve restriction implies that the number of Jordan sequences of n values is O c n for some c rather than n implying that a general purpose comparison based sorting algorithm may not be optimal In fact has been known for over a decade that Jordan sequences can be sorted in O n time using only comparisons I emphasize the point about comparisons to avoid getting mired in the MSD radix sort flame war now in progress Anyway there is an appealing conjecture in two of the papers presenting linear time algorithms Information and Control 68 17 184 1986 and Information Processing Letters 35 85 92 199 that if the values in a Jordan Sequence are simply inserted into a splay tree and read off in sorted order then this might also require O n time in the worst case This general technique is usually called Splay Sort and can for certain kinds of input be shown to require much less time than a worst case optimal comparision based sort such as Mergesort If I understand the Jordan Sequence conjecture correctly I can show that it is incorrect I don t know if the following result is new but it s fairly specialized and doesn t seem to lead anywhere so I m posting it here after wondering for about a month what to do with it Because this posting not a formal publication I m going to leave out some steps It should not be too hard to fill in the details First to prove a lower bound on sorting a sequence using Splay Sort it will suffice to prove a lower bound for any algorithm that uses insertions into a binary search tree using any rotation strategy In fact the more general kind of lower bound is often easier to prove than a lower bound for Splay Sort itself owing to the work of Robert Wilber in FOCS 86 revised version in Siam J Comp vol 18 no 1 which provides two powerful methods for showing lower bounds on accessing sequences of values in Binary Search Trees We will not really need these methods here but only the corollary that accessing the nodes of a binary tree containing the values 1 2 k 1 in bit reversed order i e taking the binary representations of these values in increasing order but reversing the significance of the bits requires Omega k 2 k rotations In the following I m going to use the claim that sorting a sequence by inserting it into a binary tree is as hard as accessing the same sequence in a tree containing these values I haven t proved this but it seems to me that each time a value is inserted a new leaf added at what was a null pointer one could imagine that that value already existed as a node in the tree but had not previously been accessed It should thus be possible to construct an initial tree containing the values to be sorted for which the rotation sequence is the same whether one is inserting into an intially empty tree or accessing from an initally full tree Originally I had a more complicated idea for a proof that would not require this claim but I think it is true and it results in a cleaner argument Now what remains is simply to construct a family of hard Jordan Sequences such that for any value of n there is a sequence in this family containing at least n elements As it happens the sequences in this family will bear a relationship to bit reversed order that will cause them to require Omega n log n rotations to sort using any binary search tree according to the result of Wilber First I ll give an intuitive explanation of where these sequences come from If one were to take a looped flattened out strip of paper and view it facing the edge this would look like a very simple Jordan Curve I e unfortunately ASCII graphics make it unclear so let me repeat that this is viewed on edge not from above as it might also appear If this is folded over on itself to double its thickness we get another Jordan Curve but which is somewhat more convoluted I e We can repeat this doubling over process as many times as we like each time doubling the number of intersections of the curve with a vertical line For larger examples it becomes more convenient to represent the shape of the curve using two sets of matching parentheses this is the representation normally used to prove a bound on the number of Jordan Sequences E g if we double over two more times and rotate 9 degrees so the curve intersects the x axis we obtain Matching parentheses in the top sequence with arcs above and those in the bottom sequence with arcs below gives us the actual curve To connect this idea with bit reversed order we will describe the folding process as a transformation on a sequence of numbers that will denote the actual Jordan Sequence in question The correspondence to folding is not too hard to see but will be omitted here since it is not really needed once we obtain the final form of the construction First in the original loop the sequence of intersections is the same both on the curve and on the intersecting line so we denote this sequence 1 Now given such a sequence we obtain the next doubled over sequence as follows 1 double each number in the sequence 2 append the new sequence to its own reverse 3 Add 1 to every odd positioned number in the sequence the leftmost position is considered even E g 1 2 by 1 2 2 by 2 3 2 1 by 3 3 2 1 6 4 2 6 4 2 2 4 6 7 4 3 2 5 6 1 7 4 3 2 5 6 1 14 8 6 4 1 12 2 14 8 6 4 1 12 2 2 12 1 4 6 8 14 15 8 7 4 11 12 3 2 13 1 5 6 9 14 1 etc Here I ll resort to proof by example and simply point out that if you take the increasing sequence 1 2 3 4 5 6 7 8 9 1 11 12 13 14 15 and connect pairs of numbers adjacent in the sequence obtained in the process above with non crossing arcs also connecting the end values and 1 you will obtain the Jordan Curve determined by the set of matching parentheses given earlier Recall that for the lower bound we want to connect this in some way to bit reversed order So yet another way to obtain the above sequence is to define the following function f on k bit binary numbers denoted B b b k 1 In the following assume denotes exclusive or and let f b b b b b b b b b k 1 1 2 k 1 In other words reverse the order of bits 1 through k 1 keeping b in the same position Also if b 1 then invert bits 1 through k 1 E g B f B 1 111 1 1 11 11 1 1 1 1 1 1 11 11 111 1 Now to get the kth sequence determined by the process given previously we merely take the values i 2 k 1 expressed in binary and apply the function f to each i in increasing order We overload the meaning of f i to denote the result of converting i to a binary string applying f and converting it back to an integer It can be seen that from the above table the sequence for k 3 is 7 4 3 2 5 6 1 which corresponds to that obtained previously I imagine a lot of readers on this newsgroup don t find examples very convincing no matter how large they are and how nicely they work out Fortunately once the function f has been defined as above it suffices to show only that the sequence f f 1 f 2 k 1 is a Jordan Sequence which is an easier task than showing it corresponds to the particular Jordan sequences illustrated earlier To do this it is necessary to show that if the numbers 1 2 k 1 are written in order left to right then adjacent numbers in the sequence f f 1 f 2 k 1 can be connected by non crossing arcs alternating above and below the list of numbers A key observation needed for such a proof is that two arcs one from a to b and another from c to d cannot cross so long as a b c d The other is that they cannot cross if a b c d The set of arcs from a to b can be put in k 1 equivalence classes according to a b so that there is no crossing within each equivalence class The second observation can then be used to exclude crossings between arcs in distinct equivalence classes So if I were writing a more rigorous article it would now say something like Lemma For all k the sequence f f 1 f 2 k 1 is a Jordan Sequence This would be followed by a proof which is here left as an exercise What remains is to show that it requires Omega k 2 k comparisons to sort such a sequence using Splay Sort This can be seen by considering only those f i such that i is even Let R i denote the result of reversing the order of the bits in the binary representation of i By definition of f we know that for even values of i f i 2 R i 2 so the subsequence f f 2 f 2 k 2 must be in bit reversed order Since the sequence f f 1 f 2 k 1 contains 2 k 1 elements in bit reversed order the result of Wilber implies that the time to access such a sequence in a binary search tree is Omega k 1 2 k 1 and this also provides a bound on the time to sort the sequence using Splay Sort Then it follows that there exists a c such that for any value of n one can construct a Jordan Sequence of length greater than n that requires c n log n comparisons to sort using Splay Sort refuting the conjecture as I understood it that Splay Sort is a linear time algorithm for sorting Jordan Sequences Paul Callahan callahan cs jhu edu The first principle in science is to invent something nice to look at and then decide what it can do Rowland Emett From rew lightstone com Bob Wilber at PUMICE Newsgroups comp theory Subject Re Jordan Sequences for which Splay Sort is Omega n log n Date 27 Sep 1995 15 57 48 5 Organization UTexas Mail to News Gateway Paul Callahan showed that a bit reversal permutation can be imbedded in a Jordan sequence In the following I m going to use the claim that sorting a sequence by inserting it into a binary tree is as hard as accessing the same sequence in a tree containing these values I haven t proved this but it seems to me that each time a value is inserted a new leaf added at what was a null pointer one could imagine that that value already existed as a node in the tree but had not previously been accessed It should thus be possible to construct an initial tree containing the values to be sorted for which the rotation sequence is the same whether one is inserting into an intially empty tree or accessing from an initally full tree This is the crux of the matter can the lower bound in 1 be used to get an an Omega n log n lower bound on Jordan sorting via insertion into a symmetrically ordered binary tree That lower bound assumed that all elements are in the tree at the start that they are being accessed in some specified order allowing rotations in the tree and that no insertions or deletions are done Originally I had a more complicated idea for a proof that would not require this claim but I think it is true and it results in a cleaner argument I believe your claim is false But I think the lower bound can be patched up to work for this case Consider how Jordan sorting with a binary tree proceeds First we traverse the simple closed curve each time we encounter an intersection with the x axis we insert that intersection point into a binary tree that is symmetrically ordered by the x coordinate Second we access the items in the tree in order by x coordinate At the end of the first pass the items are sorted by x coordinate so the second pass accesses the nodes in sequential order This pass takes linear time including when the splay algorithm is used to do the accessing as was proved by Tarjan 2 So any lower bound must be applied to the first pass when the items are being inserted I find it convenient to reverse the film items are inserted into a tree in sequential order by x coordinate in linear time and then they are deleted in the order they appear on the curve that is deleted according to a Jordan sequence We want to show that the deletion phase takes n log n time We need to extend the model to allow for deletions I think the following definition covers all the cases Definition A standard deletion of a node v can occur when v has at most one child In that case if v has no children it is a leaf it is simply removed Otherwise v is removed and v s only child is made a child of v s parent if v was not the root or is made the root if v was the root In general to delete a node v you do some sequence of rotations so that v has at most one child and then you do a standard deletion of v For example as I recall deletion of a node v in a splay tree proceeds as follows 1 v is splayed to the root and removed leaving its left and right subtrees L and R 2 The largest node in L r is splayed to the root of L 3 R is made the right subtree of r This can be cast into the standard model as follows 1 v is splayed to the root Its left subtree is L 2 The largest node in L r is splayed to the root of L making r the left child of v 3 r is rotated over v 4 v has no left child a standard deletion of v is done Clearly this has the same complexity as the usual deletion routine In the model when we delete v we must also count the cost of accessing v from the root In order to fold all the costs into rotations we require that the algorithm be normalized so that before deleting any node it first rotates that node to the root This can always be done without increasing the time by more than a constant factor because if the original algorithm does a standard deletion of some node v at depth d it could first rotatate v to the root then rotate v back to where it was using 2d 2 rotations and then delete v The cost of the extra rotations is just a constant times the cost of following the path from the root to v Likewise a look up of v is always done by rotating v to the root Two lower bound methods were given in 1 I will only patch up the first one both methods give an Omega n log n bound for accessing the bit reversal permutation It is important to understand that the intuition behind both lower bounds is that items you access get in the way of items that you want to access later and must be rotated over But if you can delete nodes you can sometimes get a node v out of the way by deleting it which might be cheaper than forcing several nodes underneath to rotate over v So the ability to shrink the tree as you go might invalidate the lower bounds given in 1 Here s a very quick review of the first lower bound method We have some binary search tree T whose n nodes may be considered to be consecutive integers We allow rotations and standard deletions on T A lower bound tree Y with 2n 1 nodes is constructed whose leaves are the initial nodes of T and whose internal nodes lie between nodes in T that is they may be taken to be half integers T changes through rotations and deletions but Y is fixed For getting the lower bound on the bit reversal permutation Y is taken to be a balanced binary tree The sequence of nodes in T to be accessed is s 1 s 2 s m A node is accessed if we either look it up or delete it in both cases such a node must be rotated to the root in a normalized algorithm Given numbers x y s x y is the subsequence consisting of those s i s that are in the interval x y For each internal node u of Y a score l u is computed as follows Let x and y be the minimum and maximum leaves of the subtree rooted at u and let s s x y and let m be the length of s Then l u i in 1 m s i u and s i 1 u or s i u and s i 1 u That is l u counts how many times the subsequence s hops from the left subtree of u to the right subtree or vice versa The sum of the l u s is a lower bound on the number of rotations that must be done to access sequence s if no deletions are done A key part of the argument is that if s i u and s i 1 u then at some point between the access of s i and the access of s i 1 there had to be a rotation of some node c u over some node d u Furthermore such a rotation has no affect on the generalized subtrees T x u and T u y corresponding to the leaves of u s left and right subtrees so it is not already counted in the scores of u s children See 1 for the definition of a generalized subtree But suppose now that we allow standard deletions If for example s i is at the root has s i 1 as its right child and has no left child then after accessing s i we can access s i 1 simply by deleting s i No rotations had to be done at all One might try to fix this by counting deletions of nodes in x y in the score l u but this doesn t work because such such deletions would be doubled counted in some of u s children In other words either T x u or T u y is affected by any deletion of a node in x y To fix the lower bound note that if there is some j i such that s j s i then even if s i is deleted it has to be the case that between the access of s i u and the access of s i 1 u there s going to be a rotation of a node c u over a node d u Use the first rotation after the access of s i that causes s j to have an ancestor that is u no standard deletion can cause this to happen Given sequence s of length m say that i in 1 m is an end access for s if either s j s i for all j in i 1 m or else s j s i for all j in i 1 m That is i is not an end access if for some j1 j2 i s j1 s i and s j2 s i Intuitively end accesses are the nodes we can get out of the way by deletion Modify the score for u as follows l u i in 1 m s i u and s i 1 u or s i u and s i 1 u and i is not an end access in subsequence s Now the lower bound goes through using l u rather than l u because we only count a rotation for u when s i u and s i 1 u and there is some j i with s j u Or else s i u and s i 1 u and there is some j i with s j u For the bit reversal permutation it is convenient to index the sequence from so that s i bit reversal i For a bit reversal sequence on k bits it is easy to show that there are only k 1 end accesses These are at those j elements s i equal to 2 1 for some j in k So the score assigned to a node u at the j th level of the lower bound tree whose subsequence is a bit reversal permutation on j bits is j l u 2 1 j 1 k j The j th level of Y has 2 nodes so summing all the scores we get k j j k L 2 2 j 2 k 4 2 k 4 1 j k k With n 2 this gives an Omega n log n lower bound So any algorithm that sorts a Jordan sequence by inserting the elements into a binary tree maintained via rotations requires n log n time Note that at any single internal node u of the the lower bound tree the subtracting out of the end accesses can cause a radical reduction in u s score For example if the subsequence for u 1 5 is 1 2 2 19 3 18 4 17 5 16 6 15 7 14 8 13 9 12 1 11 then l u 19 but l u Indeed if the nodes are in the following zig zag binary tree 1 2 2 19 3 They can be accessed in the stated order solely through standard deletions with no rotations Question Are there sequences of n nodes where the lower bound for accessing with deletions is d n and the lower bound for accessing without deletions is not O d n n Such a sequence will need many end accesses in many of its subsequences 1 R Wilber Lower Bounds for Accessing Binary Search Trees With Rotations SIAM J Computing 18 1 1989 pp 56 67 2 R Tarjan Sequential Access in Splay Trees Takes Linear Time Combinatorica 5 1985 pp 367 378 From rew lightstone com Bob Wilber at PUMICE Newsgroups comp theory Subject Re 2 Jordan Sequences for which Splay Sort is n log n Date 1 Oct 1995 13 28 32 5 Organization UTexas Mail to News Gateway There is a statement I made in my last post that needs some correction and clarification Paul Callahan said In the following I m going to use the claim that sorting a sequence by inserting it into a binary tree is as hard as accessing the same sequence in a tree containing these values I haven t proved this but it seems to me that each time a value is inserted a new leaf added at what was a null pointer one could imagine that that value already existed as a node in the tree but had not previously been accessed It should thus be possible to construct an initial tree containing the values to be sorted for which the rotation sequence is the same whether one is inserting into an intially empty tree or accessing from an initally full tree Originally I had a more complicated idea for a proof that would not require this claim but I think it is true and it results in a cleaner argument and I said I believe your claim is false It is clear that the model of insertion that Callahan had in mind is that nodes are always inserted as leaves in the appropriate part of the tree It that case his claim is easily proven to be true Starting from an empty tree carry out a sequence of rotations and insertions of new leaves until all nodes have been inserted creating some tree T Now carry out the sequence backward starting from T except that when you would delete a leaf the backwards version of inserting it instead leave the node in place and mark it as deleted Subsequent rotations in the backwards sequence do not involve any marked leaves Furthermore leaves marked as deleted stay at the fringe of the tree that is it is never the case that a marked leaf has an unmarked leaf as a child So the backward sequence of rotations can be carried out In the final tree all nodes are marked This is the tree that satisfies the claim What I had in mind was a more general model of insertion namely the reverse of standard deletions and it is with this more general type of insertion that the claim appears to be false A standard insertion of a node v into a tree T is defined as follows 1 Let x be the largest node v in T and let y be the smallest node v in T For now assume that v is neither smaller than every node in T nor bigger than every node in T 2 Either x is an ancestor of y or y is an ancestor of x Assume the former Let u x u 1 u 2 u k y be the path from x to y u 1 is the right child of x and for i 1 u i is the left child of u i 1 Node v can be made a child of any one of the u i s If it is made a child of x it is a right child otherwise it is a left child v has no left child and is given u i 1 as a right child unless i k in which case v is a leaf 3 If v is less than every node in T we can either make v the root with T as its right subtree or can insert v as a left child of any of the nodes along the leftmost path of T Similarly when v is greater than every node in T 4 The cost of a standard insertion is the cost of following the path from the root to v after v is inserted Note that the argument used above to prove Callahan s claim for insertions of leaves doesn t work for the more general type of insertion because marked nodes might be left in the middle of the tree with unmarked nodes as children and this can make subsequent rotations in the reverse sequence invalid It is trivial to emulate a splay tree insertion by means of rotations and a standard insertion with no change in the cost of the operation I don t see any way to emulate a splay tree insertion with rotations and an insertion of a leaf while retaining the original cost So the patched up lower bound of my previous post seems to be necessary to be able to claim that a splay sort of a bit reversal permutation or of a Jordan sequence requires n log n time From callahan biffvm cs jhu edu Paul Callahan Newsgroups comp theory Subject Re Re 2 Jordan Sequences for which Splay Sort is n log n Date 2 Oct 1995 11 49 2 4 Organization The Johns Hopkins University CS Department In article 6edc 8 lightstone com Bob Wilber at PUMICE rew lightstone com wrote There is a statement I made in my last post that needs some correction and clarification It is clear that the model of insertion that Callahan had in mind is that nodes are always inserted as leaves in the appropriate part of the tree It that case his claim is easily proven to be true What I had in mind was a more general model of insertion namely the reverse of standard deletions and it is with this more general type of insertion that the claim appears to be false OK this is a point I hadn t considered so I guess things are a bit more complicated than I had hoped As I mentioned I had a backup argument This relied on a different claim that seemed clear at the time namely that to insert an element into a binary tree one must access either its successor or predecessor in symmetric order Now that you bring up the issue of general insertions even the latter claim seems less clear to me because it is only true in the case of leaf insertions that one must link the node directly to either its successor or predecessor However it should still hold because one cannot certify that a node is being inserted into the correct place without having seen its successor and predecessor at least assuming no extra information is maintained in the tree Anyway instead of bounding the rotations from the very beginning we can simply ignore the cost of inserting the first half of the bit reversed sequence even valued elements Then to bound the cost of inserting the remaining odd valued elements we would find the cost of accessing any sequence of successors or predecessors of these elements which I think should be Omega n log n Since the above poster seems to have patched up my argument to his own satisfaction there is probably no need for this especially if the correspondence between his name and the author of one of the cited papers is not coincidental Actually this brings up another unstated assumption I would have to use which is that the cost of accessing any subsequence of n 2 elements from a list of n elements in bit reversed order is Omega n log n I would be surprised if this were not true but I don t know the best way of proving it Clearly there are some sequences that are hard to access but which contain an easy subsequence of length n 2 but intuitively it looks like any subsequence of a bit reversed permutation should have the same property of breaking down the kind of locality of reference needed to obtain o n log n rotations I d appreciate any insight into this I suspect that the machinery needed for the lower bound on bit reversed sequences would be sufficient but maybe there is a simpler argument Paul Callahan callahan cs jhu edu The first principle in science is to invent something nice to look at and then decide what it can do Rowland Emett From rew lightstone com Bob Wilber at PUMICE Newsgroups comp theory Subject Re Jordan Sequences for which Splay Sort is n log n Date 3 Oct 1995 14 34 15 5 Organization UTexas Mail to News Gateway I wrote What I had in mind was a more general model of insertion namely the reverse of standard deletions and it is with this more general type of insertion that the claim appears to be false Paul Callahan wrote OK this is a point I hadn t considered so I guess things are a bit more complicated than I had hoped As I mentioned I had a backup argument This relied on a different claim that seemed clear at the time namely that to insert an element into a binary tree one must access either its successor or predecessor in symmetric order Now that you bring up the issue of general insertions even the latter claim seems less clear to me because it is only true in the case of leaf insertions that one must link the node directly to either its successor or predecessor However it should still hold because one cannot certify that a node is being inserted into the correct place without having seen its successor and predecessor at least assuming no extra information is maintained in the tree Well this brings up an issue that arises with any sort of lower bound what s the right model When inserting node v in a tree that contains immediate predecessor x and immediate successor y it is arguable that one should charge for the cost of finding both x and y in order to certify that v is being inserted in a legal spot let s call these two nodes bounds v Instead for standard insertions I charge the cost of following the path from the root to the newly inserted node My reasons for choosing the cost model I did are as follows 1 Symmetry The cost of a standard insertion is the same as the cost of a standard deletion of the same node in the time reversed sequence It is clear that when deleting node v it is not necessary to charge for finding bounds v 2 Generality This is a more generous cost model than the one that charges for finding bounds v so any lower bound obtained with this cost model will apply to a broader class of algorithms In principle an algorithm doesn t need to look for bounds v For example store the minimum and maximum values in the entire tree and in addition store with each non root node v the minimum value of the subtree it is a root of if v is a right child of its parent or the maximum value of the subtree it is a root of if v is a left child of its parent With these values we can verify the validity of an insertion while only having to look as far as the child of the node being inserted These values can be maintained in constant time under rotations For example if x is a left child of z and y is a right child of x then when x is rotated over z x gets z s old extremum value either a minimum or a maximum z gets y s old minimum and y gets x s old maximum When a standard deletion or insertion is done the cost of making the required updates of extrema can be charged against the cost of following the path from the root to the inserted or deleted node Most balanced search tree algorithms need some sort of extra information in the tree For example red black trees need a bit per node that tells whether they re red or black splay trees are unusual in that they don t have any such extra information So while storing one extra value in each node is more overhead than some other search algorithms have it seems arbitrary to reject out of hand algorithms that do that And there might be a less costly way to avoid looking at bounds v 3 Simplicity If I charge for finding bounds v I have to figure out what bounds v is For a highly regular sequence like the bit reversal permutation this is easy but in general it might be harder than counting end accesses Anyway instead of bounding the rotations from the very beginning we can simply ignore the cost of inserting the first half of the bit reversed sequence even valued elements Then to bound the cost of inserting the remaining odd valued elements we would find the cost of accessing any sequence of successors or predecessors of these elements which I think should be Omega n log n Well yes if for inserting each node v you charge for accessing bounds v I believe this works For the second half of the bit reversal permutation br n 2 br n 2 1 br n 1 the nodes accessed are bounds br n 2 bounds br n 2 1 bounds br n 1 from which we can extract the subsequence br br 1 br n 2 1 And this takes Omega n log n time to access A complicating factor is that as you proceed nodes are being inserted into the tree you re not just doing accesses but I don t think this affects the validity of the lower bound proofs This is sufficient to establish a bound on splay sorting since a splay insertion of v does in fact access bounds v Since the above poster seems to have patched up my argument to his own satisfaction there is probably no need for this especially if the correspondence between his name and the author of one of the cited papers is not coincidental The probability of two people with my name looking at this problem is low Actually this brings up another unstated assumption I would have to use which is that the cost of accessing any subsequence of n 2 elements from a list of n elements in bit reversed order is Omega n log n I would be surprised if this were not true but I don t know the best way of proving it I thought this was self evident Suppose I can access some sequence s 1 s 2 s n in time f n Then the same algorithm also accesses any subsequence s i 1 s i 2 s i k in time f n Just ignore the accesses you don t care about So any lower bound on accessing the subsequence is necessarily a lower bound on accessing the full sequence From callahan condor cs jhu edu Paul Callahan Newsgroups comp theory Subject Re Jordan Sequences for which Splay Sort is n log n Date 3 Oct 1995 17 23 32 4 Organization The Johns Hopkins University CS Department In article 718e6e lightstone com Bob Wilber at PUMICE rew lightstone com wrote I thought this was self evident Suppose I can access some sequence s 1 s 2 s n in time f n Then the same algorithm also accesses any subsequence s i 1 s i 2 s i k in time f n Just ignore the accesses you don t care about So any lower bound on accessing the subsequence is necessarily a lower bound on accessing the full sequence Actually I meant that the bound should also hold in the other direction for bit reversed sequences What I want to show is that the lower bound for the full bit reversed sequence is to within a constant a lower bound for any subsequence containing half the elements There are sequences for which this doesn t hold For example interleave a bit reversed sequence with a sequence in increasing order Then the full sequence requires Omega n log n rotations for access but it contains a subsequence the one in increasing order that requires O n rotations But what I m claiming is that the bit reversed sequence does not contain any such easy sequence as a subsequence Is this true Paul Callahan callahan cs jhu edu The first principle in science is to invent something nice to look at and then decide what it can do Rowland Emett From rew lightstone com Bob Wilber at PUMICE Newsgroups comp theory Subject Re Jordan Sequences for which Splay Sort is n log n Date 4 Oct 1995 11 59 49 5 Organization UTexas Mail to News Gateway Actually I meant that the bound should also hold in the other direction for bit reversed sequences What I want to show is that the lower bound for the full bit reversed sequence is to within a constant a lower bound for any subsequence containing half the elements There are sequences for which this doesn t hold For example interleave a bit reversed sequence with a sequence in increasing order Then the full sequence requires Omega n log n rotations for access but it contains a subsequence the one in increasing order that requires O n rotations But what I m claiming is that the bit reversed sequence does not contain any such easy sequence as a subsequence I this true I suspect that it is but I don t have a proof However you don t need such a strong claim for your proof to work Let s look at it again We have a proof that accessing a bit reversal permutation of length n via a binary search tree algorithm requires c n log n time for some c We insert into an initially empty tree a bit reversal permutation on k bits k with n 2 elements We want to show that inserting the last n 2 elements requires accessing the n 2 nodes already in tree in bit reversal order Fix k at 4 When br n 2 1 is inserted we must access the lower of bounds 1 namely the lower of and 1 The higher of these two nodes is an ancestor of the lower so we actually visit both and are free to charge for accessing either one So charge for acessing When we insert br n 2 1 1 1 we must access 1 and 1 1 Charge for 1 When we insert br n 2 1 1 1 we must access 1 and 11 Charge for 1 The sequence of accesses we charge for 1 1 11 111 is a full bit reversal permutation on k 1 bits the k th bit being fixed at with no missing elements So this takes c n 2 log n 2 Omega n log n time The only lower bound being applied here is to a complete bit reversal permutation not some arbitrary subsequence of a bit reversal permutation ", "_id": "http://www.ics.uci.edu/~eppstein/junkyard/jordan-splay.html", "title": "", "html": "<HR><PRE>\n<B>From:</B>           <A HREF=\"mailto:callahan@condor.cs.jhu.edu\">callahan@condor.cs.jhu.edu</A> (Paul Callahan)\n<B>Newsgroups:</B>     comp.theory\n<B>Subject:</B>        Jordan Sorting with Splay Trees conjecture\n<B>Date:</B>           12 Aug 1995 13:40:08 -0400\n<B>Organization:</B>   The Johns Hopkins University CS Department\n</PRE><HR><PRE>\nJordan Sorting is the problem of sorting a list of numbers by\nx-coordinate, assuming that the numbers represent intersections of a\nnon-self-intersecting (i.e. Jordan) curve with the x-axis, and that\nthey are given in the order that they appear along this curve.  It has\nbeen known for about a decade (as far as I my research has determined)\nthat Jordan Sorting can be performed in linear time.\n\nWhat I'm curious about is the following conjecture given in a\npaper that presents a linear time algorithm (reference given below):\n\n    Our second remark is that there may be a much simpler way\n    to sort Jordan sequences in linear time: we merely insert\n    the items in the sequence one-at-a-time into a splay tree \n    ... and then access them in sorted order.  ... On the basis\n    of Sleator and Tarjan's dynamic optimality conjecture, we \n    conjecture than this sorts Jordan sequences in O(n) time.\n\nThis is from \"Sorting Jordan Sequences in Linear Time Using\nLevel-Linked Search Trees\" (Hoffman, Mehlhorn, Rosensteihl, and\nTarjan, _Information and Control_ 68 (1986) pp.170--184).\n\nSeveral later papers claim to present simpler algorithms, but the\nmost recent one I've seen (1990) is still not nearly as simple\nas the approach using splay trees.  So, I'm curious if this\nconjecture has been treated either theoretically or experimentally.\n\nFrom a theoretical perspective, one would think that if the conjecture\nis true, it would at least be easier to prove than the dynamic\noptimality conjecture, and would still be a pretty interesting result.\n\nIt strikes me as even more attractive as an experimental issue,\nthough, because there is existing code for splay trees, and random\nJordan sequences are not hard to generate (of course, this leaves open\nthe issue of generating \"hard\" cases of Jordan Sorting).  In a sense,\nthere's no excuse at all for not performing this experiment.  My\nliterature search was far from exhaustive, so if there are\nexperimental results, I'd very much appreciate a reference.\n\nIt seems to me that if the conjecture is actually true, then one could\nperhaps make a careful study of the splay tree algorithm for Jordan\nSorting and try to infer what it is doing to achieve such good\nresults.  This would provide a non-trivial linear time algorithm that\nin some sense \"exists in nature\" rather than being the consequence of\nclever design.  If true, that strikes me (and some other people, I\nhope) as quite remarkable despite the fact that it would do no better\nthan a known optimal algorithm.\n\n-- \n        --- Paul Callahan --- <A HREF=\"mailto:callahan@cs.jhu.edu\">callahan@cs.jhu.edu</A> ---\n\n\"The first principle in science is to invent something nice to look at \n and then decide what it can do.\" -- Rowland Emett\n</PRE><HR><PRE>\n<B>From:</B>           <A HREF=\"mailto:callahan@biffvm.cs.jhu.edu\">callahan@biffvm.cs.jhu.edu</A> (Paul Callahan)\n<B>Newsgroups:</B>     comp.theory\n<B>Subject:</B>        A family of Jordan Sequences for which Splay Sort is Omega(n log n)\n<B>Date:</B>           25 Sep 1995 14:13:09 -0400\n<B>Organization:</B>   The Johns Hopkins University CS Department\n</PRE><HR><PRE>\nAbout a month and a half ago, I posted an inquiry about a conjecture\nrelated to sorting Jordan sequences.  A Jordan sequence is a list of\nintersections of a non-self-intersecting plane curve with the x-axis.\nThe Jordan sequence sorting problem is to sort these intersections by\nx coordinate.  The non-crossing-curve restriction implies that the\nnumber of Jordan sequences of n values is O(c^n) for some c, rather\nthan n!, implying that a general-purpose comparison-based sorting\nalgorithm may not be optimal. In fact has been known for over a decade\nthat Jordan sequences can be sorted in O(n) time using only\ncomparisons (I emphasize the point about comparisons to avoid getting\nmired in the MSD-radix-sort flame war now in progress).\n\nAnyway, there is an appealing conjecture in two of the papers\npresenting linear time algorithms (Information and Control, 68 170-184\n(1986) and Information Processing Letters 35 85-92 (1990)) that if the\nvalues in a Jordan Sequence are simply inserted into a splay tree, and\nread off in sorted order, then this might also require O(n) time in\nthe worst case.  This general technique is usually called Splay Sort,\nand can for certain kinds of input be shown to require much less time\nthan a worst-case optimal comparision-based sort such as Mergesort.\nIf I understand the Jordan Sequence conjecture correctly, I can show that it is\nincorrect.  \n\nI don't know if the following result is new, but it's fairly\nspecialized and doesn't seem to lead anywhere, so I'm posting it here\nafter wondering for about a month what to do with it.  Because this posting\nnot a formal publication, I'm going to leave out some steps.  It\nshould not be too hard to fill in the details.  \n\nFirst, to prove a lower bound on sorting a sequence using Splay Sort,\nit will suffice to prove a lower bound for any algorithm that uses\ninsertions into a binary search tree using any rotation strategy.  In\nfact, the more general kind of lower bound is often easier to prove\nthan a lower bound for Splay Sort itself, owing to the work of Robert\nWilber in FOCS '86 (revised version in Siam J Comp vol. 18 no. 1),\nwhich provides two powerful methods for showing lower bounds on\naccessing sequences of values in Binary Search Trees.  We will not\nreally need these methods here, but only the corollary that accessing\nthe nodes of a binary tree containing the values 0,1,...,2^k-1 in\nbit-reversed order (i.e. taking the binary representations of these\nvalues in increasing order but reversing the \"significance\" of the\nbits) requires Omega(k 2^k) rotations\n\nIn the following, I'm going to use the claim that sorting a sequence by\ninserting it into a binary tree is as hard as accessing the same\nsequence in a tree containing these values.  I haven't proved this,\nbut it seems to me that each time a value is inserted (a new leaf\nadded at what was a \"null pointer\"), one could imagine that that value\nalready existed as a node in the tree but had not previously been\naccessed.  It should thus be possible to construct an initial tree\ncontaining the values to be sorted for which the rotation sequence is\nthe same whether one is inserting into an intially empty tree, or\naccessing from an initally full tree.  (Originally, I had a more\ncomplicated idea for a proof that would not require this claim\nbut I think it is true, and it results in a cleaner argument).\n\nNow, what remains is simply to construct a family of \"hard\" Jordan\nSequences such that for any value of n there is a sequence in this\nfamily containing at least n elements.  As it happens, the sequences\nin this family will bear a relationship to bit-reversed order that\nwill cause them to require Omega(n log n) rotations to sort using any\nbinary search tree, according to the result of Wilber.\n\nFirst I'll give an intuitive explanation of where these sequences come\nfrom.  If one were to take a looped, flattened out strip of paper and\nview it facing the edge, this would look like a very simple Jordan\nCurve.  I.e.:\n\n             +---------------------------------------+\n             |                                       |\n             +---------------------------------------+\n\n(unfortunately, ASCII graphics make it unclear, so let me repeat that\nthis is viewed on edge, not from above, as it might also appear).\n\nIf this is folded over on itself to double its thickness, we\nget another Jordan Curve, but which is somewhat more convoluted.\n\n       I.e:\n\n            +-------------------+\n            |                   |\n            +---------------+   |\n                            |   |\n            +---------------+   |\n            |                   |\n            +-------------------+\n\nWe can repeat this \"doubling over\" process as many times as we like,\neach time doubling the number of intersections of the curve with\na vertical line.  For larger examples, it becomes more convenient to\nrepresent the shape of the curve using two sets of matching\nparentheses (this is the representation normally used to prove a bound on the\nnumber of Jordan Sequences).  E.g., if we double over two more times,\nand rotate 90 degrees so the curve intersects the x-axis, we obtain:\n\n            (((((((())))))))\n            ()()(())(((())))\n\nMatching parentheses in the top sequence with arcs above and those in\nthe bottom sequence with arcs below gives us the actual curve.\n\nTo connect this idea with bit-reversed order, we will describe the\nfolding process as a transformation on a sequence of numbers that will\ndenote the actual Jordan Sequence in question.  The correspondence to\nfolding is not too hard to see, but will be omitted here, since it\nis not really needed once we obtain the final form of the construction.\n\nFirst, in the original loop, the sequence of intersections is the same\nboth on the curve and on the intersecting line, so we denote this\nsequence 0 1.\n\nNow, given such a sequence, we obtain the next, doubled over, sequence\nas follows:\n\n    (1) double each number in the sequence\n    (2) append the new sequence to its own reverse\n    (3) Add 1 to every odd-positioned number in the sequence\n        (the leftmost position is considered even).\n\nE.g.\n\n     0 1   --&gt;    0 2        by (1)\n           --&gt;    0 2 2 0    by (2)\n           --&gt;    0 3 2 1    by (3)\n\n     0 3 2 1  --&gt;  0 6 4 2   \n              --&gt;  0 6 4 2 2 4 6 0\n              --&gt;  0 7 4 3 2 5 6 1\n\n     0 7 4 3 2 5 6 1  --&gt;  0 14 8 6 4 10 12 2\n                      --&gt;  0 14 8 6 4 10 12 2 2 12 10 4 6 8 14 0\n                      --&gt;  0 15 8 7 4 11 12 3 2 13 10 5 6 9 14 1\n\n     etc.\n\nHere I'll resort to \"proof by example\" and simply point out that\nif you take the increasing sequence:\n\n       0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15\n\nand connect pairs of numbers adjacent in the sequence obtained in the\nprocess above with non-crossing arcs (also connecting the end values\n0 and 1) you will obtain the Jordan Curve determined by the set of \nmatching parentheses given earlier.\n\nRecall that for the lower bound, we want to connect this in some way\nto bit reversed order.  So, yet another way to obtain the above\nsequence is to define the following function f on k-bit binary numbers\ndenoted B = b    ... b\n             k-1      0\n\nIn the following, assume \"+\" denotes exclusive-or, and let\n\n            f(b   ... b )  = (b + b ) (b + b) ... (b   +b ) b0\n               k-1     0       1   0    2   0       k-1  0\n\nIn other words, reverse the order of bits 1 through k-1, keeping b\n                                                                  0\n\nin the same position.  Also, if b  = 1, then invert bits 1 through k-1.\n                              0\n\nE.g.,\n\n       B     f(B)\n      ---    ---\n      000    000\n      001    111   \n      010    100\n      011    011\n      100    010\n      101    101\n      110    110\n      111    001\n\nNow, to get the kth sequence determined by the process given\npreviously, we merely take the values i = 0,...,2^k-1 expressed in\nbinary, and apply the function f to each i in increasing order.  (We\noverload the meaning of f(i) to denote the result of converting i to a\nbinary string, applying f, and converting it back to an integer.)  It\ncan be seen that from the above table, the sequence for k=3 is \n0 7 4 3 2 5 6 1, which corresponds to that obtained previously.\n\nI imagine a lot of readers on this newsgroup don't find examples very\nconvincing, no matter how large they are and how nicely they work out.\nFortunately, once the function f has been defined as above, it\nsuffices to show only that the sequence f(0), f(1), ..., f(2^k-1) is a\nJordan Sequence, which is an easier task than showing it corresponds\nto the particular Jordan sequences illustrated earlier.\n\nTo do this, it is necessary to show that if the numbers 0,1,...,2^k-1\nare written in order left to right, then adjacent numbers in the sequence\nf(0),f(1), ..., f(2^k-1) can be connected by non-crossing arcs alternating\nabove and below the list of numbers.\n\nA key observation needed for such a proof is that two arcs, one from \na to b, and another from c to d cannot cross so long as a+b = c+d.  The\nother is that they cannot cross if a &lt; b &lt; c &lt; d.  The set of arcs\nfrom a to b can be put in k+1 equivalence classes according to a+b, so\nthat there is no crossing within each equivalence class.  The second\nobservation can then be used to exclude crossings between arcs in\ndistinct equivalence classes.\n\nSo, if I were writing a more rigorous article, it would now say something like\n\"Lemma: For all k<U>&gt;</U>0, the sequence f(0),f(1),...,f(2^k-1) is a\nJordan Sequence.\"  This would be followed by a proof, which is here\nleft as an exercise.\n\nWhat remains is to show that it requires Omega(k 2^k) comparisons to\nsort such a sequence using Splay Sort.  This can be seen by\nconsidering only those f(i) such that i is even.  Let R(i) denote the\nresult of reversing the order of the bits in the binary representation\nof i.  By definition of f, we know that for even values of i,\nf(i)=2*R(i/2), so the subsequence f(0), f(2), ..., f(2^k-2) must be in\nbit-reversed order.  Since the sequence f(0),f(1),...,f(2^k-1)\ncontains 2^(k-1) elements in bit-reversed order, the result of Wilber\nimplies that the time to access such a sequence in a binary search\ntree is Omega((k-1)2^(k-1)), and this also provides a bound on the time\nto sort the sequence using Splay Sort.\n\nThen, it follows that there exists a c such that for any value of n,\none can construct a Jordan Sequence of length greater than n that\nrequires c n log n comparisons to sort using Splay Sort, refuting the\nconjecture (as I understood it) that Splay Sort is a linear time\nalgorithm for sorting Jordan Sequences.\n\n-- \n        --- Paul Callahan --- <A HREF=\"mailto:callahan@cs.jhu.edu\">callahan@cs.jhu.edu</A> ---\n\n\"The first principle in science is to invent something nice to look at \n and then decide what it can do.\" -- Rowland Emett\n</PRE>\n<HR><PRE>\n<B>From:</B>           <A HREF=\"mailto:rew@lightstone.com\">rew@lightstone.com</A> (Bob Wilber at PUMICE)\n<B>Newsgroups:</B>     comp.theory\n<B>Subject:</B>        Re: Jordan Sequences for which Splay Sort is Omega(n log n)\n<B>Date:</B>           27 Sep 1995 15:57:48 -0500\n<B>Organization:</B>   UTexas Mail-to-News Gateway\n</PRE><HR><PRE>\nPaul Callahan showed that a bit reversal permutation can be imbedded in a\nJordan sequence.\n\n&gt;In the following, I'm going to use the claim that sorting a sequence by\n&gt;inserting it into a binary tree is as hard as accessing the same\n&gt;sequence in a tree containing these values.  I haven't proved this,\n&gt;but it seems to me that each time a value is inserted (a new leaf\n&gt;added at what was a \"null pointer\"), one could imagine that that value\n&gt;already existed as a node in the tree but had not previously been\n&gt;accessed.  It should thus be possible to construct an initial tree\n&gt;containing the values to be sorted for which the rotation sequence is\n&gt;the same whether one is inserting into an intially empty tree, or\n&gt;accessing from an initally full tree.\n\nThis is the crux of the matter -- can the lower bound in [1] be used to\nget an an Omega(n log n) lower bound on Jordan sorting via insertion into\na symmetrically ordered binary tree?  That lower bound assumed that all\nelements are in the tree at the start, that they are being accessed in some\nspecified order (allowing rotations in the tree), and that no insertions or\ndeletions are done.\n\n&gt;(Originally, I had a more\n&gt;complicated idea for a proof that would not require this claim\n&gt;but I think it is true, and it results in a cleaner argument).\n\nI believe your claim is false.  But I think the lower bound can be patched\nup to work for this case.\n\nConsider how Jordan sorting with a binary tree proceeds:\n\nFirst, we traverse the simple closed curve, each time we encounter an \nintersection with the x axis, we insert that intersection point into a binary\ntree that is symmetrically ordered by the x coordinate.\n\nSecond, we access the items in the tree, in order by x coordinate.\n\nAt the end of the first pass the items are sorted by x coordinate, so the\nsecond pass accesses the nodes in sequential order.  This pass takes linear\ntime, including when the splay algorithm is used to do the accessing, as was\nproved by Tarjan [2].\n\nSo any lower bound must be applied to the first pass, when the items are\nbeing inserted.  I find it convenient to \"reverse the film\" -- items are\ninserted into a tree in sequential order by x coordinate, in linear time,\nand then they are deleted in the order they appear on the curve (that is,\ndeleted according to a Jordan sequence).  We want to show that the deletion\nphase takes n log n time.\n\nWe need to extend the model to allow for deletions.  I think the following\ndefinition covers all the cases:\n\nDefinition:  A *standard deletion* of a node v can occur when v has at most\none child.  In that case, if v has no children (it is a leaf) it is simply\nremoved.  Otherwise v is removed and v's only child is made a child of v's\nparent (if v was not the root) or is made the root (if v was the root).\n\nIn general, to delete a node v you do some sequence of rotations so that\nv has at most one child, and then you do a standard deletion of v.\n\nFor example, as I recall deletion of a node v in a splay tree proceeds as\nfollows:\n\n1.  v is splayed to the root and removed, leaving its left and right subtrees,\n    L and R.\n\n2.  The largest node in L, r, is splayed to the root of L.\n\n3.  R is made the right subtree of r.\n\nThis can be cast into the \"standard model\" as follows:\n\n1.  v is splayed to the root.  Its left subtree is L.\n\n2.  The largest node in L, r, is splayed to the root of L, making r the left\n    child of v.\n\n3.  r is rotated over v.\n\n4.  v has no left child; a standard deletion of v is done.\n\nClearly this has the same complexity as the usual deletion routine.\n\nIn the model when we delete v we must also count the cost of accessing v from\nthe root.  In order to fold all the costs into rotations, we require that the\nalgorithm be \"normalized\" so that before deleting any node it first rotates\nthat node to the root.  This can always be done without increasing the\ntime by more than a constant factor, because if the original algorithm does\na standard deletion of some node v at depth d, it could first rotatate v to\nthe root, then rotate v back to where it was (using 2d - 2 rotations), and\nthen delete v.  The cost of the extra rotations is just a constant times the\ncost of following the path from the root to v.  Likewise a look up of v is\nalways done by rotating v to the root.\n\nTwo lower bound methods were given in [1], I will only patch up the first one\n(both methods give an Omega(n log n) bound for accessing the bit reversal\npermutation).\n\nIt is important to understand that the intuition behind both lower bounds is\nthat items you access \"get in the way\" of items that you want to access later,\nand must be rotated over.  But if you can delete nodes, you can sometimes get a\nnode v out of the way by deleting it, which might be cheaper than forcing\nseveral nodes \"underneath\" to rotate over v.  So the ability to shrink the\ntree as you go might invalidate the lower bounds given in [1].\n\nHere's a very quick review of the first lower bound method.  We have some\nbinary search tree T, whose n nodes may be considered to be consecutive\nintegers.  We allow rotations and standard deletions on T.  A lower bound tree\nY with 2n - 1 nodes is constructed whose leaves are the initial nodes of T and \nwhose internal nodes lie between nodes in T, that is, they may be taken to be \nhalf integers.  T changes through rotations and deletions but Y is fixed.  For\ngetting the lower bound on the bit reversal permutation Y is taken to be a\nbalanced binary tree.  The sequence of nodes in T to be accessed is s[1], s[2],\n..., s[m].  (A node is \"accessed\" if we either look it up or delete it; in both\ncases such a node must be rotated to the root in a normalized algorithm.)\nGiven numbers x <U>&lt;</U> y, s{x, y} is the subsequence consisting of those s[i]s that\nare in the interval [x, y].  For each internal node u of Y, a score l(u) is\ncomputed as follows: Let x and y be the minimum and maximum leaves of the\nsubtree rooted at u, and let s' = s{x, y} and let m' be the length of s'.  Then\n\nl(u) = |{ i in [1, m'] | (s'(i) &lt; u and s'(i+1) &gt; u) or\n                         (s'(i) &gt; u and s'(i+1) &lt; u) }|.\n\nThat is, l(u) counts how many times the subsequence s' hops from the left\nsubtree of u to the right subtree, or vice versa.\n\nThe sum of the l(u)'s is a lower bound on the number of rotations that must\nbe done to access sequence s, if no deletions are done.\n\nA key part of the argument is that if s(i) &lt; u and s(i+1) &gt; u, then at some\npoint between the access of s(i) and the access of s(i+1) there had to be a\nrotation of some node c &gt; u over some node d &lt; u.  Furthermore, such a rotation\nhas no affect on the generalized subtrees T{x, u} and T{u, y} corresponding to\nthe leaves of u's left and right subtrees, so it is not already counted in\nthe scores of u's children.  (See [1] for the definition of a generalized\nsubtree.)\n\nBut suppose now that we allow standard deletions.  If, for example, s(i) is at\nthe root, has s(i+1) as its right child, and has no left child, then after\naccessing s(i) we can access s(i+1) simply by deleting s(i).  No rotations had\nto be done at all.  One might try to fix this by counting deletions of nodes in\n[x, y] in the score l(u), but this doesn't work because such such deletions\nwould be doubled counted in some of u's children.  In other words, either\nT{x, u} or T{u, y} is affected by any deletion of a node in [x, y].\n\nTo fix the lower bound note that if there is some j &gt; i such that s(j) <U>&lt;</U> s(i),\nthen even if s(i) is deleted it has to be the case that between the access of\ns(i) &lt; u and the access of s(i+1) &gt; u there's going to be a rotation of a node\nc &gt; u over a node d &lt; u.  (Use the first rotation after the access of s(i) that\ncauses s(j) to have an ancestor that is &gt; u; no standard deletion can cause\nthis to happen.)\n\nGiven sequence s of length m, say that i in [1, m] is an *end access* for s\nif either s(j) &gt; s(i) for all j in [i+1, m] or else s(j) &lt; s(i) for all\nj in [i+1, m].  That is, i is not an end access if for some j1, j2 &gt; i,\ns(j1) <U>&lt;</U> s(i) and s(j2) <U>&gt;</U> s(i).  Intuitively, end accesses are the nodes we\ncan get out of the way by deletion.\n\nModify the score for u as follows:\n\nl'(u) =  |{ i in [1, m] | ((s'(i) &lt; u and s'(i+1) &gt; u) or\n                           (s'(i) &gt; u and s'(i+1) &lt; u)) and\n                          i is not an end access in subsequence s'}|.\n\nNow the lower bound goes through, using l'(u) rather than l(u), because we\nonly count a rotation for u when s(i) &lt; u and s(i+1) &gt; u, and there is some\nj &gt; i with s(j) &lt; u.  (Or else s(i) &gt; u and s(i+1) &lt; u, and there is some\nj &gt; i with s(j) &gt; u.)\n\nFor the bit reversal permutation it is convenient to index the sequence from\n0, so that s(i) = bit_reversal(i).  For a bit reversal sequence on k bits,\nit is easy to show that there are only k+1 end accesses.  These are at those\n                        j\nelements s(i) equal to 2  - 1, for some j in [0, k].  So the score assigned\nto a node u at the j'th level of the lower bound tree, whose subsequence is a\nbit reversal permutation on j bits, is\n         j\nl'(u) = 2  - 1 - (j + 1).\n\n                         k-j\nThe j'th level of Y has 2    nodes, so summing all the scores we get\n      __\n      \\   k-j     j                    k\nL  =  /_ 2    * (2  - j - 2)  = (k-4)*2  + k + 4.\n  1 <U>&lt;</U> j <U>&lt;</U> k\n\n          k\nWith n = 2 ,  this gives an Omega(n log n) lower bound.\n\nSo any algorithm that sorts a Jordan sequence by inserting the elements into\na binary tree, maintained via rotations, requires n log n time.\n\nNote that at any single internal node u of the the lower bound tree the\nsubtracting out of the end accesses can cause a radical reduction in u's score.\nFor example, if the subsequence for u = 10.5 is\n    1 20 2 19 3 18 4 17 5 16 6 15 7 14 8 13 9 12 10 11\nthen l(u) = 19 but l'(u) = 0.\n\nIndeed, if the nodes are in the following \"zig-zag\" binary tree\n\n     1\n      \\\n       20\n      /\n     2\n      \\\n       19\n      /\n     3\n      \\\n       ...\n\nThey can be accessed in the stated order solely through standard deletions,\nwith no rotations.\n\nQuestion:  Are there sequences of n nodes where the lower bound for accessing\nwith deletions is d(n) and the lower bound for accessing without deletions is\nnot O(d(n) + n)?  Such a sequence will need many end accesses in many of its\nsubsequences.\n\n[1]  R. Wilber, \"Lower Bounds for Accessing Binary Search Trees With Rotations\"\n     SIAM J. Computing, 18(1) (1989) pp. 56-67.\n\n[2]  R. Tarjan, \"Sequential Access in Splay Trees Takes Linear Time\",\n     Combinatorica 5 (1985)  pp. 367-378.\n</PRE><HR><PRE>\n<B>From:</B>           <A HREF=\"mailto:rew@lightstone.com\">rew@lightstone.com</A> (Bob Wilber at PUMICE)\n<B>Newsgroups:</B>     comp.theory\n<B>Subject:</B>        Re[2]: Jordan Sequences for which Splay Sort is n log n\n<B>Date:</B>           1 Oct 1995 13:28:32 -0500\n<B>Organization:</B>   UTexas Mail-to-News Gateway\n</PRE><HR><PRE>\nThere is a statement I made in my last post that needs some correction and\nclarification.\n\nPaul Callahan said:\n&gt;In the following, I'm going to use the claim that sorting a sequence by\n&gt;inserting it into a binary tree is as hard as accessing the same\n&gt;sequence in a tree containing these values.  I haven't proved this,\n&gt;but it seems to me that each time a value is inserted (a new leaf\n&gt;added at what was a \"null pointer\"), one could imagine that that value\n&gt;already existed as a node in the tree but had not previously been\n&gt;accessed.  It should thus be possible to construct an initial tree\n&gt;containing the values to be sorted for which the rotation sequence is\n&gt;the same whether one is inserting into an intially empty tree, or\n&gt;accessing from an initally full tree.\n&gt;(Originally, I had a more\n&gt;complicated idea for a proof that would not require this claim\n&gt;but I think it is true, and it results in a cleaner argument).\n\nand I said\n&gt;I believe your claim is false...\n\nIt is clear that the model of insertion that Callahan had in mind is that nodes\nare always inserted as leaves in the appropriate part of the tree.  It that\ncase his claim is easily proven to be true.  Starting from an empty tree, carry\nout a sequence of rotations and insertions of new leaves until all nodes have\nbeen inserted, creating some tree T.  Now carry out the sequence backward,\nstarting from T, except that when you would delete a leaf (the backwards\nversion of inserting it), instead leave the node in place and mark it as\ndeleted.  Subsequent rotations in the backwards sequence do not involve any\nmarked leaves.  Furthermore, leaves marked as deleted stay at the fringe of the\ntree, that is, it is never the case that a marked leaf has an unmarked leaf as\na child.  So the backward sequence of rotations can be carried out.  In the \nfinal tree all nodes are marked.  This is the tree that satisfies the claim.\n\nWhat I had in mind was a more general model of insertion, namely, the reverse\nof \"standard deletions\", and it is with this more general type of insertion\nthat the claim appears to be false.  A standard insertion of a node v into a\ntree T is defined as follows:\n\n1.  Let x be the largest node &lt; v in T, and let y be the smallest node &gt; v in\n    T.  (For now assume that v is neither smaller than every node in T, nor\n    bigger than every node in T.)\n\n2.  Either x is an ancestor of y or y is an ancestor of x.  Assume the former.\n    Let u[0] = x, u[1], u[2], ..., u[k] = y be the path from x to y.  u[1] is\n    the right child of x and for i &gt; 1, u[i] is the left child of u[i-1].\n    Node v can be made a child of any one of the u[i]s.  If it is made a child\n    of x, it is a right child, otherwise it is a left child.  v has no left\n    child and is given u[i+1] as a right child (unless i = k, in which case\n    v is a leaf).\n\n3.  If v is less than every node in T, we can either make v the root (with T as\n    its right subtree) or can insert v as a left child of any of the nodes\n    along the leftmost path of T.  Similarly when v is greater than every node\n    in T.\n\n4.  The cost of a standard insertion is the cost of following the path from\n    the root to v after v is inserted.\n\nNote that the argument used above to prove Callahan's claim for insertions of\nleaves doesn't work for the more general type of insertion, because marked\nnodes might be left in the middle of the tree (with unmarked nodes as children)\nand this can make subsequent rotations in the reverse sequence invalid.\n\nIt is trivial to emulate a splay tree insertion by means of rotations and a\nstandard insertion, with no change in the cost of the operation.  I don't\nsee any way to emulate a splay tree insertion with rotations and an insertion\nof a leaf, while retaining the original cost.\n\nSo the \"patched up\" lower bound of my previous post seems to be necessary to be\nable to claim that a splay sort of a bit reversal permutation, or of a Jordan\nsequence, requires n log n time.\n</PRE><HR><PRE>\n<B>From:</B>           <A HREF=\"mailto:callahan@biffvm.cs.jhu.edu\">callahan@biffvm.cs.jhu.edu</A> (Paul Callahan)\n<B>Newsgroups:</B>     comp.theory\n<B>Subject:</B>        Re: Re[2]: Jordan Sequences for which Splay Sort is n log n\n<B>Date:</B>           2 Oct 1995 11:49:20 -0400\n<B>Organization:</B>   The Johns Hopkins University CS Department\n</PRE><HR><PRE>\nIn article &lt;06edc080@lightstone.com&gt;,\nBob Wilber at PUMICE &lt;<A HREF=\"mailto:rew@lightstone.com\">rew@lightstone.com</A>&gt; wrote:\n&gt;There is a statement I made in my last post that needs some correction and\n&gt;clarification.\n&gt;\n...\n&gt;It is clear that the model of insertion that Callahan had in mind is that nodes\n&gt;are always inserted as leaves in the appropriate part of the tree.  It that\n&gt;case his claim is easily proven to be true.  \n...\n&gt;What I had in mind was a more general model of insertion, namely, the reverse\n&gt;of \"standard deletions\", and it is with this more general type of insertion\n&gt;that the claim appears to be false.  \n\nOK, this is a point I hadn't considered, so I guess things are a bit\nmore complicated than I had hoped.  As I mentioned, I had a backup\nargument.  This relied on a different claim that seemed clear at the\ntime, namely that to insert an element into a binary tree, one must\naccess either its successor or predecessor in symmetric order.\n\nNow that you bring up the issue of general insertions, even the latter\nclaim seems less clear to me, because it is only true in the\ncase of leaf insertions that one must link the node directly to\neither its successor or predecessor.  However, it should still hold\nbecause one cannot certify that a node is being inserted into the\ncorrect place without having seen its successor and predecessor (at least\nassuming no extra information is maintained in the tree).\n\nAnyway, instead of bounding the rotations from the very beginning, we\ncan simply ignore the cost of inserting the first half of the\nbit-reversed sequence (even-valued elements).  Then, to bound the cost\nof inserting the remaining (odd-valued) elements, we would find the\ncost of accessing any sequence of successors or predecessors of these\nelements (which I think should be Omega(n log n)).  Since the above\nposter seems to have patched up my argument to his own satisfaction,\nthere is probably no need for this (especially if the correspondence\nbetween his name and the author of one of the cited papers is not\ncoincidental.)\n\nActually, this brings up another unstated assumption I would have to\nuse, which is that the cost of accessing *any* subsequence of n/2\nelements from a list of n elements in bit-reversed order is \nOmega(n log n).  I would be surprised if this were not true, but I don't know\nthe best way of proving it.  Clearly, there are some sequences that\nare \"hard\" to access but which contain an \"easy\" subsequence of length\nn/2, but intuitively it looks like any subsequence of a bit-reversed\npermutation should have the same property of breaking down the kind of\nlocality of reference needed to obtain o(n log n) rotations.  I'd\nappreciate any insight into this.  I suspect that the machinery\nneeded for the lower bound on bit-reversed sequences would be sufficient,\nbut maybe there is a simpler argument.\n\n-- \n        --- Paul Callahan --- <A HREF=\"mailto:callahan@cs.jhu.edu\">callahan@cs.jhu.edu</A> ---\n\n\"The first principle in science is to invent something nice to look at \n and then decide what it can do.\" -- Rowland Emett\n</PRE><HR><PRE>\n<B>From:</B>           <A HREF=\"mailto:rew@lightstone.com\">rew@lightstone.com</A> (Bob Wilber at PUMICE)\n<B>Newsgroups:</B>     comp.theory\n<B>Subject:</B>        Re: Jordan Sequences for which Splay Sort is n log n\n<B>Date:</B>           3 Oct 1995 14:34:15 -0500\n<B>Organization:</B>   UTexas Mail-to-News Gateway\n</PRE><HR><PRE>\nI wrote:\n&gt;What I had in mind was a more general model of insertion, namely, the reverse\n&gt;of \"standard deletions\", and it is with this more general type of insertion\n&gt;that the claim appears to be false.  \n\nPaul Callahan wrote:\n&gt;OK, this is a point I hadn't considered, so I guess things are a bit\n&gt;more complicated than I had hoped.  As I mentioned, I had a backup\n&gt;argument.  This relied on a different claim that seemed clear at the\n&gt;time, namely that to insert an element into a binary tree, one must\n&gt;access either its successor or predecessor in symmetric order.\n&gt;\n&gt;Now that you bring up the issue of general insertions, even the latter\n&gt;claim seems less clear to me, because it is only true in the\n&gt;case of leaf insertions that one must link the node directly to\n&gt;either its successor or predecessor.  However, it should still hold\n&gt;because one cannot certify that a node is being inserted into the\n&gt;correct place without having seen its successor and predecessor (at least\n&gt;assuming no extra information is maintained in the tree).\n\nWell, this brings up an issue that arises with any sort of lower bound --\nwhat's the right model?  When inserting node v in a tree that contains\nimmediate predecessor x and immediate successor y, it is arguable that one\nshould charge for the cost of finding both x and y, in order to certify that v\nis being inserted in a legal spot (let's call these two nodes bounds(v)).\nInstead, for standard insertions I charge the cost of following the path from\nthe root to the newly inserted node.  My reasons for choosing the cost model I\ndid are as follows:\n\n1.  Symmetry.  The cost of a standard insertion is the same as the cost of a\nstandard deletion of the same node in the time reversed sequence.  It is clear\nthat when deleting node v it is not necessary to charge for finding bounds(v).\n\n2.  Generality.  This is a more generous cost model than the one that charges\nfor finding bounds(v), so any lower bound obtained with this cost model will\napply to a broader class of algorithms.  In principle, an algorithm doesn't\nneed to look for bounds(v).  For example, store the minimum and maximum\nvalues in the entire tree, and in addition, store with each non-root node\nv the minimum value of the subtree it is a root of, if v is a right child of\nits parent, or the maximum value of the subtree it is a root of, if v is a\nleft child of its parent.  With these values we can verify the validity of an\ninsertion while only having to look as far as the child of the node being\ninserted.  These values can be maintained in constant time under rotations.\nFor example, if x is a left child of z and y is a right child of x, then when\nx is rotated over z, x gets z's old extremum value (either a minimum or a \nmaximum), z gets y's old minimum, and y gets x's old maximum.  When a standard\ndeletion or insertion is done, the cost of making the required updates of\nextrema can be charged against the cost of following the path from the root to\nthe inserted or deleted node.\n\nMost balanced search tree algorithms need *some* sort of extra information in\nthe tree.  For example, red-black trees need a bit per node that tells whether\nthey're red or black (splay trees are unusual in that they don't have any such\nextra information).  So, while storing one extra value in each node is more\noverhead than some other search algorithms have, it seems arbitrary to reject\nout of hand algorithms that do that.  And there might be a less costly way to\navoid looking at bounds(v).\n\n3.  Simplicity.  If I charge for finding bounds(v), I have to figure out what\nbounds(v) is.  For a highly regular sequence like the bit reversal permutation\nthis is easy, but in general it might be harder than counting end accesses.\n\n&gt;Anyway, instead of bounding the rotations from the very beginning, we\n&gt;can simply ignore the cost of inserting the first half of the\n&gt;bit-reversed sequence (even-valued elements).  Then, to bound the cost\n&gt;of inserting the remaining (odd-valued) elements, we would find the\n&gt;cost of accessing any sequence of successors or predecessors of these\n&gt;elements (which I think should be Omega(n log n)).\n\nWell, yes, if for inserting each node v you charge for accessing bounds(v)\nI believe this works.  For the second half of the bit reversal permutation,\nbr(n/2), br(n/2 + 1), ..., br(n-1), the nodes accessed are\nbounds(br(n/2)), bounds(br(n/2 + 1)), ..., bounds(br(n-1)), from which we can\nextract the subsequence br(0), br(1), ..., br(n/2 - 1).  And this takes\nOmega(n log n) time to access.  A complicating factor is that as you proceed,\nnodes are being inserted into the tree (you're not just doing accesses) but\nI don't think this affects the validity of the lower bound proofs.  This is\nsufficient to establish a bound on splay sorting, since a splay insertion of v\ndoes in fact access bounds(v).\n\n&gt;Since the above poster seems to have patched up my argument to his own\n&gt;satisfaction, there is probably no need for this (especially if the\n&gt;correspondence between his name and the author of one of the cited papers is\n&gt;not coincidental.)\n\nThe probability of two people with my name looking at this problem is low.\n\n&gt;Actually, this brings up another unstated assumption I would have to\n&gt;use, which is that the cost of accessing *any* subsequence of n/2\n&gt;elements from a list of n elements in bit-reversed order is \n&gt;Omega(n log n).  I would be surprised if this were not true, but I don't know\n&gt;the best way of proving it.\n\nI thought this was self evident.  Suppose I can access some sequence s[1],\ns[2], ..., s[n] in time f(n).  Then the same algorithm also accesses any\nsubsequence, s[i_1], s[i_2], ..., s[i_k] in time f(n).  (Just ignore the\naccesses you don't care about.)  So any lower bound on accessing the\nsubsequence is necessarily a lower bound on accessing the full sequence.\n</PRE><HR><PRE>\n<B>From:</B>           <A HREF=\"mailto:callahan@condor.cs.jhu.edu\">callahan@condor.cs.jhu.edu</A> (Paul Callahan)\n<B>Newsgroups:</B>     comp.theory\n<B>Subject:</B>        Re: Jordan Sequences for which Splay Sort is n log n\n<B>Date:</B>           3 Oct 1995 17:23:32 -0400\n<B>Organization:</B>   The Johns Hopkins University CS Department\n</PRE><HR><PRE>\nIn article &lt;0718e6e0@lightstone.com&gt;,\nBob Wilber at PUMICE &lt;<A HREF=\"mailto:rew@lightstone.com\">rew@lightstone.com</A>&gt; wrote:\n\n&gt;I thought this was self evident.  Suppose I can access some sequence s[1],\n&gt;s[2], ..., s[n] in time f(n).  Then the same algorithm also accesses any\n&gt;subsequence, s[i_1], s[i_2], ..., s[i_k] in time f(n).  (Just ignore the\n&gt;accesses you don't care about.)  So any lower bound on accessing the\n&gt;subsequence is necessarily a lower bound on accessing the full sequence.\n\nActually, I meant that the bound should also hold in the other\ndirection for bit-reversed sequences.  What I want to show is that the\nlower bound for the full bit-reversed sequence is (to within a\nconstant) a lower bound for any subsequence containing half the\nelements.\n\nThere are sequences for which this doesn't hold.  For example, interleave\na bit-reversed sequence with a sequence in increasing order.  Then\nthe full sequence requires Omega(n log n) rotations for access, but\nit contains a subsequence (the one in increasing order) that requires\nO(n) rotations.  But what I'm claiming is that the bit-reversed\nsequence does not contain any such \"easy\" sequence as a subsequence.\n\nIs this true?\n-- \n        --- Paul Callahan --- <A HREF=\"mailto:callahan@cs.jhu.edu\">callahan@cs.jhu.edu</A> ---\n\n\"The first principle in science is to invent something nice to look at \n and then decide what it can do.\" -- Rowland Emett\n</PRE><HR><PRE>\n<B>From:</B>           <A HREF=\"mailto:rew@lightstone.com\">rew@lightstone.com</A> (Bob Wilber at PUMICE)\n<B>Newsgroups:</B>     comp.theory\n<B>Subject:</B>        Re: Jordan Sequences for which Splay Sort is n log n\n<B>Date:</B>           4 Oct 1995 11:59:49 -0500\n<B>Organization:</B>   UTexas Mail-to-News Gateway\n</PRE><HR><PRE>\n&gt;Actually, I meant that the bound should also hold in the other\n&gt;direction for bit-reversed sequences.  What I want to show is that the\n&gt;lower bound for the full bit-reversed sequence is (to within a\n&gt;constant) a lower bound for any subsequence containing half the\n&gt;elements.\n&gt;\n&gt;There are sequences for which this doesn't hold.  For example, interleave\n&gt;a bit-reversed sequence with a sequence in increasing order.  Then\n&gt;the full sequence requires Omega(n log n) rotations for access, but\n&gt;it contains a subsequence (the one in increasing order) that requires\n&gt;O(n) rotations.  But what I'm claiming is that the bit-reversed\n&gt;sequence does not contain any such \"easy\" sequence as a subsequence.\n&gt;\n&gt;I this true?\n\nI suspect that it is, but I don't have a proof.\n\nHowever, you don't need such a strong claim for your proof to work.  Let's look\nat it again.  We have a proof that accessing a bit reversal permutation of\nlength n via a binary search tree algorithm requires c * n log n time,\nfor some c &gt; 0.\n\nWe insert into an initially empty tree a bit reversal permutation on k bits,\n          k\nwith n = 2  elements.  We want to show that inserting the last n/2 elements\nrequires accessing the n/2 nodes already in tree in bit reversal order.  Fix k\nat 4.  When br(n/2) = 0001 is inserted, we must access the lower of\nbounds(0001), namely, the lower of 0000 and 0010.  The higher of these\ntwo nodes is an ancestor of the lower, so we actually visit both and are free\nto charge for accessing either one.  So charge for acessing 0000.  When we\ninsert br(n/2 + 1) = 1001, we must access 1000 and 1010.  Charge for 1000.\nWhen we insert br(n/2 + 1) = 0101, we must access 0100 and 0110.  Charge for\n0100.  The sequence of accesses we charge for, 0000, 1000, 0100, 1100, ....,\n1110, is a full bit reversal permutation on k-1 bits (the k'th bit being fixed\nat 0), with no missing elements.  So this takes c*(n/2) log (n/2) =\nOmega(n log n) time.\n\nThe only lower bound being applied here is to a complete bit reversal\npermutation, not some arbitrary subsequence of a bit reversal permutation.\n</PRE>\n", "id": 10951.0}