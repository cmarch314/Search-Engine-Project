{"text": "Machine Learning Spring 2 9 Final with answers Simulation of changing the weights of a RBF kernel in a kernel PCA projection of the Iris dataset Source Darren Davis CompSci 273A Instructor Max Welling Office hours Wednedays 4 5pm Prerequisites ICS 27 A Intro AI or with consent of instructor Goals The goal of this class is to familiarize you with various stat of the art machine learning techniques for classification regression clustering and dimensionality reduction Besides this an important aspect this class is to provide a modern statistical view of machine learning The course will primarily be lecture based with homework project and an exam Most homework will revolve around the implementation of various classification algorithms It is required that you use MATLAB for this coding work Presentation Schedule The following groups have been scheduled for a presentation on these days Th May 28 Viveck Cadambe Group and Yi Yang Group Tu June 2 Phitchayaphong Tantikul Group and David Keator Th June 4 Michael Zeller Group and Ullas Sankhla Group If you are taking the exam but do not find yourself affiliated with one of these groups you should contact me asap to get yourself scheduled Presentations can take 3 minutes each with 1 minutes for left for questions The presentation should be equally divided among the members of the group Everyone is required to present a piece Note that each invidiual member will also have to write a report of at least 2 pages on his her contribution to the project which will only be due in finals week Slides Week 1 2 Slides Intro kNN Logistic Regression Overfitting pdf Slides Evaluation of Results pdf Week 3 4 Slides DecisionTrees Bagging Boosting pdf Slides Nural Networks pdf Week 5 Lecture notes Convex Optimization Slides support Vector Machines pdf Week 6 Lecture notes Clustering ps Slides Unsupervised Learning pdf Lecture notes Kernel PCA Week 7 Lecture notes Kernel Spectral Clustering Lecture notes Fisher LDA Week 8 Lecture notes Kernel Canonical Correlation Analysis Data Sets and Online Resources Iris Data There are 5 columns The first 4 columns are feature values while the last value is the class label 1 2 3 Flower dataset This dataset is an excellent starting point for a image retrieval system You can use the one with 17 categories to test your algorithms on Thesis in Features for Image Retrieval Suggested Image Features to Check out Color Histograms Histograms of Scale Invariant Features SIFT Histograms of Image Gradients Texture Filter Banks Textons Gist Features Torralba Code for Spatial Pyramid Paper on Spatial Pyramid Very fast method for retrieval Large Scale Online Learning of Image Similarity Through Ranking ICML paper on this method Gal Chechik and Varun Sharma and Uri Shalit and Samy Bengio Just released Google image similarity search webpage A bunch of images of simulated Tumor growth are be supplied below A possible project with some real relevance is to take these images and predict the class of tumor that generated it I have held some test data behind Train Images Class 1 Train Images Class 2 Test Images Class 1 2 mixed We will do a contest who performs best on test data wihout labels Prize a bottle of champagne Homework always due the next Tuesday at 11pm Week 1 Reading Bishop Sec 1 1 2 5 2 4 3 2 This paper on Earth Movers Distance Exercises Homework 1 pdf answer sheet HW1 Week 2 Reading Bishop Sec 3 2 This paper on Flower Classification Exercises Homework 2 pdf answer sheet HW2 Week 3 4 Reading Bishop Sec 14 until not including Sec 14 5 Bishop Chapter 5 until not including 5 6 This paper on Bagging Predictors This paper on Convolutional Networks Exercises Homework 3 pdf answer sheet HW3 Week 5 Reading Bishop Chapter 6 This technical note on convex optimization This paper on fast retrieval These notes on SVMs Exercises Homework 4 pdf answer sheet HW4 Week 6 Reading Bishop Chapter 9 This classnote on clustering Exercises Homework 5 pdf answer sheet HW5 Week 7 Reading Bishop Chapter 9 This classnote on Kernel PCA This classnote on Kernel Spectral Clustering Exercises Homework 6 pdf answer sheet HW6 Week 8 Reading Bishop Chapter 4 section 4 1 only This classnote on Fisher LDA Exercises Homework 7 pdf answer sheet HW7 Project Consider the following facts 1 Search engines now store more images than a human will see in its lifetime 2 Almost everyone carries a digital camera of some sort in his her pocket Conclusion 1 there is or will very soon be an obvious need for a search tool that searches for information based on on an uploaded image There is enough information on the internet to make this feasible Now consider this have you ever been able to upload a picture into some website which then returned related pictures or information about the objects in that picture Not me and I tried Last year I had a mystery plant in my garden and people claimed it was poiseness I took a picture and tried to locate internet services that would take my image and find webpages on the plant in question Well it didn t work I got lost of red images but very few plants I ended up going to a gardening center with my picture to find out that it was a Castor Bean yes that is very poiseness Anyway it felt like this information should have been easier to obtain Conclusion 2 This problem must be very difficult if not it would already exist There really are lots of cool applications of such a system Imagine taking a picture of your kids skin rash and finding out via this tool what some likely candidates for its possible underlying disease are Or imagine a tool for Alzheimer s patients who are having a hard time recognizing their family friends Or imagine you are on vacation in Rome and wish to know more about that building who s name you really don t know So here is my challenge to you Use the knowledge you learn in this class and more to build a very simple system of the above kind We will think about a nice restricted domain for which we can easily get data California plants Cars Skin diseases Faces We ll think about methods to use which features to extract how to build a useful kernel what classification algorithm to use You can break up in groups of 5 students at most and divide the work You will need to report your work through a presentation If we end up with systems that work reasonably well we can build the actual tool as a demo and run it on a server We can even combine more than one system and combine their results using averaging Anyway things are still a big open ended right now but it will be very instructive and lots of fun Syllabus incomplete 1 introduction overview examples goals algorithm evaluation statistics kNN logistic regression 2 classification I decision trees random forests bagging boosting 3 clustering dimensionality reduction k means expectation maximization PCA 4 neural networks perceptron multi layer networks back propagation 5 classification II kernel methods support vector machines required reading on SVM Additional background reading Practice Final ansers Grading Criteria Grading will be based on a combination of Homework 2 projects 3 and a final exam 5 This information may change depending on whether a reader will be assigned to this class Textbook The textbook that will be used for this course is 1 C Bishop Pattern Recognition and Machine Learning Optional side readings are 2 D MacKay Information Theory Inference and Learning Algorithms 3 R O Duda P E Hart D Stork Pattern Classification 4 C M Bishop Neural Networks for Pattern Recognition 5 T Hastie R Tibshirani J H Friedman The Elements of Statistical Learning 6 B D Ripley Pattern Recognition and Neural Networks 7 T Mitchell Machine Learning http www cs cmu edu tom mlbook html ", "_id": "http://www.ics.uci.edu/%7ewelling/teaching/273ASpring09/ICS273ASpring09.html", "title": "untitled document", "html": "<html xmlns:v=\"urn:schemas-microsoft-com:vml\"\nxmlns:o=\"urn:schemas-microsoft-com:office:office\"\nxmlns:w=\"urn:schemas-microsoft-com:office:word\"\nxmlns:st1=\"urn:schemas-microsoft-com:office:smarttags\"\nxmlns=\"http://www.w3.org/TR/REC-html40\">\n\n\t<head>\n<meta http-equiv=Content-Type content=\"text/html; charset=us-ascii\">\n<meta name=ProgId content=Word.Document>\n<meta name=Generator content=\"Microsoft Word 11\">\n<meta name=Originator content=\"Microsoft Word 11\">\n<link rel=File-List href=\"ICS273AFall06_files/filelist.xml\">\n<link rel=Edit-Time-Data href=\"ICS273AFall06_files/editdata.mso\">\n<!--[if !mso]>\n<style>\nv\\:* {behavior:url(#default#VML);}\no\\:* {behavior:url(#default#VML);}\nw\\:* {behavior:url(#default#VML);}\n.shape {behavior:url(#default#VML);}\n</style>\n<![endif]-->\n<title>Untitled Document</title>\n<o:SmartTagType namespaceuri=\"urn:schemas-microsoft-com:office:smarttags\"\n name=\"place\"/>\n<o:SmartTagType namespaceuri=\"urn:schemas-microsoft-com:office:smarttags\"\n name=\"City\"/>\n<!--[if gte mso 9]><xml>\n <o:DocumentProperties>\n  <o:Author>Welling</o:Author>\n  <o:Template>Normal</o:Template>\n  <o:LastAuthor>Welling</o:LastAuthor>\n  <o:Revision>9</o:Revision>\n  <o:TotalTime>131</o:TotalTime>\n  <o:Created>2006-07-03T18:58:00Z</o:Created>\n  <o:LastSaved>2006-08-30T21:40:00Z</o:LastSaved>\n  <o:Pages>1</o:Pages>\n  <o:Words>358</o:Words>\n  <o:Characters>2044</o:Characters>\n  <o:Company> UCI</o:Company>\n  <o:Lines>17</o:Lines>\n  <o:Paragraphs>4</o:Paragraphs>\n  <o:CharactersWithSpaces>2398</o:CharactersWithSpaces>\n  <o:Version>11.5606</o:Version>\n </o:DocumentProperties>\n</xml><![endif]--><!--[if gte mso 9]><xml>\n <w:WordDocument>\n  <w:Zoom>125</w:Zoom>\n  <w:SpellingState>Clean</w:SpellingState>\n  <w:GrammarState>Clean</w:GrammarState>\n  <w:ValidateAgainstSchemas/>\n  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>\n  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>\n  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>\n  <w:BrowserLevel>MicrosoftInternetExplorer4</w:BrowserLevel>\n </w:WordDocument>\n</xml><![endif]--><!--[if gte mso 9]><xml>\n <w:LatentStyles DefLockedState=\"false\" LatentStyleCount=\"156\">\n </w:LatentStyles>\n</xml><![endif]--><!--[if !mso]><object\n classid=\"clsid:38481807-CA0E-42D2-BF39-B33AF135CC4D\" id=ieooui></object>\n<style>\nst1\\:*{behavior:url(#ieooui) }\n</style>\n<![endif]-->\n<style>\n<!--\n /* Font Definitions */\n @font-face\n\t{font-family:Tahoma;\n\tpanose-1:2 11 6 4 3 5 4 4 2 4;\n\tmso-font-charset:0;\n\tmso-generic-font-family:swiss;\n\tmso-font-pitch:variable;\n\tmso-font-signature:1627421319 -2147483648 8 0 66047 0;}\n /* Style Definitions */\n p.MsoNormal, li.MsoNormal, div.MsoNormal\n\t{mso-style-parent:\"\";\n\tmargin:0in;\n\tmargin-bottom:.0001pt;\n\tmso-pagination:widow-orphan;\n\tfont-size:12.0pt;\n\tfont-family:\"Times New Roman\";\n\tmso-fareast-font-family:\"Times New Roman\";}\nh2\n\t{mso-margin-top-alt:auto;\n\tmargin-right:0in;\n\tmso-margin-bottom-alt:auto;\n\tmargin-left:0in;\n\tmso-pagination:widow-orphan;\n\tmso-outline-level:2;\n\tfont-size:18.0pt;\n\tfont-family:\"Times New Roman\";}\na:link, span.MsoHyperlink\n\t{color:blue;\n\ttext-decoration:underline;\n\ttext-underline:single;}\na:visited, span.MsoHyperlinkFollowed\n\t{color:blue;\n\ttext-decoration:underline;\n\ttext-underline:single;}\nspan.SpellE\n\t{mso-style-name:\"\";\n\tmso-spl-e:yes;}\nspan.GramE\n\t{mso-style-name:\"\";\n\tmso-gram-e:yes;}\n@page Section1\n\t{size:8.5in 11.0in;\n\tmargin:1.0in 1.25in 1.0in 1.25in;\n\tmso-header-margin:.5in;\n\tmso-footer-margin:.5in;\n\tmso-paper-source:0;}\ndiv.Section1\n\t{page:Section1;}\n-->\n</style>\n<!--[if gte mso 10]>\n<style>\n /* Style Definitions */\n table.MsoNormalTable\n\t{mso-style-name:\"Table Normal\";\n\tmso-tstyle-rowband-size:0;\n\tmso-tstyle-colband-size:0;\n\tmso-style-noshow:yes;\n\tmso-style-parent:\"\";\n\tmso-padding-alt:0in 5.4pt 0in 5.4pt;\n\tmso-para-margin:0in;\n\tmso-para-margin-bottom:.0001pt;\n\tmso-pagination:widow-orphan;\n\tfont-size:10.0pt;\n\tfont-family:\"Times New Roman\";\n\tmso-ansi-language:#0400;\n\tmso-fareast-language:#0400;\n\tmso-bidi-language:#0400;}\n</style>\n<![endif]--><!--[if gte mso 9]><xml>\n <o:shapedefaults v:ext=\"edit\" spidmax=\"12290\"/>\n</xml><![endif]--><!--[if gte mso 9]><xml>\n <o:shapelayout v:ext=\"edit\">\n  <o:idmap v:ext=\"edit\" data=\"1\"/>\n </o:shapelayout></xml><![endif]-->\n</head>\n\n\t<body bgcolor=\"#CCCCCC\" background=\"../../background.gif\" lang=EN-US link=blue vlink=blue style=\"tab-interval:.5in\">\n\t\t<div class=Section1>\n\t\t\t<h2><span style=\"font-size:10.0pt;font-family:Tahoma;color:red\">Machine Learning <span class=GramE>Spring</span> 2009</span></h2>\n\t\t\t<h2><a href=\"Final-273Aspring09-answers.pdf\">Final with\u00a0answers</a></h2>\n\t\t\t<h2></h2>\n\t\t\t<h2><img src=\"davis_kpca_label_wts.gif\" alt=\"\" height=\"287\" width=\"368\" border=\"0\"></h2>\n\t\t\t<h2><span style=\"font-size:10.0pt\">Simulation of changing the weights of a RBF kernel in a kernel PCA projection of the Iris dataset.<br>\n\t\t\t\t\t<br>\n\t\t\t\t\tSource: Darren Davis</span></h2>\n\t\t\t<hr size=2 width=\"100%\" align=left>\n\t\t\t<h2><span style=\"font-size:10.0pt\">CompSci: 273A<br>\n\t\t\t\t\tInstructor: Max Welling</span></h2>\n\t\t\t<h2><span style=\"font-size:10.0pt\">Office hours: Wednedays 4-5pm</span><span style=\"color:black\">\u00a0</span></h2>\n\t\t\t<h2><span style=\"font-size:10.0pt\">\n\t\t\t\t\t<hr size=2 width=\"100%\" align=left>\n\t\t\t\t</span></h2>\n\t\t\t<h2><span style=\"font-size:10.0pt;font-family:Arial;color:red\">Prerequisites</span></h2>\n\t\t\t<h2><span style=\"font-size:10.0pt\">ICS 270A Intro AI, or with consent of instructor.</span></h2>\n\t\t\t<h2><span style=\"font-size:10.0pt\">\n\t\t\t\t\t<hr size=2 width=\"100%\" align=left>\n\t\t\t\t</span></h2>\n\t\t\t<h2><span style=\"font-size:10.0pt;font-family:Arial;color:red\">Goals:</span></h2>\n\t\t\t<h2><span style=\"font-size:10.0pt;color:black\">The goal of this class is to familiarize you with various stat-of-the-art machine learning techniques for<br>\n\t\t\t\t\tclassification, regression, <span class=GramE>clustering</span> and dimensionality reduction. Besides this, an important aspect<br>\n\t\t\t\t\tthis class is to provide a modern statistical view of machine learning. </span></h2>\n\t\t\t<h2><span style=\"font-size:10.0pt\">The course will primarily be lecture-based with homework, project and an<br>\n\t\t\t\t\texam. Most homework will revolve around the implementation of various<br>\n\t\t\t\t\tclassification algorithms. It is required that you use MATLAB for this coding work. </span></h2>\n\t\t\t<hr size=2 width=\"100%\" align=left>\n\t\t\t<p><strong><font color=\"red\">Presentation Schedule</font>:</strong></p>\n\t\t\t<p><strong>The following groups have been scheduled for a presentation on these days:</strong></p>\n\t\t\t<p><strong>Th. May 28 : Viveck Cadambe Group and Yi Yang Group</strong></p>\n\t\t\t<p><strong>Tu. June 2: Phitchayaphong Tantikul Group and David Keator</strong></p>\n\t\t\t<p><strong>Th. June 4: Michael Zeller Group and Ullas Sankhla Group</strong></p>\n\t\t\t<p><strong>If you are taking the exam but do not find yourself affiliated with one of these groups you should contact me asap to get yourself scheduled.<br>\n\t\t\t\t\tPresentations can take 30 minutes each with 10 minutes for left for questions.<br>\n\t\t\t\t\tThe presentation should be equally divided among the members of the group. Everyone is required to present a piece.<br>\n\t\t\t\t\tNote that each invidiual member will also have to write a report of at least 2 pages on his/her contribution to the project<br>\n\t\t\t\t\t(which will only be due in finals week).</strong></p>\n\t\t\t<p></p>\n\t\t\t<h2><span style=\"font-size:10.0pt;font-family:Arial;color:black\">\n\t\t\t\t\t<hr size=2 width=\"100%\" align=left>\n\t\t\t\t</span></h2>\n\t\t\t<h2><span class=GramE><span style=\"font-size:10.0pt;font-family:Arial; color:red\">Slides:<br>\n\t\t\t\t\t\t<br>\n\t\t\t\t\t\t<font size=\"-1\" color=\"#0033bb\">Week 1/2:</font> <font color=\"black\" face=\"Times New Roman\">[<a href=\"Intro273ASpring09.ppt\">Slides: Intro, kNN, Logistic Regression, Overfitting</a>][<a href=\"Intro273ASpring09.pdf\">pdf</a>] [<a href=\"EvauationMethods273ASpring09.ppt\">Slides: Evaluation of Results</a>][<a href=\"EvauationMethods273ASpring09.pdf\">pdf</a>]</font><br>\n\t\t\t\t\t\t<br>\n\t\t\t\t\t\t<font size=\"-1\" color=\"#0033bb\">Week 3/4:</font> <font color=\"black\" face=\"Times New Roman\">[<a href=\"ClassificationI273Aspring06.ppt\">Slides: DecisionTrees, Bagging, Boosting</a>][<a href=\"ClassificationI273Aspring06.pdf\">pdf</a>] [<a href=\"NeuralNets273ASpring09.ppt\">Slides: Nural Networks</a>] [<a href=\"NeuralNets273ASpring09.pdf\">pdf</a>]</font><br>\n\t\t\t\t\t\t<br>\n\t\t\t\t\t\t<font size=\"-1\" color=\"#0033bb\">Week 5:</font><font size=\"1\" color=\"black\"> </font><font size=\"2\" color=\"black\">[</font><font size=\"2\" color=\"black\" face=\"Times New Roman\"><a href=\"Convex-Opt.pdf\">Lecture-notes Convex Optimization</a></font><font size=\"2\" color=\"black\">][</font><font size=\"2\" color=\"black\" face=\"Times New Roman\"><a href=\"SVM273ASpring2009.ppt\">Slides: support Vector Machines</a></font><font size=\"2\" color=\"black\">] [</font><font size=\"2\" color=\"black\" face=\"Times New Roman\"><a href=\"SVM273ASpring2009.pdf\">pdf</a></font><font size=\"2\" color=\"black\">]<br>\n\t\t\t\t\t\t\t<br>\n\t\t\t\t\t\t</font><font size=\"-1\" color=\"#0033bb\">Week 6:</font><font size=\"1\" color=\"black\"> </font><font size=\"2\" color=\"black\">[</font><font size=\"2\" color=\"black\" face=\"Times New Roman\"><a href=\"Clustering.ps.gz\">Lecture-notes Clustering (ps)</a></font><font size=\"2\" color=\"black\">][</font><font size=\"2\" color=\"black\" face=\"Times New Roman\"><a href=\"UnsupLearn273ASpring09.ppt\">Slides: Unsupervised Learning</a></font><font size=\"2\" color=\"black\">] [</font><font size=\"2\" color=\"black\" face=\"Times New Roman\"><a href=\"UnsupLearn273ASpring09.pdf\">pdf</a></font><font size=\"2\" color=\"black\">][</font><font size=\"2\" color=\"black\" face=\"Times New Roman\"><a href=\"Kernel-PCA.pdf\">Lecture-notes Kernel PCA</a></font><font size=\"2\" color=\"black\">]<br>\n\t\t\t\t\t\t\t<br>\n\t\t\t\t\t\t</font><font size=\"-1\" color=\"#0033bb\">Week 7:</font><font size=\"1\" color=\"black\"> </font><font size=\"2\" color=\"black\">[</font><font size=\"2\" color=\"black\" face=\"Times New Roman\"><a href=\"SpectralClustering.pdf\">Lecture-notes Kernel &amp; Spectral Clustering</a></font><font size=\"2\" color=\"black\">][</font><font size=\"2\" color=\"black\" face=\"Times New Roman\"><a href=\"Fisher-LDA.pdf\">Lecture-notes Fisher LDA</a></font><font size=\"2\" color=\"black\">]<br>\n\t\t\t\t\t\t\t<br>\n\t\t\t\t\t\t</font><font size=\"-1\" color=\"#0033bb\">Week 8:</font><font size=\"1\" color=\"black\"> </font><font size=\"2\" color=\"black\">[</font><font size=\"2\" color=\"black\" face=\"Times New Roman\"><a href=\"kCCA.pdf\">Lecture-notes Kernel Canonical Correlation Analysis</a></font><font size=\"2\" color=\"black\">]</font><font size=\"2\" color=\"black\"><br>\n\t\t\t\t\t\t</font></span></span></h2>\n\t\t\t<hr size=2 width=\"100%\" align=left>\n\t\t\t<h2><span class=GramE><span style=\"font-size:10.0pt;font-family:Arial; color:red\">Data Sets and Online Resources:<br>\n\t\t\t\t\t</span></span></h2>\n\t\t\t<h2><font size=\"2\"><a href=\"iris_edit\">Iris Data<br>\n\t\t\t\t\t</a></font><font size=\"2\" face=\"Times New Roman\">There are 5 columns. The first 4 columns are feature values while the last value is the class label (1,2,3).</font></h2>\n\t\t\t<h2><b><font size=\"2\"><a href=\"http://www.robots.ox.ac.uk/%7evgg/data/flowers/index.html\">Flower dataset.<br>\n\t\t\t\t\t\t</a>This dataset is an excellent starting point for a image retrieval system. You can use the one with 17 categories<br>\n\t\t\t\t\t\tto test your algorithms on.<br>\n\t\t\t\t\t\t<br>\n\t\t\t\t\t\t<a href=\"da-deselaers-ImRetr.pdf\">Thesis</a> in Features for Image Retrieval<br>\n\t\t\t\t\t\t<br>\n\t\t\t\t\t\tSuggested Image Features to Check out:<br>\n\t\t\t\t\t\t-Color Histograms<br>\n\t\t\t\t\t\t-Histograms of Scale Invariant Features (SIFT)<br>\n\t\t\t\t\t\t-Histograms of Image Gradients<br>\n\t\t\t\t\t\t-Texture Filter Banks / Textons<br>\n\t\t\t\t\t\t-Gist Features (Torralba)<br>\n\t\t\t\t\t\t<br>\n\t\t\t\t\t\t<a href=\"http://www.cs.unc.edu/%7elazebnik/research/spatial_pyramid_code.zip\">Code for Spatial Pyramid<br>\n\t\t\t\t\t\t</a><a href=\"http://www-cvr.ai.uiuc.edu/ponce_grp/publication/paper/cvpr06b.pdf\">Paper on Spatial Pyramid</a></font></b><b><font size=\"2\"><br>\n\t\t\t\t\t</font></b></h2>\n\t\t\t<p><b><font size=\"2\">Very fast method for retrieval: <br>\n\t\t\t\t\t</font></b><font color=\"#000000\"><a href=\"GalBengio.pdf\">Large Scale Online Learning of Image Similarity Through Ranking<br>\n\t\t\t\t\t</a><a href=\"paperChechik.pdf\">ICML paper on this method</a></font><br>\n\t\t\t\t<i>Gal Chechik and Varun Sharma and Uri Shalit and Samy Bengio<br>\n\t\t\t\t</i><b><font size=\"2\"><br>\n\t\t\t\t\t</font></b><b><font size=\"2\">Just released <a href=\"http://similar-images.googlelabs.com/\">Google image similarity search webpage</a></font></b></p>\n\t\t\t<p><b><font size=\"2\">A bunch of images of simulated Tumor growth are be supplied below.<br>\n\t\t\t\t\t\t\tA possible project with some real relevance is to take these images and predict the class of<br>\n\t\t\t\t\t\ttumor that generated it.  I have held some test data behind.</font></b></p>\n\t\t\t<p><b><font size=\"2\">  </font></b><b><font size=\"2\">  </font></b></p>\n\t\t\t<p><a href=\"TildeGamma0p5.zip\">Train Images Class 1</a></p>\n\t\t\t<p><a href=\"TildeGamme0.zip\">Train Images Class 2</a></p>\n\t\t\t<p><a href=\"TumorTestSet.zip\">Test Images Class 1&amp;2 (mixed)</a></p>\n\t\t\t<p><font color=\"#c00079\">We will do a contest who performs best on test data (wihout labels).<br>\n\t\t\t\t\tPrize: a bottle of champagne</font>.</p>\n\t\t\t<hr size=2 width=\"100%\" align=left>\n\t\t\t<h2><span class=GramE><span style=\"font-size:10.0pt;font-family:Arial; color:red\">Homework : <font size=\"-1\" color=\"black\">(always due the next Tuesday at 11pm)</font></span></span></h2>\n\t\t\t<h2><span class=GramE><span style=\"font-size:10.0pt;font-family:Arial; color:red\"><font size=\"-1\" color=\"#0033bb\">Week 1: </font><font size=\"2\" color=\"black\" face=\"Times New Roman\">Reading: Bishop, Sec 1.1, 2.5.2, 4.3.2.<br>\n\t\t\t\t\t\t\t<a href=\"rubnerIjcv00-1.pdf\">This paper on Earth Movers\u00a0Distance</a><br>\n\t\t\t\t\t\t\tExercises: <a href=\"HWCS273ASpring09.doc\">Homework 1</a>[<a href=\"HWCS273ASpring09.pdf\">pdf</a>] [<a href=\"AnswerSheetHW1.pdf\">answer sheet HW1</a>]</font></span></span></h2>\n\t\t\t<h2><span class=GramE><span style=\"font-size:10.0pt;font-family:Arial; color:red\"><font size=\"-1\" color=\"#0033bb\">Week 2: </font><font size=\"2\" color=\"black\" face=\"Times New Roman\">Reading: Bishop Sec 3.2<br>\n\t\t\t\t\t\t\t<a href=\"nilsback06.pdf\">This paper on Flower Classification</a><br>\n\t\t\t\t\t\t\tExercises: <a href=\"HWCS273ASpring09-2.doc\">Homework 2</a>[<a href=\"HWCS273ASpring09-2.pdf\">pdf</a>] [<a href=\"AnswerSheetHW2.pdf\">answer sheet HW2</a>]<br>\n\t\t\t\t\t\t\t<br>\n\t\t\t\t\t\t</font><font size=\"-1\" color=\"#0033bb\">Week 3/4: </font><font size=\"2\" color=\"black\" face=\"Times New Roman\">Reading:<br>\n\t\t\t\t\t\t\t\tBishop, Sec 14 until (not including) Sec. 14.5.<br>\n\t\t\t\t\t\t\t\tBishop, Chapter 5 until (not including) 5.6<br>\n\t\t\t\t\t\t\tThis paper on &quot;<a href=\"BAGGING_PREDICTORS.pdf\">Bagging Predictors</a>&quot;<br>\n\t\t\t\t\t\t\t\tThis paper on <a href=\"lecun-89e.pdf\">Convolutional Networks</a><br>\n\t\t\t\t\t\t\t\tExercises: <a href=\"HWCS273ASpring09-3.doc\">Homework 3</a> [<a href=\"HWCS273ASpring09-3.pdf\">pdf</a>] [<a href=\"AnswerSheetHW3.pdf\">answer sheet HW3</a>]<br>\n\t\t\t\t\t\t\t<br>\n\t\t\t\t\t\t</font><font size=\"-1\" color=\"#0033bb\">Week 5: </font></span></span><font size=\"2\"><span class=GramE><span style=\"font-size:10.0pt;font-family:Arial; color:red\"><font color=\"black\" face=\"Times New Roman\">Reading:<br>\n\t\t\t\t\t\t\t\tBishop Chapter 6<br>\n\t\t\t\t\t\t\t\tThis <a href=\"Convex-Opt.pdf\">technical note on convex optimization</a><br>\n\t\t\t\t\t\t\t\tThis<a href=\"paperChechik.pdf\"> paper on fast retrieval</a><br>\n\t\t\t\t\t\t\t\tThese<a href=\"SVM.pdf\"> notes on SVMs</a><br>\n\t\t\t\t\t\t\t\tExercises: <a href=\"HWCS273ASpring09-4.doc\">Homework 4</a> [<a href=\"HWCS273ASpring09-4.pdf\">pdf</a>]</font></span></span></font><span class=GramE><span style=\"font-size:10.0pt;font-family:Arial; color:red\"><font size=\"2\" color=\"black\" face=\"Times New Roman\">[<a href=\"AnswerSheetHW4.pdf\">answer sheet HW4</a>]<br>\n\t\t\t\t\t\t</font></span></span><font size=\"2\"><span class=GramE><span style=\"font-size:10.0pt;font-family:Arial; color:red\"><font color=\"black\" face=\"Times New Roman\"><br>\n\t\t\t\t\t\t\t\t<br>\n\t\t\t\t\t\t\t</font></span></span></font><span class=GramE><span style=\"font-size:10.0pt;font-family:Arial; color:red\"><font size=\"-1\" color=\"#0033bb\">Week 6: </font></span></span><font size=\"2\"><span class=GramE><span style=\"font-size:10.0pt;font-family:Arial; color:red\"><font color=\"black\" face=\"Times New Roman\">Reading:<br>\n\t\t\t\t\t\t\t\tBishop Chapter 9<br>\n\t\t\t\t\t\t\t\tThis <a href=\"Clustering.ps.gz\">classnote on clustering</a><br>\n\t\t\t\t\t\t\t\tExercises: <a href=\"HWCS273ASpring09-5.doc\">Homework 5</a> [<a href=\"HWCS273ASpring09-5.pdf\">pdf</a>]</font></span></span></font><span class=GramE><span style=\"font-size:10.0pt;font-family:Arial; color:red\"><font size=\"2\" color=\"black\" face=\"Times New Roman\">[<a href=\"AnswerSheetHW5.pdf\">answer sheet HW5</a>]</font></span></span><font size=\"2\"><span class=GramE><span style=\"font-size:10.0pt;font-family:Arial; color:red\"><font color=\"black\" face=\"Times New Roman\"><br>\n\t\t\t\t\t\t\t\t<br>\n\t\t\t\t\t\t\t</font></span></span></font><span class=GramE><span style=\"font-size:10.0pt;font-family:Arial; color:red\"><font size=\"-1\" color=\"#0033bb\">Week 7: </font></span></span><font size=\"2\"><span class=GramE><span style=\"font-size:10.0pt;font-family:Arial; color:red\"><font color=\"black\" face=\"Times New Roman\">Reading:<br>\n\t\t\t\t\t\t\t\t\tBishop Chapter 9<br>\n\t\t\t\t\t\t\t\tThis <a href=\"Kernel-PCA.pdf\">classnote on Kernel-PCA<br>\n\t\t\t\t\t\t\t\t</a>This <a href=\"SpectralClustering.pdf\">classnote on Kernel &amp; Spectral Clustering</a><br>\n\t\t\t\t\t\t\t\tExercises: <a href=\"HWCS273ASpring09-6.doc\">Homework 6</a> [<a href=\"HWCS273ASpring09-6.pdf\">pdf</a>]</font></span></span></font><span class=GramE><span style=\"font-size:10.0pt;font-family:Arial; color:red\"><font size=\"2\" color=\"black\" face=\"Times New Roman\">[<a href=\"AnswerSheetHW6.pdf\">answer sheet HW6</a>]</font></span></span><font size=\"2\"><span class=GramE><span style=\"font-size:10.0pt;font-family:Arial; color:red\"><font color=\"black\" face=\"Times New Roman\"><br>\n\t\t\t\t\t\t\t</font></span></span></font></h2>\n\t\t\t<h2><span class=GramE><span style=\"font-size:10.0pt;font-family:Arial; color:red\"><font size=\"-1\" color=\"#0033bb\">Week 8: </font></span></span><font size=\"2\"><span class=GramE><span style=\"font-size:10.0pt;font-family:Arial; color:red\"><font color=\"black\" face=\"Times New Roman\">Reading:<br>\n\t\t\t\t\t\t\t\tBishop Chapter 4, section 4.1 only<br>\n\t\t\t\t\t\t\t\tThis <a href=\"Fisher-LDA.pdf\">classnote on Fisher-LDA</a><a href=\"Kernel-PCA.pdf\"><br>\n\t\t\t\t\t\t\t\t</a>Exercises: <a href=\"HWCS273ASpring09-7.doc\">Homework 7</a> [<a href=\"HWCS273ASpring09-7.pdf\">pdf</a>]</font></span></span></font><span class=GramE><span style=\"font-size:10.0pt;font-family:Arial; color:red\"><font size=\"2\" color=\"black\" face=\"Times New Roman\">[<a href=\"AnswerSheetHW7.pdf\">answer sheet HW7</a>]</font></span></span><font size=\"2\"><span class=GramE><span style=\"font-size:10.0pt;font-family:Arial; color:red\"><font color=\"black\" face=\"Times New Roman\"><br>\n\t\t\t\t\t\t\t</font></span></span></font></h2>\n\t\t\t<hr size=2 width=\"100%\" align=left>\n\t\t\t<h2><span style=\"font-size:10.0pt;font-family: Arial;color:red\"><font color=\"red\">Project:<br>\n\t\t\t\t\t</font></span></h2>\n\t\t\t<h2><span style=\"font-size:10.0pt;font-family: Arial;color:red\"><font color=\"black\" face=\"Times New Roman\">Consider the following facts:<br>\n\t\t\t\t\t\t1. Search engines now store more images than a human will see in its lifetime<br>\n\t\t\t\t\t\t2. Almost everyone carries a digital camera of some sort in his/her pocket<br>\n\t\t\t\t\t\t<br>\n\t\t\t\t\t\tConclusion 1: there is (or will very soon be) an obvious need for a search tool that searches for information based on<br>\n\t\t\t\t\t\ton an uploaded image. There is enough information on the internet to make this feasible.<br>\n\t\t\t\t\t\t<br>\n\t\t\t\t\t\tNow consider this: have you ever been able to upload a picture into some website which then returned<br>\n\t\t\t\t\t\trelated pictures or information about the objects in that picture? Not me, and I\u00a0tried. Last year I\u00a0had a mystery plant<br>\n\t\t\t\t\t\tin my garden and people claimed it was poiseness. I\u00a0took a picture and tried to locate internet services that would<br>\n\t\t\t\t\t\ttake my image and find webpages on the plant in question. Well, it didn't work. I\u00a0got lost of red images, but very few plants.<br>\n\t\t\t\t\t\tI\u00a0ended up going to a gardening center with my picture to find out that it was a Castor Bean (yes that is very poiseness). Anyway,<br>\n\t\t\t\t\t\tit felt like this information should have been easier to obtain.<br>\n\t\t\t\t\t</font></span><span style=\"font-size:10.0pt;font-family: Arial;color:red\"><font color=\"black\" face=\"Times New Roman\"><br>\n\t\t\t\t\t\tConclusion 2: This problem must be very difficult (if not, it would already exist).<br>\n\t\t\t\t\t\t<br>\n\t\t\t\t\t\tThere really are lots of cool applications of such a system. Imagine taking a picture of your kids skin rash and finding<br>\n\t\t\t\t\t\tout via this tool what some likely candidates for its possible underlying disease are. Or, imagine a tool for Alzheimer's patients<br>\n\t\t\t\t\t\twho are having a hard time recognizing their family friends. Or imagine you are on vacation in Rome and wish to know more about<br>\n\t\t\t\t\t\tthat building who's name you really don't know.<br>\n\t\t\t\t\t\t<br>\n\t\t\t\t\t</font></span><span style=\"font-size:10.0pt;font-family: Arial;color:red\"><font color=\"black\" face=\"Times New Roman\">So here is my challenge to you. Use the knowledge you learn in this class (and more) to build a very simple system of the above<br>\n\t\t\t\t\t\tkind. We will think about a nice restricted domain for which we can easily get data (California plants, Cars, Skin diseases, Faces).<br>\n\t\t\t\t\t\tWe'll think about methods to use (which features to extract, how to build a useful kernel, what classification algorithm to use).<br>\n\t\t\t\t\t\t<br>\n\t\t\t\t\t\tYou can break up in groups of 5 students at most and divide the work. You will need to report your work through a presentation.<br>\n\t\t\t\t\t\tIf we end up with systems that work reasonably well, we can build the actual tool as a demo and run it on a server. We can even<br>\n\t\t\t\t\t\tcombine more than one system and combine their results using averaging.<br>\n\t\t\t\t\t\t<br>\n\t\t\t\t\t\tAnyway, things are still a big open ended right now, but it will be very instructive and lots of fun!<br>\n\t\t\t\t\t</font></span></h2>\n\t\t\t<h2><span style=\"font-size:10.0pt;font-family:Arial;color:black\">\n\t\t\t\t\t<hr size=2 width=\"100%\" align=left>\n\t\t\t\t</span></h2>\n\t\t\t<h2><span style=\"font-size:10.0pt;font-family:Arial;color:red\">Syllabus: <font size=\"-1\" color=\"black\">(incomplete)</font></span></h2>\n\t\t\t<h2><span class=GramE><span style=\"font-size:10.0pt;color:blue\">1</span></span><span style=\"font-size:10.0pt;color:blue\">:</span><span style=\"font-size:10.0pt; color:red\"> </span><span style=\"font-size:10.0pt\">introduction: overview, examples, goals, algorithm evaluation, statistics, kNN, logistic regression. </span></h2>\n\t\t\t<h2><span class=GramE><span style=\"font-size:10.0pt;color:blue\">2</span></span><span style=\"font-size:10.0pt;color:blue\">:</span><span style=\"font-size:10.0pt; color:red\"> </span><span style=\"font-size:10.0pt\">classification I: decision trees, random forests, bagging, boosting. </span></h2>\n\t\t\t<h2><span class=GramE><span style=\"font-size:10.0pt;color:blue\">3</span></span><span style=\"font-size:10.0pt;color:blue\">: </span><span style=\"font-size:10.0pt\">clustering &amp; dimensionality reduction:<span style=\"color:black\"> k-means, expectation-maximization, PCA. </span></span></h2>\n\t\t\t<h2><span style=\"font-size:10.0pt\"><span class=GramE><span style=\"color:blue\">4</span></span><span style=\"color:blue\">: </span>neural networks: <span class=SpellE>perceptron</span>, multi-layer networks, back-propagation. </span></h2>\n\t\t\t<h2><span class=GramE><span style=\"font-size:10.0pt;color:blue\">5:</span></span><span style=\"font-size:10.0pt;color:blue\"> </span><span style=\"font-size:10.0pt\">classification II: kernel methods &amp; support vector machines. </span></h2>\n\t\t\t<h2><span style=\"font-size:10.0pt\">required reading on SVM .<br>\n\t\t\t\t\tAdditional background reading </span></h2>\n\t\t\t<h2><span style=\"font-size:10.0pt\"><a href=\"Final-273Afall06-answers.pdf\">Practice Final + ansers</a></span></h2>\n\t\t\t<h2><span style=\"font-size:10.0pt\">\n\t\t\t\t\t<hr size=2 width=\"100%\" align=left>\n\t\t\t\t</span></h2>\n\t\t\t<h2><span style=\"font-size:10.0pt;font-family:Arial;color:red\">Grading Criteria</span></h2>\n\t\t\t<h2><span style=\"font-size:10.0pt;color:black\"><br>\n\t\t\t\t\tGrading will be based on a combination of,<span class=GramE><span style=\"mso-spacerun:yes\">\u00a0 Homework (20%) , </span>projects</span><span style=\"mso-spacerun:yes\">\u00a0 </span>(30%) and a final exam (50%) .<br>\n\t\t\t\t\t(This information may change depending on whether a reader will be assigned to this class.)</span></h2>\n\t\t\t<h2><span style=\"font-size:10.0pt;color:black\">\n\t\t\t\t\t<hr size=2 width=\"100%\" align=left>\n\t\t\t\t</span></h2>\n\t\t\t<h2><span style=\"font-size:10.0pt;font-family:Arial;color:red\">Textbook</span></h2>\n\t\t\t<h2><span style=\"font-size:10.0pt;color:#000099\"><br>\n\t\t\t\t\tThe textbook that will be used for this course is:</span></h2>\n\t\t\t<h2><span style=\"font-size:10.0pt;color:black\">1. C. Bishop: Pattern Recognition and Machine Learning</span></h2>\n\t\t\t<h2><span style=\"font-size:10.0pt;color:#000099\"><br>\n\t\t\t\t\tOptional side readings are:</span></h2>\n\t\t\t<h2><span style=\"font-size:10.0pt;color:black\">2. D. MacKay: Information Theory, Inference and Learning Algorithms<br>\n\t\t\t\t\t3. R.O. <span class=SpellE>Duda</span>, P.E. Hart, D. Stork: Pattern Classification<br>\n\t\t\t\t\t4. C.M. Bishop: Neural Networks for Pattern Recognition<br>\n\t\t\t\t\t5. T. <span class=SpellE>Hastie</span>, R. <span class=SpellE>Tibshirani</span>, J.H, Friedman: The Elements of Statistical Learning<br>\n\t\t\t\t\t6. B.D. Ripley: Pattern Recognition and Neural Networks<br>\n\t\t\t\t\t7. T. Mitchell: Machine Learning. <i style=\"mso-bidi-font-style:normal\">(http://www.cs.cmu.edu/~tom/mlbook.html)</i><br>\n\t\t\t\t</span></h2>\n\t\t</div>\n\t</body>\n\n</html>\n", "id": 16045.0}