{"text": "Main Home Overview Schedule Invited Speakers Keynotes Call For Papers Accepted Papers Organizers Related Links NIPS 13 Workshop on Crowdsourcing Theory Algorithms and Applications Workshop in conjunction with NIPS 2 13 Important Dates Submission deadline October 15 2 13 Acceptance Notification October 3 2 13 Workshop December 9 2 13 Overview Machine learning systems involve an integration of data representing human or physical knowledge and algorithms that discover patterns in this data and make predictions about new instances While machine learning research usually focuses on developing more efficient learning algorithms it is often the quality and amount of training data that predominately govern the performance of real world systems This is only amplified by the recent popularity of large scale and complicated learning systems such as deep networks which can require millions to billions of training instances to perform well Unfortunately traditional methods of collecting data from specialized workers are usually expensive and slow In recent years however a potential for change has emerged thanks to crowdsourcing which enables huge amounts of labeled data to be collected from large groups of usually online workers for a low cost or no cost at all Many machine learning tasks such as computer vision and natural language processing increasingly benefit from data gathered on crowdsourcing platforms such as Amazon Mechanical Turk and CrowdFlower On the other hand tools in machine learning game theory and mechanism design can help to address many challenging problems in crowdsourcing systems such as making them more reliable more efficient and less expensive In this workshop we call attention to crowdsourcing as a source of data discussing cheap and fast data collection methods based on crowdsourcing and how these methods could impact subsequent stages of machine learning Furthermore we will emphasize how the data sourcing paradigm interacts with the most recent emerging trends in the NIPS community Examples of topics of interest in the workshop include but are not limited to Applications of crowdsourcing to machine learning Reliable crowdsourcing e g label aggregation quality control Optimal budget allocation or active learning in crowdsourcing Pricing and incentives in crowdsourcing markets Workflow design and answer aggregation for complex tasks e g machine translation proofreading Prediction markets information markets and their connection to learning Theoretical analyses of crowdsourcing algorithms e g error rates and sample complexities for label aggregation and budget allocation algorithms Invited Speakers Michael Bernstein Stanford University abstract slides Evgeniy Gabrilovich Google abstract Arpita Ghosh Cornell University abstract slides Devavrat Shah MIT abstract Dengyong Zhou Microsoft Research abstract slides Call for Papers Submissions should follow the NIPS format and are encouraged to be up to eight pages excluding references Additional appendices and supporting materials are allowed Papers submitted for review do not need to be anonymized There will be no official proceedings but the accepted papers will be made available on the workshop website Accepted papers will be either presented as a talk or poster We welcome submissions both on novel research work as well as extended abstracts on work recently published or under review in another conference or journal please state the venue of publication in the later case we particularly encourage submission of visionary position papers on the emerging trends on the field Please submit papers in PDF format here Accepted Papers Gagan Goel Afshin Nikzad Adish Singla Matching Workers Expertise with Tasks Incentives in Heterogeneous Crowdsourcing Markets Hossein Azari Soufiani William Z Chen David C Parkes Lirong Xia Generalized Method of Moments for Rank Aggregation Genevieve Patterson Grant Van Horn Serge Belongie Pietro Perona James Hays Bootstrapping Fine Grained Classifiers Active Learning with a Crowd in the Loop Chien Ju Ho Aleksandrs Slivkins Jennifer Wortman Vaughan Adaptive Contract Design for Crowdsourcing Paul Ruvolo Jacob Whitehill Javier R Movellan Exploiting Commonality and Interaction Effects in Crowdsourcing Tasks Using Latent Factor Models Ashwinkumar Badanidiyuru Robert Kleinberg Aleksandrs Slivkins Bandits with Knapsacks Dynamic procurement for crowdsourcing Nicole Immorlica Greg Stoddard Vasilis Syrgkanis Social Status and the Design of Optimal Badges Adish Singla Ilija Bogunovic G bor Bart k Amin Karbasi Andreas Krause On Actively Teaching the Crowd to Classify Organizers Dengyong Zhou Jenn Wortman Vaughan Nikhil R Devanur Microsoft Research Qiang Liu Alexander Ihler UC Irvine Xi Chen UC Berkeley NYU Related Workshops Conferences and Resources ICML 2 13 Workshop on Machine Learning Meets Crowdsourcing Conference on Human Computation Crowdsourcing HCOMP 2 13 HCOMP 2 13 Workshop on Crowdsourcing at Scale ICML 2 12 Workshop on Machine Learning in Human Computation Crowdsourcing ICML 2 11 Workshop on Combining Learning Strategies to Reduce Label Cost NIPS 2 12 Workshop on Human Computation for Science and Computational Sustainability NIPS 2 11 Workshop on Computational Social Science and the Wisdom of Crowds NIPS 2 1 Workshop on Computational Social Science and the Wisdom of Crowds CVPR 2 1 Workshop on Advancing Computer Vision with Humans in the Loop ACVHL 1st 4th Human Computation Workshop HCOMP CrowdCamp 2 12 2 13 CHI 2 11 Workshop on Crowdsourcing and Human Computation See more information on CrowdResearch org or Mathew Lease s crowdsourcing site Page generated 2 13 12 14 17 35 35 PST by jemdoc source ", "_id": "http://www.ics.uci.edu/~qliu1/nips13_workshop/", "title": "nips &rsquo;13 workshop on crowdsourcing: theory, algorithms and applications", "html": "<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.1//EN\"\n  \"http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd\">\n<html xmlns=\"http://www.w3.org/1999/xhtml\" xml:lang=\"en\">\n<head>\n<meta name=\"generator\" content=\"jemdoc, see http://jemdoc.jaboc.net/\" />\n<meta http-equiv=\"Content-Type\" content=\"text/html;charset=utf-8\" />\n<link rel=\"stylesheet\" href=\"jemdoc.css\" type=\"text/css\" />\n<title>NIPS &rsquo;13 Workshop on Crowdsourcing: Theory, Algorithms and Applications</title>\n</head>\n<body>\n<table summary=\"Table for page layout.\" id=\"tlayout\">\n<tr valign=\"top\">\n<td id=\"layout-menu\">\n<div class=\"menu-category\">Main</div>\n<div class=\"menu-item\"><a href=\"index.html\" class=\"current\">Home</a></div>\n<div class=\"menu-item\"><a href=\"index.html#Overview\">Overview</a></div>\n<div class=\"menu-item\"><a href=\"schedule.html\">Schedule</a></div>\n<div class=\"menu-item\"><a href=\"index.html#Speakers\">Invited&nbsp;Speakers</a></div>\n<div class=\"menu-item\"><a href=\"keynotes.html\">Keynotes</a></div>\n<div class=\"menu-item\"><a href=\"index.html#CFP\">Call&nbsp;For&nbsp;Papers</a></div>\n<div class=\"menu-item\"><a href=\"index.html#Papers\">Accepted&nbsp;Papers</a></div>\n<div class=\"menu-item\"><a href=\"index.html#Organizers\">Organizers</a></div>\n<div class=\"menu-item\"><a href=\"index.html#Related\">Related&nbsp;Links</a></div>\n</td>\n<td id=\"layout-content\">\n<div id=\"toptitle\">\n<h1>NIPS &rsquo;13 Workshop on Crowdsourcing: Theory, Algorithms and Applications</h1>\n<div id=\"subtitle\"><br />\nWorkshop in conjunction with <a href=\"http://nips.cc/Conferences/2013/\">NIPS</a> 2013. </div>\n</div>\n<div class=\"infoblock\">\n<div class=\"blockcontent\">\n<p><b>Important Dates </b> <img src=\"pics/MSR_3.png\" style=\"float:right\" alt=\"MSR\" height=\"100\"> </p>\n<ul>\n<li><p>Submission deadline: October 15, 2013 <br />  </p>\n</li>\n<li><p>Acceptance Notification: October 30, 2013 <br />  </p>\n</li>\n<li><p>Workshop: December 9, 2013 <br />  </p>\n</li>\n</ul>\n<p><!-- - [schedule.html \\<font color=\\\"blue\\\"\\>\\[Schedule\\]\\<\\/font\\>] ~ [keynotes.html \\<font color=\\\"blue\\\"\\>\\[Keynotes\\]\\<\\/font\\>] ~  [index.html\\#Papers \\<font color=\\\"blue\\\"\\>\\[Papers\\]\\<\\/font\\>]  --></p>\n</div></div>\n<h2><a name='Overview'> Overview </a> </h2>\n<p>Machine learning systems involve an integration of data representing human or physical knowledge, and algorithms that discover patterns in this data and make predictions about new instances. While machine learning research usually focuses on developing more efficient learning algorithms, it is often the quality and amount of training data that predominately govern the performance of real-world systems. This is only amplified by the recent popularity of large scale and complicated learning systems such as deep networks, which can require millions to billions of training instances to perform well. Unfortunately, traditional methods of collecting data from specialized workers are usually expensive and slow. In recent years, however, a potential for change has emerged thanks to crowdsourcing, which enables huge amounts of labeled data to be collected from large groups of (usually online) workers for a low cost or no cost at all. Many machine learning tasks, such as computer vision and natural language processing, increasingly benefit from data gathered on crowdsourcing platforms such as Amazon Mechanical Turk and CrowdFlower. On the other hand, tools in machine learning, game theory, and mechanism design can help to address many challenging problems in crowdsourcing systems, such as making them more reliable, more efficient, and less expensive. </p>\n<p>In this workshop, we call attention to crowdsourcing as a source of data, discussing cheap and fast data collection methods based on crowdsourcing, and how these methods could impact subsequent stages of machine learning. Furthermore, we will emphasize how the data sourcing paradigm interacts with the most recent emerging trends in the NIPS community. </p>\n<p>Examples of topics of interest in the workshop include (but are not limited to): </p>\n<p><br /></p>\n<ul>\n<li><p>Applications of crowdsourcing to machine learning</p>\n</li>\n</ul>\n<ul>\n<li><p>Reliable crowdsourcing, e.g., label aggregation, quality control</p>\n</li>\n</ul>\n<ul>\n<li><p>Optimal budget allocation or active learning in crowdsourcing</p>\n</li>\n</ul>\n<ul>\n<li><p>Pricing and incentives in crowdsourcing markets</p>\n</li>\n</ul>\n<ul>\n<li><p>Workflow design and answer aggregation for complex tasks (e.g., machine translation, proofreading)</p>\n</li>\n</ul>\n<ul>\n<li><p>Prediction markets / information markets and their connection to learning</p>\n</li>\n</ul>\n<ul>\n<li><p>Theoretical analyses of crowdsourcing algorithms, e.g., error rates and sample complexities for label aggregation and budget allocation algorithms</p>\n</li>\n</ul>\n<h2><a name='Speakers'> Invited Speakers </a>  </h2>\n<ul>\n<li><p><a href=\"http://hci.stanford.edu/msb/\">Michael Bernstein.</a> Stanford University. <a href=\"keynotes.html\">[abstract]</a>, <a href=\"slides/13.12.09-nips-crowdsourcing-30min.pptx.pdf\">[slides]</a></p>\n</li>\n<li><p><a href=\"http://www.cs.technion.ac.il/~gabr/\">Evgeniy Gabrilovich.</a> Google. <a href=\"keynotes.html\">[abstract]</a></p>\n</li>\n<li><p><a href=\"http://www.arpitaghosh.com\">Arpita Ghosh.</a> Cornell University. <a href=\"keynotes.html\">[abstract]</a>, <a href=\"slides/NIPS2013_crowds_ag.pdf\">[slides]</a></p>\n</li>\n<li><p><a href=\"http://www.mit.edu/~devavrat/\">Devavrat Shah.</a> MIT. <a href=\"keynotes.html\">[abstract]</a></p>\n</li>\n<li><p><a href=\"http://research.microsoft.com/en-us/um/people/denzho/\">Dengyong Zhou.</a> Microsoft Research. <a href=\"keynotes.html\">[abstract]</a>, <a href=\"http://research.microsoft.com/en-us/um/people/denzho/talks/AlgorithmicCrowdsourcing.pdf\">[slides]</a></p>\n</li>\n</ul>\n<h2><a name='CFP'>  Call for Papers </a> </h2>\n<p>Submissions should follow the <a href=\"http://nips.cc/Conferences/2013/PaperInformation/AuthorSubmissionInstructions\">NIPS</a> format and are encouraged to be up to eight pages, excluding references. Additional appendices and supporting materials are allowed. Papers submitted for review do not need to be anonymized. There will be no official proceedings, but the accepted papers will be made available on the workshop website. Accepted papers will be either presented as a talk or poster. We welcome submissions both on novel research work as well as extended abstracts on work recently published or under review in another conference or journal (please state the venue of publication in the later case); we particularly encourage submission of visionary position papers on the emerging trends on the field.</p>\n<p>Please submit papers in PDF format <a href=\"https://cmt.research.microsoft.com/CROWDNIPS2013/\">here</a>. </p>\n<p><br />\n<br /></p>\n<h2><a name='Papers'> Accepted Papers </a> </h2>\n<ul>\n<li><p>Gagan Goel, Afshin Nikzad, Adish Singla; <a href=\"Papers/ActivePaper1.pdf\">Matching Workers Expertise with Tasks: Incentives in Heterogeneous Crowdsourcing Markets</a>. </p>\n</li>\n</ul>\n<ul>\n<li><p>Hossein Azari Soufiani, William Z. Chen, David C. Parkes, Lirong Xia; <a href=\"Papers/ActivePaper2.pdf\">Generalized Method-of-Moments for Rank Aggregation</a>. </p>\n</li>\n</ul>\n<ul>\n<li><p>Genevieve Patterson, Grant Van Horn, Serge Belongie, Pietro Perona, James Hays;  <a href=\"Papers/ActivePaper3.pdf\">Bootstrapping Fine-Grained Classifiers: Active Learning with a Crowd in the Loop</a>.</p>\n</li>\n</ul>\n<ul>\n<li><p>Chien-Ju Ho, Aleksandrs Slivkins, Jennifer Wortman Vaughan; <a href=\"Papers/ActivePaper4.pdf\">Adaptive Contract Design for Crowdsourcing</a>.</p>\n</li>\n</ul>\n<ul>\n<li><p>Paul Ruvolo, Jacob Whitehill, Javier R. Movellan; <a href=\"Papers/ActivePaper5.pdf\">Exploiting Commonality and Interaction Effects in Crowdsourcing Tasks Using Latent Factor Models</a>.</p>\n</li>\n</ul>\n<ul>\n<li><p>Ashwinkumar Badanidiyuru, Robert Kleinberg, Aleksandrs Slivkins; <a href=\"Papers/ActivePaper6.pdf\">Bandits with Knapsacks: Dynamic procurement for crowdsourcing</a>.</p>\n</li>\n</ul>\n<ul>\n<li><p>Nicole Immorlica, Greg Stoddard, Vasilis Syrgkanis; <a href=\"Papers/ActivePaper7.pdf\">Social Status and the Design of Optimal Badges</a>.</p>\n</li>\n</ul>\n<ul>\n<li><p>Adish Singla, Ilija Bogunovic, G&aacute;bor Bart&oacute;k, Amin Karbasi, Andreas Krause; <a href=\"Papers/ActivePaper8.pdf\">On Actively Teaching the Crowd to Classify</a>.</p>\n</li>\n</ul>\n<p><br />\n<br /></p>\n<h2><a name='Organizers'> Organizers </a> </h2>\n<ul>\n<li><p><a href=\"http://research.microsoft.com/en-us/um/people/denzho/\">Dengyong Zhou</a>, <a href=\"http://www.cs.ucla.edu/~jenn/\">Jenn Wortman Vaughan</a>, <a href=\"http://research.microsoft.com/en-us/um/people/nikdev/\">Nikhil R. Devanur</a>. \nMicrosoft Research </p>\n</li>\n</ul>\n<ul>\n<li><p><a href=\"http://www.ics.uci.edu/~qliu1/\">Qiang Liu</a>, <a href=\"http://www.ics.uci.edu/~ihler/\">Alexander Ihler</a>.  \nUC Irvine</p>\n</li>\n</ul>\n<ul>\n<li><p><a href=\"http://www.cs.cmu.edu/~xichen/\">Xi Chen</a>. \nUC Berkeley & NYU </p>\n</li>\n</ul>\n<p><br />\n<br /></p>\n<h2><a name='Related'> Related Workshops, Conferences and Resources </a>  </h2>\n<ul>\n<li><p><a href=\"http://www.ics.uci.edu/~qliu1/MLcrowd_ICML_workshop/\">ICML 2013 Workshop on Machine Learning Meets Crowdsourcing.</a></p>\n</li>\n<li><p><a href=\"http://www.humancomputation.com/2013/\">Conference on Human Computation & Crowdsourcing (HCOMP), 2013.</a></p>\n</li>\n<li><p><a href=\"https://sites.google.com/site/crowdscale2013/\">HCOMP 2013 Workshop on Crowdsourcing at Scale.</a></p>\n</li>\n<li><p><a href=\"http://crowdml12.wordpress.com\">ICML 2012 Workshop on Machine Learning in Human Computation & Crowdsourcing.</a></p>\n</li>\n<li><p><a href=\"https://sites.google.com/site/comblearn/program\">ICML 2011 Workshop on Combining Learning Strategies to Reduce Label Cost.</a></p>\n</li>\n<li><p><a href=\"http://nips.cc/Conferences/2012/Program/event.php?ID=3140\">NIPS 2012 Workshop on Human Computation for Science and Computational Sustainability.</a></p>\n</li>\n<li><p><a href=\"http://nips.cc/Conferences/2011/Program/event.php?ID=2522\">NIPS 2011 Workshop on Computational Social Science and the Wisdom of Crowds.</a></p>\n</li>\n<li><p><a href=\"http://nips.cc/Conferences/2010/Program/event.php?ID=1990\">NIPS 2010 Workshop on Computational Social Science and the Wisdom of Crowds.</a></p>\n</li>\n<li><p><a href=\"http://filebox.ece.vt.edu/~parikh/acvhl2010.htm\">CVPR 2010 Workshop on Advancing Computer Vision with Humans in the Loop (ACVHL)</a></p>\n</li>\n<li><p><a href=\"http://www.humancomputation.com/2012/About_the_Workshop.html\">1st-4th Human Computation Workshop (HCOMP).</a></p>\n</li>\n<li><p><a href=\"http://crowdresearch.org/crowdcamp/indexCHI2012.html/\">CrowdCamp 2012</a>, <a href=\"http://crowdresearch.org/crowdcamp/\">2013</a>.</p>\n</li>\n<li><p><a href=\"http://crowdresearch.org/chi2011-workshop/\">CHI 2011 Workshop on Crowdsourcing and Human Computation</a></p>\n</li>\n<li><p>See more information on  <a href=\"http://crowdresearch.org\">CrowdResearch.org</a> or <a href=\"http://ir.ischool.utexas.edu/crowd/\">Mathew Lease's crowdsourcing site.</a></p>\n</li>\n</ul>\n<div id=\"footer\">\n<div id=\"footer-text\">\nPage generated 2013-12-14 17:35:35 PST, by <a href=\"http://jemdoc.jaboc.net/\">jemdoc</a>.\n(<a href=\"index.jemdoc\">source</a>)\n</div>\n</div>\n</td>\n</tr>\n</table>\n</body>\n</html>\n", "id": 4434.0}