{"text": "Computational Vision at UC Irvine homeprojectspeoplepublicationsdatasetseventscoursescontactlinks Automatic Annotation of Everyday Movements Deva Ramanan David Forsyth This paper describes a system that can annotate a video sequence with a description of the appearance of each actor when the actor is in view and a representation of the actor s activity while in view The system does not require a fixed background and is automatic The system works by 1 tracking people in 2D and then using an annotated motion capture dataset 2 synthesizing an annotated 3D motion sequence matching the 2D tracks The 3D motion capture data is manually annotated off line using a class structure that describes everyday motions and allows motion annotations to be composed one may jump while running for example Descriptions computed from video of real motions show that the method is accurate Download pdf Text Reference Deva Ramanan and David A Forsyth Automatic annotation of everyday movements In Sebastian Thrun Lawrence Saul and Bernhard Sch o lkopf editors Advances in Neural Information Processing Systems 16 MIT Press Cambridge MA 2 4 BibTeX Reference incollection RamananF NIPS 2 3 author Ramanan Deva and Forsyth David A editor Thrun Sebastian and Saul Lawrence and Sch o lkopf Bernhard publisher MIT Press keywords activity recognition video annotation single camera tracking dynamic Bayesian networks motion capture address Cambridge MA year 2 4 title Automatic Annotation of Everyday Movements booktitle Advances in Neural Information Processing Systems 16 Computational Vision School of Information and Computer Sciences UC Irvine 2 7 2 15 UC Irvine", "_id": "http://vision.ics.uci.edu/papers/RamananF_NIPS_2003/", "title": "computational vision | ics | uc irvine", "html": "\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\" \"http://www.w3.org/TR/html4/strict.dtd\">\n<html>\n<head>\n  <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n  <title>Computational Vision | ICS | UC Irvine</title>\n  <link rel=\"stylesheet\" type=\"text/css\" href=\"/stylesheets/screen.css\" media=\"all\">\n</head>\n\n<body id=\"publications\">\n  <div id=\"outerframe\">\n  <div id=\"header\">\n    <h1>Computational Vision at UC Irvine &nbsp;<img src=\"/images/eye_small.jpg\" alt=\"small eye\"></h1>\n  </div>\n  <div id=\"tabs\">\n    <ul id=\"tabnav\">\n      <li id=\"home_tab\"><a href=\"/index.html\">home</a></li>\n      <li id=\"projects_tab\"><a href=\"/projects.html\">projects</a></li>\n      <li id=\"people_tab\"><a href=\"/people.html\">people</a></li>\n      <li id=\"publications_tab\"><a href=\"/publications.html\">publications</a></li>\n      <li id=\"datasets_tab\"><a href=\"/datasets/index.html\">datasets</a></li>\n      <li id=\"events_tab\"><a href=\"/events.html\">events</a></li>\n      <li id=\"courses_tab\"><a href=\"/courses.html\">courses</a></li>\n      <li id=\"contact_tab\"><a href=\"/contact.html\">contact</a></li>\n      <li id=\"links_tab\"><a href=\"/links.html\">links</a></li>\n    </ul>\n  </div>\n\n  <div id=\"content\">\n    <div id=\"paper_title\">Automatic Annotation of Everyday Movements</div>\n    <div id=\"paper_authors\"><a href=\"/people/20.html\">Deva&nbsp;Ramanan</a>, David&nbsp;Forsyth</div>\n    <div id=\"abstract\">\n      <img style=\"float:left;\" src=\"icon_drop.jpg\" alt=\"icon\">\n      This paper describes a system that can annotate a video sequence with:\na description of the appearance of each actor; when the actor is in \nview; and a representation of the actor's activity while in view.  The \nsystem does not require a fixed background, and is automatic.  The \nsystem works by (1) tracking people in 2D and then, using an annotated motion capture dataset, (2) synthesizing an annotated 3D motion sequence matching the 2D tracks. The 3D motion capture data is manually annotated off-line using a class structure that describes everyday motions and allows motion annotations to be composed --- one may jump while running, for example. Descriptions computed from video of real motions show that the method is accurate. \n\n\n    </div>\n    <div id=\"bibtext\">\n      <h3>Download: <a href=\"/papers/RamananF_NIPS_2003/RamananF_NIPS_2003.pdf\">pdf</a></h3>\n      <h3>Text Reference</h3>\nDeva Ramanan and David&nbsp;A. Forsyth.\nAutomatic annotation of everyday movements.\nIn Sebastian Thrun, Lawrence Saul, and Bernhard {Sch\\\"{o}lkopf}, editors, <em>Advances in Neural Information Processing Systems 16</em>.\nMIT Press, Cambridge, MA, 2004.<br>\n<h3>BibTeX Reference</h3>\n@incollection{<br>\n&nbsp;&nbsp;&nbsp;&nbsp;RamananF_NIPS_2003,<br>\n&nbsp;&nbsp;&nbsp;&nbsp;author = \"Ramanan, Deva and Forsyth, David A.\",<br>\n&nbsp;&nbsp;&nbsp;&nbsp;editor = {Thrun, Sebastian and Saul, Lawrence and {Sch\\\"{o}lkopf}, Bernhard},<br>\n&nbsp;&nbsp;&nbsp;&nbsp;publisher = \"MIT Press\",<br>\n&nbsp;&nbsp;&nbsp;&nbsp;keywords = \"activity recognition, video annotation, single-camera tracking, dynamic Bayesian networks, motion capture\",<br>\n&nbsp;&nbsp;&nbsp;&nbsp;address = \"Cambridge, MA\",<br>\n&nbsp;&nbsp;&nbsp;&nbsp;year = \"2004\",<br>\n&nbsp;&nbsp;&nbsp;&nbsp;title = \"Automatic Annotation of Everyday Movements\",<br>\n&nbsp;&nbsp;&nbsp;&nbsp;booktitle = \"Advances in Neural Information Processing Systems 16\"<br>\n}<br>\n<br>\n    </div>\n  </div>\n  <div id=\"footer\">\n    <div>\n      <a href=\"/\">Computational Vision</a> |\n      <a href=\"http://www.ics.uci.edu/\">School of Information and Computer Sciences</a> |\n      <a href=\"http://www.uci.edu/\">UC Irvine</a>\n    </div>\n    <div id=\"updated\">&copy; 2007-2015 UC Irvine</div>\n  </div>\n  </div>\n</body>\n</html>\n\n", "id": 4968.0}