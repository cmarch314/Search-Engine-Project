{"text": "Face Detection Pose Estimation and Landmark Localization in the Wild Last updated on 2 1 2 13 We present a unified model for face detection pose estimation and landmark estimation in real world cluttered images Our model is based on a mixtures of trees with a shared pool of parts we model every facial landmark as a part and use global mixtures to capture topological changes due to viewpoint We show that tree structured models are surprisingly effective at capturing global elastic deformation while being easy to optimize unlike dense graph structures We present extensive results on standard face benchmarks as well as a new in the wild annotated dataset that suggests our system advances the state of the art sometimes considerably for all three tasks Though our model is modestly trained with hundreds of faces it compares favorably to commercial systems trained with billions of examples such as Google Picasa and face com X Zhu D Ramanan Face detection pose estimation and landmark localization in the wild Computer Vision and Pattern Recognition CVPR Providence Rhode Island June 2 12 pdf slides Keynote file 36M slides PPT file converted from keynote animation may not work correctly 17M Updates NEW The AFW testdata NEW Our own landmark annotations of 4 side view faces Fixed a small bug in the basic version code when visualize the output of the independent model 7 11 2 12 Posted the two models in our CVPR2 12 paper You can use them to reproduce the results in the paper The independent model is the best performing one for landmark localization 7 3 2 12 Added Windows compatible mex files cc 7 1 2 12 Movies The following movies are DIVX encoded Downloads FilenameDescriptionSizeREADME Description of contents 2 3 KB face release1 basic zip Basic code matlab for face detection pose and landmark estimation with pre trained models 8 3 MB face release1 full zip Full code matlab for training and testing You need MultiPIE dataset to run it 59 MB sideview annotation zip NEW Landmark annotations of 4 sideview faces labeled by us You also need the other annotations from CMU to reproduce the results in our paper we don t have permission to release them here 3 KB mex windows compatible zip Windows compatible mex files cc 11 KB models CVPR2 12 zip The fully shared and independent model we used to produce the curves in our CVPR2 12 paper 6 8 MB AFW zip NEW The Annotated Faces in the Wild AFW testset 47 MB FAQs Can you release the images and annotations of MultiPIE you used in the paper Unfortunately we can t We don t own the copyright of the data and are not authorized to release them You can purchase MultiPIE from here The curator s contact information is also available on their website if you have any questions regarding the data Your detector could not find faces on my image Why The most common reason is that the faces in your image are smaller than what the released models can handle We put three pre learned models online One of them face p146 small mat works for faces larger than 8 x8 pixels eyebrows to chin ear to ear the other two work best on faces larger than 15 x15 This is simply because they were trained on large faces where all landmarks are clearly visible If landmark is not your main concern and you are really interested in detecting small faces we recommend training your own model on smaller faces you may need to use fewer parts accordingly AFLW could be a nice dataset to use for doing that I saw too many false detections or missed detections what can I do You could try tuning the threshold saved in model thresh You may want to use a higher threshold if you see too many false detections and a lower threshold if you miss a lot of faces ", "_id": "http://www.ics.uci.edu/~xzhu/face/", "title": "face detection matlab code", "html": "<html>\n<head>\n<title>Face Detection Matlab Code</title>\n\n<script type=\"text/javascript\">\n\nvar _gaq = _gaq || [];\n    _gaq.push(['_setAccount', 'UA-26193351-2']);\n\t_gaq.push(['_trackPageview']);\n(function() {\nvar ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;\nga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';\nvar s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);\n})();\n\n</script>\n</head>\n\n<style type=\"text/css\">\n#container\n{\n\twidth : 850px;\n\tpadding : 0px;\n\tmargin : 25px;\n\tbackground-color : #fff;\n\tfont-family : Ariel;\n}\nA:link {text-decoration: none}\nA:visited {text-decoration: none}\nA:active {text-decoration: none}\nA:hover {text-decoration: underline}\ntr {border:0px}\nimg.pub {height:120px;border:0px}\np.link {font-weight:bold;font-size:small;text-align:center;white-space:pre}\ntable.pub {width: 800px; border=0}\ntd.pic {text-align: right; vertical-align:top}\ntd.pub {width: 600px; vertical-align:bottom}\nspan.h2 {font-size:x-large; font-weight:bold}\nspan.h3 {font-size:large; font-weight:bold}\nspan.h3red {font-size:large; color:red}\nspan.h4 {font-style:italic; font-weight:bold} \n</style>\n\n<body bgcolor=white>\n<div id=\"container\">\n<center><h1><font size=\"6\"> Face Detection, Pose Estimation and Landmark Localization in the Wild </font></h1>\n<p> Last updated on 02/10/2013 </p></center>\n<center><img src=\"AFW_results_small.jpg\"></center>\n<br>\n<center><img src=\"mixture_trees.jpg\"></center>\n<br>\n<table border=\"0\" width=\"800\" cellpadding=\"5\">\n<tr>\n<td> <a href=\"http://www.ics.uci.edu/~xzhu/paper/face-cvpr12.pdf\"><img src=\"main_cover_shadow.jpg\"></a>\n<td>\n<p> We present a unified model for face detection, pose estimation, and landmark estimation in real-world, cluttered images. Our model is based on a mixtures of trees with a shared pool of parts; we model every facial landmark as a part and use global mixtures to capture topological changes due to viewpoint. We show that tree-structured models are surprisingly effective at  capturing global elastic deformation, while being easy to optimize unlike dense graph structures. We present extensive results on standard face benchmarks, as well as a new \"in the wild\" annotated dataset, that suggests our system advances the state-of-the-art, sometimes considerably, for all three tasks. Though our model is modestly trained with hundreds of faces, it compares favorably to commercial systems trained with billions of examples (such as Google Picasa and face.com).\n<br>\n<br>\n<p> <a href=\"http://www.ics.uci.edu/~xzhu\">X. Zhu</a>, <a href=\"http://www.ics.uci.edu/~dramanan\">D. Ramanan</a>. <b>\"Face detection, pose estimation and landmark localization in the wild\"</b> <i> Computer Vision and Pattern Recognition </i>(CVPR) Providence, Rhode Island, June 2012.\n<br>\n<a href=\"http://www.ics.uci.edu/~xzhu/paper/face-cvpr12.pdf\">[pdf]</a>\n<br>\n<a href=\"face.key\">[slides (Keynote file,36M)]</a>\n<br>\n<a href=\"face_ppt.zip\">[slides (PPT file, converted from keynote, animation may\nnot work correctly,17M)]</a>\n</table>\n\n<br>\n\n<!--updates-->\n<center><h3>Updates</h3> </center>\n<ul>\n<li> <font color=\"red\">[NEW]</font> The AFW testdata.\n<li> <font color=\"red\">[NEW]</font> Our own landmark annotations of 400 side-view faces.\n<!--<li> Added link to a C++ implementation of part-based detectors by Hilton Bristow @ WillowGarage. (08/23/2012)-->\n<!--<li> Added our face models that work with Hilton's C++ implementation. (08/23/2012)-->\n<li> Fixed a small bug in the basic version code when visualize the output of the independent model. (07/11/2012)\n<li> Posted the two models in our CVPR2012 paper. You can use them to reproduce the results in the paper. The independent model is the best-performing one for landmark localization. (07/03/2012)\n<li> Added Windows compatible mex files(.cc). (07/01/2012)\n</ul>\n\n<!-- movies -->\n<center><h3>Movies</h3> <p>The following movies are <a href=\"http://www.divx.com/divx\">DIVX</a> encoded.</p> </center>\n\n<table style=\"text-align: left; margin-left: auto; margin-right: auto;\" cellspacing=\"2\" cellpadding=\"2\">\n<tbody>\n<tr>\n\t<td style=\"text-align: center; vertical-align: bottom;\"><a href=\"face_eigen_movie.avi\"><img border=\"0\" src=\"face_eigen_movie.jpg\" alt=\"Lola Run Movie\"></a></td>\n\n\t<td style=\"width: 200px; text-align: center; vertical-align: bottom;\"> <a href=\"viewpoint_movie.avi\"><img border=\"0\" src=\"viewpoint_movie.jpg\" alt=\"Lola Stop Movie\"></a> </td>\n\n</tr>\n</tbody>\n</table>\n<!-- movies -->\n\n<center><h3>Downloads</h3></center>\n \n<table style=\"text-align: left\"> \n<col width=\"200\" />\n<col width=\"500\" />\n<col width=\"100\" />\n<tbody><tr><th>Filename</th><th>Description</th><th>Size</th>\n<tr> \n<td><a href=\"README\">README</a>\n<td>Description of contents.\n<td>2.3 KB\n\n<tr>\n<!--<td><a href=\"face-release1.0-basic.zip\">face-release1.0-basic.zip</a>-->\n<td><a href=\"face-release1.0-basic.zip\" onClick=\"_gaq.push(['_trackEvent', 'FaceCode', 'Download', 'BasicVersion']);\">face-release1.0-basic.zip</a>\n<td>Basic code (matlab) for face detection, pose and landmark estimation with pre-trained models.\n<td> 8.3 MB\n\n<tr>\n<td><a href=\"face-release1.0-full.zip\" onClick=\"_gaq.push(['_trackEvent', 'FaceCode', 'Download', 'FullVersion']);\">face-release1.0-full.zip</a>\n<td>Full code (matlab) for training and testing. You need <a href=\"http://www.multipie.org\">MultiPIE dataset</a> to run it.\n<td> 59 MB\n\n<tr>\n<td><a href=\"sideview_annotation.zip\">sideview_annotation.zip<font color=\"red\">[NEW]</font></a>\n<td> Landmark annotations of 400 sideview faces labeled by us. You also need the other annotations from CMU to reproduce the results in our paper (we don't have permission to release them here).\n<td> 300 KB\n\n\n<tr>\n<td><a href=\"mex-windows-compatible.zip\">mex-windows-compatible.zip</a>\n<td> Windows compatible mex files(.cc).\n<td> 11 KB\n\n<tr>\n<td><a href=\"models_CVPR2012.zip\">models_CVPR2012.zip</a>\n<td> The fully shared and independent model we used to produce the curves in our CVPR2012 paper.\n<td> 6.8 MB\n<tr>\n\n<!--<td><a href=\"http://github.com/wg-perception/PartsBasedDetector\">C++ PartsBasedDetector</a>-->\n<!--<td>A C++ implementation by Hilton Bristow @ <a href=\"http://www.willowgarage.com\">WillowGarage</a>. -->\n<!--<td> -->\n<!--<tr>-->\n\n<!--<td><a href=\"face_models.zip\">Face models for Hilton's C++ implementation</a>-->\n<!--<td>The face models converted from our Matlab format to Hilton's format. -->\n<!--<td> 11 MB-->\n<!--<tr>-->\n\n<td><a href=\"AFW.zip\">AFW.zip<font color=\"red\">[NEW]</font></a>\n<td> The Annotated Faces in the Wild (AFW) testset.\n<td> 47 MB\n</tbody>\n</table>\n\n<center><h3>FAQs</h3></center>\n<ul>\n<li><b>Can you release the images and annotations of MultiPIE you used in the paper?</b><br>\n- Unfortunately, we can't. We don't own the copyright of the data, and are not authorized to release them. You can purchase MultiPIE from <a href=\"http://www.flintbox.com/public/project/4742/\">here</a>. The curator's contact information is also available on their website, if you have any questions regarding the data. \n<li><b>Your detector could not find faces on my image. Why?</b><br>\n- The most common reason is that the faces in your image are smaller than what the released models can handle. We put three pre-learned models online. One of them (face_p146_small.mat) works for faces larger than 80x80 pixels (eyebrows to chin, ear to ear); the other two work best on faces larger than 150x150. This is simply because they were trained on large faces where all landmarks are clearly visible.<br>\nIf landmark is not your main concern, and you are really interested in <em>detecting small faces</em>, we recommend training your own model on smaller faces (you may need to use fewer parts accordingly). <a href=\"http://lrs.icg.tugraz.at/research/aflw\">AFLW</a> could be a nice dataset to use for doing that.\n<li><b>I saw too many false detections (or missed detections), what can I do?</b><br>\n- You could try tuning the threshold saved in <em>model.thresh</em>. You may want to use a higher threshold if you see too many false detections, and a lower threshold if you miss a lot of faces.\n</ul>\n\n</div>\n</body>\n</html>\n", "id": 4502.0}